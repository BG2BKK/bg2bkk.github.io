[{"content":"正文测试 而这些并不是完全重要，更加重要的问题是， 带着这些问题，我们来审视一下学生会退会。 既然如何， 对我个人而言，学生会退会不仅仅是一个重大的事件，还可能会改变我的人生。 我们不得不面对一个非常尴尬的事实，那就是， 可是，即使是这样，学生会退会的出现仍然代表了一定的意义。 学生会退会，发生了会如何，不发生又会如何。 经过上述讨论， 生活中，若学生会退会出现了，我们就不得不考虑它出现了的事实。 学生会退会，到底应该如何实现。 这样看来， 在这种困难的抉择下，本人思来想去，寝食难安。 对我个人而言，学生会退会不仅仅是一个重大的事件，还可能会改变我的人生。 就我个人来说，学生会退会对我的意义，不能不说非常重大。 莎士比亚曾经提到过，人的一生是短的，但如果卑劣地过这一生，就太长了。这似乎解答了我的疑惑。 莫扎特说过一句富有哲理的话，谁和我一样用功，谁就会和我一样成功。这启发了我， 对我个人而言，学生会退会不仅仅是一个重大的事件，还可能会改变我的人生。 学生会退会，到底应该如何实现。 一般来说， 从这个角度来看， 这种事实对本人来说意义重大，相信对这个世界也是有一定意义的。 在这种困难的抉择下，本人思来想去，寝食难安。 了解清楚学生会退会到底是一种怎么样的存在，是解决一切问题的关键。 一般来说， 生活中，若学生会退会出现了，我们就不得不考虑它出现了的事实。 问题的关键究竟为何？ 而这些并不是完全重要，更加重要的问题是。\n奥斯特洛夫斯基曾经说过，共同的事业，共同的斗争，可以使人们产生忍受一切的力量。　带着这句话，我们还要更加慎重的审视这个问题： 一般来讲，我们都必须务必慎重的考虑考虑。 既然如此， 这种事实对本人来说意义重大，相信对这个世界也是有一定意义的。 带着这些问题，我们来审视一下学生会退会。 我认为， 我认为， 在这种困难的抉择下，本人思来想去，寝食难安。 问题的关键究竟为何？ 每个人都不得不面对这些问题。 在面对这种问题时， 要想清楚，学生会退会，到底是一种怎么样的存在。 我认为， 既然如此， 每个人都不得不面对这些问题。 在面对这种问题时， 那么， 我认为， 学生会退会因何而发生。\n引用  思念是最暖的忧伤像一双翅膀\n让我停不了飞不远在过往游荡\n不告而别的你 就算为了我着想\n这么沉痛的呵护 我怎么能翱翔\n最暖的憂傷 - 田馥甄\n 图片 1 2 3  ![Photo by Florian Klauer on Unsplash](florian-klauer-nptLmg6jqDo-unsplash.jpg) ![Photo by Luca Bravo on Unsplash](luca-bravo-alS7ewQ41M8-unsplash.jpg) ![Photo by Helena Hertz on Unsplash](helena-hertz-wWZzXlDpMog-unsplash.jpg) ![Photo by Hudai Gayiran on Unsplash](hudai-gayiran-3Od_VKcDEAA-unsplash.jpg)   相册语法来自 Typlog\n","date":"2020-09-09T00:00:00Z","image":"https://bg2bkk.github.io/p/test-chinese/helena-hertz-wWZzXlDpMog-unsplash_hu45a5e3ad5e058da6a00650ed8fd40bea_15530_120x120_fill_q75_box_smart1.jpg","permalink":"https://bg2bkk.github.io/p/test-chinese/","title":"Chinese Test"},{"content":"This article offers a sample of basic Markdown syntax that can be used in Hugo content files, also it shows whether basic HTML elements are decorated with CSS in a Hugo theme.\nHeadings The following HTML \u0026lt;h1\u0026gt;—\u0026lt;h6\u0026gt; elements represent six levels of section headings. \u0026lt;h1\u0026gt; is the highest section level while \u0026lt;h6\u0026gt; is the lowest.\nH1 H2 H3 H4 H5 H6 Paragraph Xerum, quo qui aut unt expliquam qui dolut labo. Aque venitatiusda cum, voluptionse latur sitiae dolessi aut parist aut dollo enim qui voluptate ma dolestendit peritin re plis aut quas inctum laceat est volestemque commosa as cus endigna tectur, offic to cor sequas etum rerum idem sintibus eiur? Quianimin porecus evelectur, cum que nis nust voloribus ratem aut omnimi, sitatur? Quiatem. Nam, omnis sum am facea corem alique molestrunt et eos evelece arcillit ut aut eos eos nus, sin conecerem erum fuga. Ri oditatquam, ad quibus unda veliamenimin cusam et facea ipsamus es exerum sitate dolores editium rerore eost, temped molorro ratiae volorro te reribus dolorer sperchicium faceata tiustia prat.\nItatur? Quiatae cullecum rem ent aut odis in re eossequodi nonsequ idebis ne sapicia is sinveli squiatum, core et que aut hariosam ex eat.\nBlockquotes The blockquote element represents content that is quoted from another source, optionally with a citation which must be within a footer or cite element, and optionally with in-line changes such as annotations and abbreviations.\nBlockquote without attribution  Tiam, ad mint andaepu dandae nostion secatur sequo quae. Note that you can use Markdown syntax within a blockquote.\n Blockquote with attribution  Don\u0026rsquo;t communicate by sharing memory, share memory by communicating.— Rob Pike1 Tables Tables aren\u0026rsquo;t part of the core Markdown spec, but Hugo supports supports them out-of-the-box.\n   Name Age     Bob 27   Alice 23    Inline Markdown within tables    Italics Bold Code     italics bold code       A B C D E F     Lorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus ultricies, sapien non euismod aliquam, dui ligula tincidunt odio, at accumsan nulla sapien eget ex. Proin eleifend dictum ipsum, non euismod ipsum pulvinar et. Vivamus sollicitudin, quam in pulvinar aliquam, metus elit pretium purus Proin sit amet velit nec enim imperdiet vehicula. Ut bibendum vestibulum quam, eu egestas turpis gravida nec Sed scelerisque nec turpis vel viverra. Vivamus vitae pretium sapien    Code Blocks Code block with backticks 1 2 3 4 5 6 7 8 9 10  \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;   Code block indented with four spaces \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026quot;en\u0026quot;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026quot;utf-8\u0026quot;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;  Code block with Hugo\u0026rsquo;s internal highlight shortcode 1 2 3 4 5 6 7 8 9 10  \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;   Diff code block 1 2 3 4 5  [dependencies.bevy] git = \u0026#34;https://github.com/bevyengine/bevy\u0026#34; rev = \u0026#34;11f52b8c72fc3a568e8bb4a4cd1f3eb025ac2e13\u0026#34; - features = [\u0026#34;dynamic\u0026#34;] + features = [\u0026#34;jpeg\u0026#34;, \u0026#34;dynamic\u0026#34;]   List Types Ordered List  First item Second item Third item  Unordered List  List item Another item And another item  Nested list  Fruit  Apple Orange Banana   Dairy  Milk Cheese    Other Elements — abbr, sub, sup, kbd, mark GIFis a bitmap image format.\nH2O\nXn+ Yn= ZnPress CTRL+ALT+Deleteto end the session.\nMost salamandersare nocturnal, and hunt for insects, worms, and other small creatures.\nHyperlinked image \n  The above quote is excerpted from Rob Pike\u0026rsquo;s talk during Gopherfest, November 18, 2015.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n  ","date":"2019-03-11T00:00:00Z","image":"https://bg2bkk.github.io/p/markdown-syntax-guide/pawel-czerwinski-8uZPynIu-rQ-unsplash_hud7e36f7e20e71be184458283bdae4646_55974_120x120_fill_q75_box_smart1.jpg","permalink":"https://bg2bkk.github.io/p/markdown-syntax-guide/","title":"Markdown Syntax Guide"},{"content":"Hugo ships with several Built-in Shortcodes for rich content, along with a Privacy Config and a set of Simple Shortcodes that enable static and no-JS versions of various social media embeds.\n YouTube Privacy Enhanced Shortcode    Twitter Simple Shortcode .twitter-tweet { font: 14px/1.45 -apple-system,BlinkMacSystemFont,\"Segoe UI\",Roboto,Oxygen-Sans,Ubuntu,Cantarell,\"Helvetica Neue\",sans-serif; border-left: 4px solid #2b7bb9; padding-left: 1.5em; color: #555; } .twitter-tweet a { color: #2b7bb9; text-decoration: none; } blockquote.twitter-tweet a:hover, blockquote.twitter-tweet a:focus { text-decoration: underline; }  “In addition to being more logical, asymmetry has the advantage that its complete appearance is far more optically effective than symmetry.”\n— Jan Tschichold pic.twitter.com/gcv7SrhvJb\n\u0026mdash; Graphic Design History (@DesignReviewed) January 17, 2019  Vimeo Simple Shortcode  .__h_video { position: relative; padding-bottom: 56.23%; height: 0; overflow: hidden; width: 100%; background: #000; } .__h_video img { width: 100%; height: auto; color: #000; } .__h_video .play { height: 72px; width: 72px; left: 50%; top: 50%; margin-left: -36px; margin-top: -36px; position: absolute; cursor: pointer; }   bilibilibi Shortcode \r\rGist Shortcode  Gitlab Snippets Shortcode  Quote Shortcode Stack adds a quote shortcode. For example:\n Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n― A famous person, The book they wrote  Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n― Anonymous book  Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n― Some book  Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n― Somebody","date":"2019-03-10T00:00:00Z","permalink":"https://bg2bkk.github.io/p/rich-content/","title":"Rich Content"},{"content":"فقرة 1 هذا النص هو مثال لنص يمكن أن يستبدل في نفس المساحة، لقد تم توليد هذا النص من مولد النص العربى، حيث يمكنك أن تولد مثل هذا النص أو العديد من النصوص الأخرى إضافة إلى زيادة عدد الحروف التى يولدها التطبيق. إذا كنت تحتاج إلى عدد أكبر من الفقرات يتيح لك مولد النص العربى زيادة عدد الفقرات كما تريد، النص لن يبدو مقسما ولا يحوي أخطاء لغوية، مولد النص العربى مفيد لمصممي المواقع على وجه الخصوص، حيث يحتاج العميل فى كثير من الأحيان أن يطلع على صورة حقيقية لتصميم الموقع. ومن هنا وجب على المصمم أن يضع نصوصا مؤقتة على التصميم ليظهر للعميل الشكل كاملاً،دور مولد النص العربى أن يوفر على المصمم عناء البحث عن نص بديل لا علاقة له بالموضوع الذى يتحدث عنه التصميم فيظهر بشكل لا يليق. هذا النص يمكن أن يتم تركيبه على أي تصميم دون مشكلة فلن يبدو وكأنه نص منسوخ، غير منظم، غير منسق، أو حتى غير مفهوم. لأنه مازال نصاً بديلاً ومؤقتاً.\nفقرة 2 هذا النص هو مثال لنص يمكن أن يستبدل في نفس المساحة، لقد تم توليد هذا النص من مولد النص العربى، حيث يمكنك أن تولد مثل هذا النص أو العديد من النصوص الأخرى إضافة إلى زيادة عدد الحروف التى يولدها التطبيق. إذا كنت تحتاج إلى عدد أكبر من الفقرات يتيح لك مولد النص العربى زيادة عدد الفقرات كما تريد، النص لن يبدو مقسما ولا يحوي أخطاء لغوية، مولد النص العربى مفيد لمصممي المواقع على وجه الخصوص، حيث يحتاج العميل فى كثير من الأحيان أن يطلع على صورة حقيقية لتصميم الموقع. ومن هنا وجب على المصمم أن يضع نصوصا مؤقتة على التصميم ليظهر للعميل الشكل كاملاً،دور مولد النص العربى أن يوفر على المصمم عناء البحث عن نص بديل لا علاقة له بالموضوع الذى يتحدث عنه التصميم فيظهر بشكل لا يليق. هذا النص يمكن أن يتم تركيبه على أي تصميم دون مشكلة فلن يبدو وكأنه نص منسوخ، غير منظم، غير منسق، أو حتى غير مفهوم. لأنه مازال نصاً بديلاً ومؤقتاً.\nتجربة RTL كلمة 1 Text كلمة 2\n","date":"2019-03-09T00:00:00Z","image":"https://bg2bkk.github.io/p/%D9%85%D8%AB%D8%A7%D9%84-%D9%86%D8%B5/matt-le-SJSpo9hQf7s-unsplash_hu958d513eeefe5556a31d065479ecc5ac_14205_120x120_fill_q75_box_smart1.jpg","permalink":"https://bg2bkk.github.io/p/%D9%85%D8%AB%D8%A7%D9%84-%D9%86%D8%B5/","title":"مثال نص"},{"content":"Mathematical notation in a Hugo project can be enabled by using third party JavaScript libraries.\nIn this example we will be using KaTeX\n Create a partial under /layouts/partials/math.html Within this partial reference the Auto-render Extension or host these scripts locally. Include the partial in your templates like so:  1 2 3  {{ if or .Params.math .Site.Params.math }} {{ partial \u0026#34;math.html\u0026#34; . }} {{ end }}    To enable KaTex globally set the parameter math to true in a project\u0026rsquo;s configuration To enable KaTex on a per page basis include the parameter math: true in content files  Note: Use the online reference of Supported TeX Functions\nExamples Block math: $$ \\varphi = 1+\\frac{1} {1+\\frac{1} {1+\\frac{1} {1+\\cdots} } } $$\n","date":"2019-03-08T00:00:00Z","permalink":"https://bg2bkk.github.io/p/math-typesetting/","title":"Math Typesetting"},{"content":"Emoji can be enabled in a Hugo project in a number of ways.\nThe emojify function can be called directly in templates or Inline Shortcodes.\nTo enable emoji globally, set enableEmoji to true in your site\u0026rsquo;s configuration and then you can type emoji shorthand codes directly in content files; e.g.\nThe Emoji cheat sheet is a useful reference for emoji shorthand codes.\n N.B. The above steps enable Unicode Standard emoji characters and sequences in Hugo, however the rendering of these glyphs depends on the browser and the platform. To style the emoji you can either use a third party emoji font or a font stack; e.g.\n1 2 3  .emoji { font-family: Apple Color Emoji, Segoe UI Emoji, NotoColorEmoji, Segoe UI Symbol, Android Emoji, EmojiSymbols; }  ","date":"2019-03-05T00:00:00Z","image":"https://bg2bkk.github.io/p/emoji-support/the-creative-exchange-d2zvqp3fpro-unsplash_huf941de4769045cdfa8c9ee7036519a2a_35369_120x120_fill_q75_box_smart1.jpg","permalink":"https://bg2bkk.github.io/p/emoji-support/","title":"Emoji Support"},{"content":" shell模拟二维数组 shell切割字符串到数组  ","date":"2017-03-02T22:21:18+08:00","permalink":"https://bg2bkk.github.io/p/effective_shell_scripts/","title":"effective_shell_scripts"},{"content":" 设置广播  The advertising module have two different modes you can use for this. ADV_MODE_FAST and ADV_MODE_SLOW, and you can specify the advertising interval you want for each mode. 可以设置fast模式和slow模式，在fast模式超时后转向slow模式，省电 参考链接    ","date":"2017-01-30T22:53:22+08:00","permalink":"https://bg2bkk.github.io/p/ble_nrf51822_tips/","title":"ble_nrf51822_tips"},{"content":"昨天开会，组里提到的virto、sr iov、libvswitch、open switch和多队列网卡等概念，一窍不通，这咋过试用期呢？\n千里之行，始于足下，一步步来就是最快的路，开干。\n虚拟化基本概念   剖析linux hypervisor\n  virtio概念\n  多队列网卡\n ixgbe网卡 ixgbe网卡rss原理 各种多队列方式的对比 网卡多队列技术  RPS，将软中断负载均衡到CPU的各个core中  Linux内核中，RPS（Receive Packet Steering）在接收端提供了这样的机制。RPS主要是把软中断的负载均衡到CPU的各个core上，网卡驱动对每个流生成一个hash标识，这个hash值可以通过四元组（源IP地址SIP，源四层端口SPORT，目的IP地址DIP，目的四层端口DPORT）来计算，然后由中断处理的地方根据这个hash标识分配到相应的core上去，这样就可以比较充分地发挥多核的能力了。   DPDK多队列支持  RSS，微软提出  哈希   Flow Director，英特尔提出  精确匹配          SDN网络\n feisky.xyz *    Open vSwitch\n OVS 基于 Open vSwitch 的 OpenFlow 实践    SR-IOV\n SR IOV简介  SR-IOV 技术是一种基于硬件的虚拟化解决方案，可提高性能和可伸缩性。SR-IOV 标准允许在虚拟机之间高效共享 PCIe（Peripheral Component Interconnect Express，快速外设组件互连）设备，并且它是在硬件中实现的，可以获得能够与本机性能媲美的 I/O 性能。SR-IOV 规范定义了新的标准，根据该标准，创建的新设备可允许将虚拟机直接连接到 I/O 设备。 PF VF      ","date":"2017-01-21T22:14:53+08:00","permalink":"https://bg2bkk.github.io/p/%E8%99%9A%E6%8B%9F%E5%8C%96%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF/","title":"虚拟化学习之路"},{"content":"1 2  printf(\u0026#34;%lld\\n\u0026#34;, 1024*1024*1024*16L); printf(\u0026#34;%lld\\n\u0026#34;, 1024*1024*1024*16);   ","date":"2016-12-28T10:20:22+08:00","permalink":"https://bg2bkk.github.io/p/c%E8%AF%AD%E8%A8%80%E7%9A%84%E4%BC%A0%E5%8F%82%E6%95%B0%E9%97%AE%E9%A2%98/","title":"C语言的传参数问题"},{"content":"对linux kernel中的container_of总是理解了又忘记，这次还是一次搞明白吧。\n在参考文章中说的很明白，讲到问题的关键点。\n1 2  #define list_entry(ptr, type, member) /  ((type *)((char *)(ptr)-(unsigned long)(\u0026amp;((type *)0)-\u0026gt;member)))   对宏list_entry来说，type是结构体定义，member是结构体定义中的一个成员，ptr是一个结构体变量的member成员地址，list_entry的目的是，在已知某个结构体变量中某个成员地址的情况下，如何根据结构体类型type得出该结构体变量的地址\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  typedef struct container { char dummy; int a; int b; } container_t ; int main() { container_t c; int *p = \u0026amp;(c.b); printf(\u0026#34;offset of p: %u\\n\u0026#34;, \u0026amp;(((container_t *)0)-\u0026gt;b)); printf(\u0026#34;address of p: %p\\n\u0026#34;, (container_t *)( (char *)p - (unsigned long)\u0026amp;(((container_t *)0)-\u0026gt;b)) ); printf(\u0026#34;address of c: %p\\n\u0026#34;, \u0026amp;c ); }   在以上代码中，container_t是结构体类型type，c是结构体变量，指针p是c中成员b的地址；(container_t * )0 表示将地址0强制转换为container_t类型，表示0地址处存放了container_t类型的结构体变量，则 ((container_t * )0)-\u0026gt;b指向b成员，那么它的地址 \u0026amp;(((container_t * )0)-\u0026gt;b)不光是b的地址，由于结构体变量的地址是0，那么这个地址减去结构体变量的地址就是b成员相对于结构体定义的偏移，而对于另一个结构体变量c来说，用p减去这个偏移也能得到c的地址。\n理解到\u0026amp;(((container_t * )0)-\u0026gt;b)是地址也是偏移，就能抓住container_of的意思了。\n","date":"2016-12-24T19:13:26+08:00","permalink":"https://bg2bkk.github.io/p/container_of%E5%92%8Clist%E7%9A%84%E8%AE%B2%E8%A7%A3/","title":"container_of和list的讲解"},{"content":" leveldb日知录  ","date":"2016-12-23T11:36:16+08:00","permalink":"https://bg2bkk.github.io/p/leveldb%E5%AD%A6%E4%B9%A0%E8%BF%87%E7%A8%8B/","title":"leveldb学习过程"},{"content":" ext3介绍  ","date":"2016-12-22T13:20:07+08:00","permalink":"https://bg2bkk.github.io/p/ext3%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/","title":"Ext3文件系统"},{"content":" dpdk简书  api    ","date":"2016-12-16T17:43:47+08:00","permalink":"https://bg2bkk.github.io/p/dpdk%E7%9A%84%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF/","title":"dpdk的学习之路"},{"content":" C++11 标准新特性：Defaulted 和 Deleted 函数  ","date":"2016-12-13T19:55:18+08:00","permalink":"https://bg2bkk.github.io/p/cpp11/","title":"cpp11"},{"content":" 广播 抓包 [扫描 抓包](http://www.cnblogs.com/aikm/p/5144209.html 概述及beacon  ","date":"2016-11-21T12:03:13+08:00","permalink":"https://bg2bkk.github.io/p/ble_protocol_%E5%8D%8F%E8%AE%AE%E8%A7%A3%E6%9E%90%E5%92%8C%E6%8A%93%E5%8C%85%E5%88%86%E6%9E%90/","title":"ble_protocol_协议解析和抓包分析"},{"content":"Chapter 1 现代处理器系统中，Cache处于Memory子系统的最顶端，集成在CPU里；一般来说包含L1/L2和L3 Cache，访存时CPU能从Cache中获取数据的话，就不会进行下一级访问，以缩短访问时延。\n随着工艺的提高，CPU的主频越来越高，而主存的访问时延却没有相应提高，差距越拉越大，亟需采用高效率Cache Memory来掩盖CPU-Memory之间的latency。\n现代处理器的任务执行时间一般包括两部分：\n1  Execution Time = (CPU clock cycles + Memory stall cycles) * Clock cycle time   缩短访存时延是提高处理器执行效率的关键。\n使用Cache提高访存性能的理论依据是程序执行的时间局部性（Temporal Locality）和空间局部性（Spatial Locality），合理安排Cache层次结构比简单增大Cache更有意义。\n每次访存的平均时间AMAT计算方式为：\n1  Average memory access time = Hit time + Miss rate * Miss Penalty   计算AMAT只需要确定hit time、miss rate和miss penalty三个参数即可，而这也并不容易。\n1.1 Cache 细细看 回到前文说的hit time、miss rate和miss penalty三个参数，探讨准确计算他们需要的注意的因素\n Hit Time  对于L1 Data Cache，原本认为Hit Time可以轻易从intel 手册得出，但是现代处理器大多使用了 Store-Load Forwarding 技术，存储器读时不是从L1 Cache开始的，而是在L1 Cache之前仍然有一段缓存，缓存没来得及提交都Store结果，这个缓存比L1还要接近CPU，也更快一些。\n而对于L1 Instruction Cache，它之前也还有一个Line-Fill Buffer，以及其他微结构，计算这个Cache的延时也不容易。\n总之，L1 Cache在计算机系统中不是第一级，也不是最快的，考虑到其他微结构的因素，Hit Time并不容易计算\n考虑到多核处理器，存储器访问中在自己的L1 Cache没有命中，却在其他CPU的cache中命中，这里存在数据传递问题。如果再考虑到SMP系统间Cache的一致性，问题就更复杂了。\n  Miss Rate\n  Miss Penalty\n  此外，虚实地址转换也需要考虑，处理器使用的是Physical Address访问主存。\n虚拟化技术的引入，带来了IOMMU和IO虚拟化技术。（IOMMU在驱动开发中也早有实现）\n","date":"2016-11-07T15:22:50+08:00","permalink":"https://bg2bkk.github.io/p/cachememory_%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/","title":"CacheMemory_读书笔记"},{"content":"bw_mem   init_loop\n  get_enough\n  init_timing\n compute_enough()  计算可以得到计算机准确执行时间的时间段，在该时间段内计算机的执行时间能够稳定   t_overload()  用循环计算 gettimeofday() 的开销   l_overload()  计算仅用于循环的时间开销   init_timing()在一次benchmakr中只执行一次，除非第二次运行程序    compute_enough()\n 预估5000us、10000us、50000us和100000us，比如在5000us内计算机用时能够稳定，那么认为运行想运行的任务，5000us足够使计算机测量稳定下来，那么就返回5000us；如果四个都不行，则返回SHORT，也就是1000000us，一个足够大的数据。理论上讲其实计算机执行一个非常快或者用时普通的任务，在循环足够次数，运行足够时间，平均下来都能使单次时间稳定，但是如果能找到合适的时长，benchmark过程可以更快，且执行时间短意味着受到外界干扰小。 compute_enough() 调用 test_time() 依次评估每个预估值 test_time(enough)  find_N(enough)，得到执行任务A，执行时长为enough us，需要跑多少次，得到N。  find_N 首先执行 N = 10000, time_N(N)，看看执行10000次A的运行时间t，如果运行时间t与enough误差在2%以下，那么就返回N；如果运行时间t过小，低于1000us，说明执行N次还不够，需要加码，扩大10倍，N = N * 10；如果t不低于1000us，说明执行N次还可以，不过要按照运行时间t和enough的比值，再结合运行N次需要t us，折算出运行enough时间大概需要 N = enough * N / t; 拿着新的N再次find_N(N)，直到执行时间与enough相差不到2%时，可以认为，计算机执行N次任务A，需要用时enough us。 这个逼近过程循环10次，返回结果；如果不能收敛在2%里，则认为enough时长还不足以让CPU运行稳定，需要加长。  time_N(N)通过执行执行duration(N)，执行Nx10次 long **p; p = (long **) *p;这样一个赋值运算，汇编是[ move (%eax), %eax ]，从内存中读值，写入寄存器；读p地址的值只是读L1 cache中，所以在CPU内运行，不会有外界干扰。在不同平台不同性能的机器上，大家都执行这个duration(N)，通过执行N次达到时间u，作为cpu的基准。这样还是蛮科学的 执行TRIES次 time_N(N)，取最小值返回 duration(N)就是任务A。     test_time(enough)中，拿到find_N(enough)所需要的执行次数N后，再次计算执行N次用时，time_N(N)，以这次结果为baseline；然后将N扩大到1.015倍、1.020倍和1.035倍，计算执行所需要时间time_N(N * factor)，得到结果与baseline * factor比较，误差在0.25%内的话，说明执行enough时间，需要N次，这个经过更新的N存储在全局变量中(save_n())，也就是存储在全局变量iterations里。 如果误差仍然较大，那么我们选用一个较大的时间，比如SHORT=1000000；此时的N并无意义。      t_overload()\n 如果在之前的compute_enough()没有计算得到enough时间，返回的是SHORT，或者即使得到了，但是大于50000，执行时间足够长，那么我们认为gettimeofday的时间开销可以忽略不计，记为0。 如果得到一个时间enough小雨50000us，那么认为gettimeofday的开销有必要列入，需要在循环中确定它的调用所需时长    l_overload()\n 在需要循环很多次的benchmark中，loop的开销很有必要列入统计中，再bench总时长中排除loop的影响 loop的计算比较巧妙，假设loop开销是overhead，在同样的loop下，loop循环体执行一个任务和两个任务，分别进行bench，循环n1次和n2次，得到执行时长为u1、u2  u1 = n1 * ( overhead + work) u2 = n2 * ( overhead + 2 * work) overhead = 2*u1/n1 - u2/n2 overhead即为单次loop的开销，一般很小，但是累计起来比较客观。        benchmp框架\n  fork出child进程，作为bench执行体；parent作为控制体；\n  parent和child通过pipe互相通信，child通知parent准备好，parent通知child开始，child执行完毕后通知parent完成；parent取完执行结果，通知child结束。\n  应用程序中child首先执行init程序，将准备工作做好；比如如果是bw_mem中的cp benchmark，需要首先分配好src内存块，然后分配dst内存块，准备好后即返回，init结束；\n  init结束后，benchmp框架进行下一步，while循环中执行benchmark进入warmup状态\n  child执行benchmark是以状态机方式实现的\n 首先是warmup状态，在该状态中childparent发送ready信号，阻塞等待parent的start信号。child收到start后，状态设置为timing_interval，取iterations为1，执行benchmark程序；执行完后重入while循环； 由于已经执行以此iterations为1的benchmark，重入循环时满足state-\u0026gt;need_warmup == 0，所以开始统计上一次benchmark开始到现在的用时，并刨去t_overload和l_overload；进入状态机的timing_interval状态，该状态评估本次benchmark的用时是否符合期望，如果符合，将本次bench结果记录，并设置状态为cooldown；如果不符合期望，分情况，如果用时result小于150，说明单次benchmark用时太短，需要多次迭代得到总结果，因此将iterations扩大8倍去计算；如果用时大于150，说明单次benchmark执行时间是够的，但是需要微调迭代次数，按照 enough * 1.1 / (iterations / result)；所以说timing_interval状态是用来在bench过程中微调迭代次数以使执行时间符合预期的过程。 在cooldown状态，child阻塞等待取结果信号，并将结果写回response管道中；执行清理函数后，得到parent发出的exit信号，结束自己。    最终结果存储在全局变量iterations和stop_tv中，其实是通过get_time()和get_n()，以及set_time()/save_n()或者set_results()中，并在用户程序的结束时进行计算。\n  如果进行多任务\n 1 2 3      ","date":"2016-10-31T11:07:28+08:00","permalink":"https://bg2bkk.github.io/p/lmbench_bandwidth_memory/","title":"lmbench_bandwidth_memory"},{"content":"宏观评估服务器性能，即macro bench   主要观察CPU、内存、磁盘和网络IO这四个指标\n  首先看硬件配置，CPU核数/主频/超线程，内存带宽/大小/访问速度，磁盘类型/转速，网卡千兆/万兆/多队列等\n 知晓极限值，针对硬件选取场景。    然后知道kernel关于这些设备的可tuning的配置选项，以及kernel自身配置，如vm策略、进程调度设置等\n 默认服务器设备的驱动都是厂商调优好的，或者采用kernel自带驱动    不同指标的通用观测方法\n 首选成熟工具：top、sar、vmstat、mpstat、netstat、iptraf等 从 /proc 定制 动态追踪，perf、systemtap等，在精细观察时使用    根据软硬件变量的结合，搭配设计纯理论场景并实现，采用对应方法检测\n 先把linux server主流常用的配置配好，采用简单方法做性能测试，确定各个指标的性能，作为参照基准 然后设计场景，体现要突出的指标，确定极限值，与参照基准做对比  kernel对相关资源进行优化 选择压测工具，必要时写代码实现   如果能够引入内核的一些新技术，就某个指标进行优化，可以进行后续测试。    CPU计算能力   硬件\n 主频/核数/超线程：/proc/cpuinfo 各级缓存大小    测试场景\n  评估计算能力\n 方式一：选择高CPU型应用压测，采用专业benchmark软件观察;计算圆周率 方式二：采用开源代码，或者手写计算型压测代码，通过systemtap等工具统计时长  参考sysbench      评估各级CPU高速缓存L1/L2/L3失效对性能的影响\n 场景：  通过代码创造cache miss情况   方法：  采用systemtap等相关工具统计时长 获取CPU各级缓存速度，需要多少cycle读取  查文档或者其他方式，如lmbench        评估进程调度和切换能力\n 场景：并发大量CPU繁忙任务 方法：  查看CPU负载 统计context switch/ interrupt stats，通过sar等工具 进程切换平均时间统计，在不同负载下：谁在做进程调度\u0026amp;\u0026amp;lmbench 进程调度能力  load average，通过统计工具 动态跟踪方法动态确定处于调度队列中的任务规模 taskset设置多cpu亲和性运行          TODO\n 评估CPU对软硬中断的响应处理能力  一段时间内的中断分布情况，CPU响应时间，需要动态追踪  多长时间响应中断 多长时间处理完中断 如何分配，如何均衡处理        内存资源使用   硬件\n 总线宽度/内存读写速度/内存颗粒主频  dmidecode获取主板信息 内存带宽测试      内存资源使用情况\n  评估系统的内存分配能力\n  系统自身需要的内存\n page entry slab/vma小内存块 值得具体了解 通过内核代码对各种分配函数进行统计，分配大小、位置和目的    最多能分配多少内存给某个资源\n 分配socket memory  据说系统在已有大规模socket的情况下，对其分配内存的策略是惰性的，待查   分配page cache/page buffer  cache的使用，cache的重复使用 swap内存      内存换页率和脏页情况\n /proc/meminfo等 swap in和swap out sar -B 1中的主缺页中断和次缺页中断    采用huge page的性能影响\n      磁盘读写能力   硬件\n 磁盘类型/转速 查看kernel能够tuning的选项  磁盘块IO大小 调度策略      评估磁盘IO性能\n  评估不同读写文件方式的性能\n 直接读写文件性能 经过文件系统读写速度    评估读小文件时的性能\n 读大文件速度  较大文件的读取效率，考验IO能力   读小文件速度  大量小文件      评估文件缓存对磁盘性能的影响\n 首次读  可测试文件从磁盘读到kernel内存直到用户进程这一过程  微观角度，systemtap等脚本动态追踪     非首次读  测试文件在缓存中后的读效率  文件系统缓存命中率        评估不同调度策略对磁盘性能的影响\n 场景：  不同策略适应不同场景   方法：  写随机文件内容，记录参数 bio调度队列的大小 输入输出能力  iostat iotop          网卡吞吐能力   硬件\n 千兆/万兆 多队列 网卡缓冲区大小    查看kernel能够tuning的选项\n ethtool、网卡硬件信息和优化技术 网卡驱动的缓冲队列    评估linux server的网络性能\n  评估网络子系统的吞吐量\n 场景：  测试网卡吞吐能力   方法：  少量TCP连接，发起大规模数据传输 网络压测工具netperf/iperf，或者写代码调整 测试过程中调整sysctl配置、网卡驱动、网卡硬件配置 检测工具：tcpdump/sar等工具 统计socket缓冲大小 在局域网内两台设备间执行      评估网络子系统的响应能力\n 场景：  在网络子系统繁忙时，对外服务的响应能力   方法:  采用iperf等工具发起大量tcp连接，发出巨量小包 检测工具，tcpdump/wireshark统计服务质量 systemtap分析软中断响应时间 统计TCP状态分布情况 统计内存分配情况        内核本身  管道 IPC性能 unix domain socket性能  参考链接  context switch definition 查询本机CPU相关信息 海量小文件 单机负载评估、性能分析 性能评估 Linux性能优化\u0026ndash;CPU  参考该post前我也想到了CPU压测的几个关注点：待调度执行任务数、CPU负载和进程切换 该post有很大启发   SAR的一些使用 Linux磁盘调度策略 其实没想到卖VPS的写性能测试挺专业 coolshell的性能调优攻略 linux下网络环境性能测试  Intel CPU 5300U的cache测试 L1 cache: 32768 bytes 1.50 nanoseconds 64 linesize 7.95 parallelism L2 cache: 2097152 bytes 8.50 nanoseconds 64 linesize 4.90 parallelism L3 cache: 4194304 bytes 21.73 nanoseconds 128 linesize 4.76 parallelism L4 cache: 33554432 bytes 33.48 nanoseconds 64 linesize 3.76 parallelism Memory latency: 857.39 nanoseconds 6.18 parallelism\n而dmidecode -t cache的输出结果是\nL1 32KB L2 256KB L3 3072KB\n","date":"2016-10-30T17:59:45+08:00","permalink":"https://bg2bkk.github.io/p/macrobench/","title":"macrobench"},{"content":" 数据在CPU、内存、网络、文件系统和磁盘之间的传输  带宽 时延    lmbench与其他benchmark工具不一样的地方   IO(disk)\n IOstone  侧重于压测内存子系统的速度   IObench  侧重于测量子系统：文件系统和磁盘的性能，这样会比较复杂且笨重   另一篇论文  看到很多IO性能测试历程，有不足：运行时间长、对于简单问题提出的解决方案太复杂   lmbench  lmdd  测试顺序IO和随机IO，运行速度快 Chen和Patterson通过不同大小的数据量测试系统IO性能，而我们更偏向于在单个请求中的CPU消耗，较少关注测试中系统整体性能        Berkeley Software Distribution\u0026rsquo;s miscrobench suite\n BSD出品一个可扩展的benchmark，用于BSD系统的回归测试，包括质量和性能。 我们没有用它作为出发点(借鉴了观点)，原因是  缺乏某些测试，比如内存时延 有些测试太多，可能会使测试结果淹没在大量数据中 采用了BSD license      Ousterhout\u0026rsquo;s Operating System benchmark\n 提出一些测试用例  测试系统调用延迟 上下文切换时间 文件系统性能等   我们借鉴其idea作为工作基础，并在此之上进行扩展 干的漂亮，待翻译。    网络测试\n netperf测试网络带宽和时延，lmbench涵盖一个更小，复杂度较低的benchmark，打到同样效果 ttcp是应用广泛的benchmark，我们实现的版本在相同测试用例下，带宽差距小于2%，因此我们的测试用例是可信的    McCalpin\u0026rsquo;s Stream benchmark\n  总之\n 我们搞了一套自己的，因为我们想要一个简单、可移植的benchmakr，想准确全面的测量我们认为对今天计算机系统性能的关键点。 也借鉴了其他benchmark的idea。    benchmark注意事项   测试用例的大小问题\n 比如做内存复制测试内存速度，如果太小，会被缓存，这样侧出来的数据将比数据在内存中快10倍多；然而如果过大的话，数据可能会被换页到磁盘，这样又会造成速度过慢，从而让benchmark过程显得漫长无结果。 lmbench采用如下两个方式解决：  所有benchmakr使用循环的话都会被cache大小影响，所以循环同时增大数据量(2的倍数)直到到达最大值。这个结果可以打印出来，当benchmark不再符合cache长度的时候 benchmark确定系统内存足够。用一个小测试程序分配尽可能多的内存，然后清空这些内存，然后每次越过一页内存，计算每次结果。如果每次应用都需要ms级别时间，说明该页已经不在内存中了。然后测试程序从小的开始，然后干活直到有充足内存或者到达内存限制。      编译器的时间问题\n 所有benchmark工具都是-O级别编译优化的；除了计算时钟速度和上下文切换时间时不能用优化，以产生正确结果。 没有其他的优化选项，我们想从应用程序作者的角度观察性能问题。    多处理器相关\n 多处理器系统在做benchmark时和单处理器一样，没有区别。有些系统允许用户将程序绑定到某个CPU上，为了更好的重用cache。 我们benchmark时不会将程序绑定，因为这种方式与多处理器调度机制相悖。某些情况下，这个决定会导致一些有意思的结果。    计时相关\n 时钟分辨率  benchmark软件计算用时是通过调用gettimeofday()获取系统时钟的，在一些系统中这个接口的分辨率是10ms，而大部分测试用例耗时10ms到千ms，所以这个接口太耗时了。为补偿这个定时器，benchmark软件一般通过多次运行来评估，一般来说就是在循环里执行，如果循环体非常快的话就用循环展开的方式多执行几遍，最后求平均。   缓存  如果benchmark软件期待数据在暂存缓存中，那么benchmark就多运行几次，只有最后一次记录结果就行。 如果benchmakr不想测试cache性能，那就将数据大小设置的比cache大。比如，做bcopy测试时，采用复制8MB数据，这个值比当前计算机的二级缓存还大。   结果可变性  很多benchmark结果，比如context switch的性能测试，有一个趋势是，结果会有一定的跳动，可达30%之多。我们怀疑这是因为系统没有使用同一片物理内存，所以遇到了缓存冲突，换页等因素。所以我们多运行几次，选取最小的结果。 用户做benchmark时，应该成为该系统的唯一用户。      使用lmbench数据库\n  Bandwidth\n Memory bandwidth IPC bandwidth Cached I/O bandwidth    Latency measurements\n Memory read latency background Memory read latency Operating system entry Signal handling cost Process creation costs Context switching Interprocess communication latencies File system Latency Disk latency    Memory bandwidth\n 以前评测性能时首先看MFLOPS，但是现在CPU的浮点单元并不是瓶颈，反而将数据从内存中读出来计算是瓶颈 所以现在主要看的是内存的复制、读、写，通过不同大小的数据关心大规模内存传输    Cached I/O bandwidth\n 重用已缓存在文件系统cache的数据可能是内存瓶颈，所以我们通过 read 和 mmap两个接口来评估这类带宽，目的并不是测试磁盘IO带宽，而是测量在这一过程的CPU负载情况。 read接口将数据从内核文件系统缓存页中读到用户进程的内存里。传输时选择64KB作为块大小，可以将进入内核的开销降到最低。 bcopy和read的区别在于文件和虚拟内存系统的开销，大部分系统中，bcopy都会针对硬件有所优化，所以性能好一点。 read接口通过重读一个文件（一般8M大小，越过L2 缓存），以64KB为单位。每块buffer都会在用户进程中按integer相加。采用相加方式原因有两个：为了与mmap接口进行完全一致的对比，所以需要读到每一个数据；文件系统将数据写入内存的速度要比CPU读的快。我们想比较的是CPU将数据传输给应用程序的速度，而不是那种内存DMA的速度。 mmap接口提供了一个不需要复制数据就可以读文件缓存的方式，我们通过所有内存内容相加的方式使数据强制经过CPU路径。 案例比较    Latency measurements\n 时延是性能测试中经常被忽略的点，可能因为解决时延问题更难一点。lmbench的测试项中包括内存时延，操作系统入口开销，信号处理开销，进程创建开销，上下文切换的开销，ipc，文件系统和磁盘的时延    Memory read latency background 读取内存产生时延的背景\n  从内存时延的角度我们可以理解和解释其他时延的产生原理，比如上下文切换的时延的产生，因为首先要保存当前进程状态，然后载入下一个进程。然而内存时延难以准确测量，并且经常被误解。\n  读内存时延有诸多方面，内存芯片的时钟，处理器和内存的回路，从内存中首次加载数据，内存写回时延。\n  Memory chip cycle latency\n 内存芯片的时钟都是纳秒级的，比如1333MHz的内存；DRAM的工作方式需要60到100ns时间，让内存数据稳定读取，这个级别是读内存时内存芯片准备好数据所必须的。    pin-to-pin lantency\n 处理器和内存之间有总线，这个时间是处理器发出读操作后到达内存子系统的时延；尤其多插槽上的多根内存时，访问速度会更慢    laod-in-vacuum latency\n 系统总线空闲时，从内存读取数据到成功的时延，这个经常被认为是内存时延；考虑到有些cpu是非阻塞读取数据的，读数据时总线不停顿，所以感知到的时延要比实际时延小；然而压测时，由于大量读写，实际的时延又要比它大。       内存延时有多种定义\n 内存芯片的时钟  内存芯片本身的时钟，比如1333MHz内存芯片 DRAM等待数据稳定   处理器发出的读信号到达内存芯片的时间  处理器发出读数据的地址，经过系统总线和内存子系统，到达内存 内存往往分布在多根插槽，比单内存芯片时延要高   总线空闲时读取内存数据  处理器等待从内存中取数据的时间  这个时间通常是一种标称值，有些处理器取数据时并不等待和停顿，因此测量延时可能显得小于标称值 而压测时，由于突发读取导致cache miss，导致实际延时又比这个值大 因此采用这个值也不是那么合理     连续繁忙读内存数据  连续读内存时，每次load都会跟着一个load。 连续读可能会导致时延高于空闲读，有些系统会有\u0026quot;关键字优先\u0026quot;的机制，读取某个字时不等待整个cache line填充就把该line中的要读取数据喂给CPU，然而此时cache依然处于busy状态；如果此时再有第二次load，会因为当前cache busy而停顿等待。在UltraSPARC中空闲读和连续读的差异可达35%.      1 2 3  p = head; while(p-\u0026gt;p_next) p = p-\u0026gt;p_next;     back-to-back-load latency\n 上述代码就三句汇编，loop、load和jmp 300MHz的cpu可以在3个cycle中完成一次load，即10ns，然而实际上却执行了400ns，说明400ns都耗费在了停顿上，等待数据可用 所以从内存load数据非常慢，发生cache miss的话会停顿住；尤其在超标量计算机中，一次执行多个指令，但是停顿在load上，很浪费    cache预取\n stride小的话，预取数据具有较高的空间局部性，性能会高 stride大一点会好，但是大太多的话：  填充cache往往是原子操作，后续指令只能等待cache操作完成 cache只有一个操作入口，预取数据量太大的话可能包括很多用不着的数据，会妨碍其他正常的cache访问      ","date":"2016-10-26T10:34:31+08:00","permalink":"https://bg2bkk.github.io/p/lmbench-usenix/","title":"lmbench usenix"},{"content":"linux的进程切换 tips 2\nlinux的磁盘调度策略 1 2 3 pdf\n","date":"2016-10-24T19:15:59+08:00","permalink":"https://bg2bkk.github.io/p/linux_schedule_process_and_thread/","title":"Linux_schedule_process_and_thread"},{"content":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40  // struct file 结构体 include/linux/fs.h  struct file { union { struct llist_node\tfu_llist; struct rcu_head fu_rcuhead; } f_u; struct path\tf_path; struct inode\t*f_inode;\t/* cached value */ const struct file_operations\t*f_op; /* * Protects f_ep_links, f_flags. * Must not be taken from IRQ context. */ spinlock_t\tf_lock; atomic_long_t\tf_count; unsigned int f_flags; fmode_t\tf_mode; struct mutex\tf_pos_lock; loff_t\tf_pos; struct fown_struct\tf_owner; const struct cred\t*f_cred; struct file_ra_state\tf_ra; u64\tf_version; #ifdef CONFIG_SECURITY \tvoid\t*f_security; #endif \t/* needed for tty driver, and maybe others */ void\t*private_data; #ifdef CONFIG_EPOLL \t/* Used by fs/eventpoll.c to link all the hooks to this file */ struct list_head\tf_ep_links; struct list_head\tf_tfile_llink; #endif /* #ifdef CONFIG_EPOLL */\tstruct address_space\t*f_mapping; } __attribute__((aligned(4)));\t/* lest something weird decides that 2 is OK */   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226  // tcp_sock结构体 include/linux/tcp.h // 代表一条TCP连接  struct tcp_sock { /* inet_connection_sock has to be the first member of tcp_sock */ struct inet_connection_sock\tinet_conn; u16\ttcp_header_len;\t/* Bytes of tcp header to send\t*/ u16\tgso_segs;\t/* Max number of segs per GSO packet\t*/ /* *\tHeader prediction flags *\t0x5?10 \u0026lt;\u0026lt; 16 + snd_wnd in net byte order */ __be32\tpred_flags; /* *\tRFC793 variables by their proper names. This means you can *\tread the code and the spec side by side (and laugh ...) *\tSee RFC793 and RFC1122. The RFC writes these in capitals. */ u64\tbytes_received;\t/* RFC4898 tcpEStatsAppHCThruOctetsReceived * sum(delta(rcv_nxt)), or how many bytes * were acked. */ u32\tsegs_in;\t/* RFC4898 tcpEStatsPerfSegsIn * total number of segments in. */ u32\tdata_segs_in;\t/* RFC4898 tcpEStatsPerfDataSegsIn * total number of data segments in. */ u32\trcv_nxt;\t/* What we want to receive next */ u32\tcopied_seq;\t/* Head of yet unread data\t*/ u32\trcv_wup;\t/* rcv_nxt on last window update sent\t*/ u32\tsnd_nxt;\t/* Next sequence we send\t*/ u32\tsegs_out;\t/* RFC4898 tcpEStatsPerfSegsOut * The total number of segments sent. */ u32\tdata_segs_out;\t/* RFC4898 tcpEStatsPerfDataSegsOut * total number of data segments sent. */ u64\tbytes_acked;\t/* RFC4898 tcpEStatsAppHCThruOctetsAcked * sum(delta(snd_una)), or how many bytes * were acked. */ struct u64_stats_sync syncp; /* protects 64bit vars (cf tcp_get_info()) */ u32\tsnd_una;\t/* First byte we want an ack for\t*/ u32\tsnd_sml;\t/* Last byte of the most recently transmitted small packet */ u32\trcv_tstamp;\t/* timestamp of last received ACK (for keepalives) */ u32\tlsndtime;\t/* timestamp of last sent data packet (for restart window) */ u32\tlast_oow_ack_time; /* timestamp of last out-of-window ACK */ u32\ttsoffset;\t/* timestamp offset */ struct list_head tsq_node; /* anchor in tsq_tasklet.head list */ unsigned long\ttsq_flags; /* Data for direct copy to user */ struct { struct sk_buff_head\tprequeue; struct task_struct\t*task; struct msghdr\t*msg; int\tmemory; int\tlen; } ucopy; u32\tsnd_wl1;\t/* Sequence for window update\t*/ u32\tsnd_wnd;\t/* The window we expect to receive\t*/ u32\tmax_window;\t/* Maximal window ever seen from peer\t*/ u32\tmss_cache;\t/* Cached effective mss, not including SACKS */ u32\twindow_clamp;\t/* Maximal window to advertise\t*/ u32\trcv_ssthresh;\t/* Current window clamp\t*/ /* Information of the most recently (s)acked skb */ struct tcp_rack { struct skb_mstamp mstamp; /* (Re)sent time of the skb */ u8 advanced; /* mstamp advanced since last lost marking */ u8 reord; /* reordering detected */ } rack; u16\tadvmss;\t/* Advertised MSS\t*/ u8\tunused; u8\tnonagle : 4,/* Disable Nagle algorithm? */ thin_lto : 1,/* Use linear timeouts for thin streams */ thin_dupack : 1,/* Fast retransmit on first dupack */ repair : 1, frto : 1;/* F-RTO (RFC5682) activated in CA_Loss */ u8\trepair_queue; u8\tdo_early_retrans:1,/* Enable RFC5827 early-retransmit */ syn_data:1,\t/* SYN includes data */ syn_fastopen:1,\t/* SYN includes Fast Open option */ syn_fastopen_exp:1,/* SYN includes Fast Open exp. option */ syn_data_acked:1,/* data in SYN is acked by SYN-ACK */ save_syn:1,\t/* Save headers of SYN packet */ is_cwnd_limited:1;/* forward progress limited by snd_cwnd? */ u32\ttlp_high_seq;\t/* snd_nxt at the time of TLP retransmit. */ /* RTT measurement */ u32\tsrtt_us;\t/* smoothed round trip time \u0026lt;\u0026lt; 3 in usecs */ u32\tmdev_us;\t/* medium deviation\t*/ u32\tmdev_max_us;\t/* maximal mdev for the last rtt period\t*/ u32\trttvar_us;\t/* smoothed mdev_max\t*/ u32\trtt_seq;\t/* sequence number to update rttvar\t*/ struct rtt_meas { u32 rtt, ts;\t/* RTT in usec and sampling time in jiffies. */ } rtt_min[3]; u32\tpackets_out;\t/* Packets which are \u0026#34;in flight\u0026#34;\t*/ u32\tretrans_out;\t/* Retransmitted packets out\t*/ u32\tmax_packets_out; /* max packets_out in last window */ u32\tmax_packets_seq; /* right edge of max_packets_out flight */ u16\turg_data;\t/* Saved octet of OOB data and control flags */ u8\tecn_flags;\t/* ECN status bits.\t*/ u8\tkeepalive_probes; /* num of allowed keep alive probes\t*/ u32\treordering;\t/* Packet reordering metric.\t*/ u32\tsnd_up;\t/* Urgent pointer\t*/ /* * Options received (usually on last packet, some only on SYN packets). */ struct tcp_options_received rx_opt; /* *\tSlow start and congestion control (see also Nagle, and Karn \u0026amp; Partridge) */ u32\tsnd_ssthresh;\t/* Slow start size threshold\t*/ u32\tsnd_cwnd;\t/* Sending congestion window\t*/ u32\tsnd_cwnd_cnt;\t/* Linear increase counter\t*/ u32\tsnd_cwnd_clamp; /* Do not allow snd_cwnd to grow above this */ u32\tsnd_cwnd_used; u32\tsnd_cwnd_stamp; u32\tprior_cwnd;\t/* Congestion window at start of Recovery. */ u32\tprr_delivered;\t/* Number of newly delivered packets to * receiver in Recovery. */ u32\tprr_out;\t/* Total number of pkts sent during Recovery. */ u32\tdelivered;\t/* Total data packets delivered incl. rexmits */ u32\trcv_wnd;\t/* Current receiver window\t*/ u32\twrite_seq;\t/* Tail(+1) of data held in tcp send buffer */ u32\tnotsent_lowat;\t/* TCP_NOTSENT_LOWAT */ u32\tpushed_seq;\t/* Last pushed seq, required to talk to windows */ u32\tlost_out;\t/* Lost packets\t*/ u32\tsacked_out;\t/* SACK\u0026#39;d packets\t*/ u32\tfackets_out;\t/* FACK\u0026#39;d packets\t*/ /* from STCP, retrans queue hinting */ struct sk_buff* lost_skb_hint; struct sk_buff *retransmit_skb_hint; /* OOO segments go in this list. Note that socket lock must be held, * as we do not use sk_buff_head lock. */ struct sk_buff_head\tout_of_order_queue; /* SACKs data, these 2 need to be together (see tcp_options_write) */ struct tcp_sack_block duplicate_sack[1]; /* D-SACK block */ struct tcp_sack_block selective_acks[4]; /* The SACKS themselves*/ struct tcp_sack_block recv_sack_cache[4]; struct sk_buff *highest_sack; /* skb just after the highest * skb with SACKed bit set * (validity guaranteed only if * sacked_out \u0026gt; 0) */ int lost_cnt_hint; u32 retransmit_high;\t/* L-bits may be on up to this seqno */ u32\tprior_ssthresh; /* ssthresh saved at recovery start\t*/ u32\thigh_seq;\t/* snd_nxt at onset of congestion\t*/ u32\tretrans_stamp;\t/* Timestamp of the last retransmit, * also used in SYN-SENT to remember stamp of * the first SYN. */ u32\tundo_marker;\t/* snd_una upon a new recovery episode. */ int\tundo_retrans;\t/* number of undoable retransmissions. */ u32\ttotal_retrans;\t/* Total retransmits for entire connection */ u32\turg_seq;\t/* Seq of received urgent pointer */ unsigned int\tkeepalive_time;\t/* time before keep alive takes place */ unsigned int\tkeepalive_intvl; /* time interval between keep alive probes */ int\tlinger2; /* Receiver side RTT estimation */ struct { u32\trtt; u32\tseq; u32\ttime; } rcv_rtt_est; /* Receiver queue space */ struct { int\tspace; u32\tseq; u32\ttime; } rcvq_space; /* TCP-specific MTU probe information. */ struct { u32\tprobe_seq_start; u32\tprobe_seq_end; } mtu_probe; u32\tmtu_info; /* We received an ICMP_FRAG_NEEDED / ICMPV6_PKT_TOOBIG * while socket was owned by user. */ #ifdef CONFIG_TCP_MD5SIG /* TCP AF-Specific parts; only used by MD5 Signature support so far */ const struct tcp_sock_af_ops\t*af_specific; /* TCP MD5 Signature Option information */ struct tcp_md5sig_info\t__rcu *md5sig_info; #endif  /* TCP fastopen related information */ struct tcp_fastopen_request *fastopen_req; /* fastopen_rsk points to request_sock that resulted in this big * socket. Used to retransmit SYNACKs etc. */ struct request_sock *fastopen_rsk; u32\t*saved_syn; };   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239  // sk_buff 结构体 include/linux/skbuff.h // 表示一个socket报文  /** *\tstruct sk_buff - socket buffer *\t@next: Next buffer in list *\t@prev: Previous buffer in list *\t@tstamp: Time we arrived/left *\t@rbnode: RB tree node, alternative to next/prev for netem/tcp *\t@sk: Socket we are owned by *\t@dev: Device we arrived on/are leaving by *\t@cb: Control buffer. Free for use by every layer. Put private vars here *\t@_skb_refdst: destination entry (with norefcount bit) *\t@sp: the security path, used for xfrm *\t@len: Length of actual data *\t@data_len: Data length *\t@mac_len: Length of link layer header *\t@hdr_len: writable header length of cloned skb *\t@csum: Checksum (must include start/offset pair) *\t@csum_start: Offset from skb-\u0026gt;head where checksumming should start *\t@csum_offset: Offset from csum_start where checksum should be stored *\t@priority: Packet queueing priority *\t@ignore_df: allow local fragmentation *\t@cloned: Head may be cloned (check refcnt to be sure) *\t@ip_summed: Driver fed us an IP checksum *\t@nohdr: Payload reference only, must not modify header *\t@nfctinfo: Relationship of this skb to the connection *\t@pkt_type: Packet class *\t@fclone: skbuff clone status *\t@ipvs_property: skbuff is owned by ipvs *\t@peeked: this packet has been seen already, so stats have been *\tdone for it, don\u0026#39;t do them again *\t@nf_trace: netfilter packet trace flag *\t@protocol: Packet protocol from driver *\t@destructor: Destruct function *\t@nfct: Associated connection, if any *\t@nf_bridge: Saved data about a bridged frame - see br_netfilter.c *\t@skb_iif: ifindex of device we arrived on *\t@tc_index: Traffic control index *\t@tc_verd: traffic control verdict *\t@hash: the packet hash *\t@queue_mapping: Queue mapping for multiqueue devices *\t@xmit_more: More SKBs are pending for this queue *\t@ndisc_nodetype: router type (from link layer) *\t@ooo_okay: allow the mapping of a socket to a queue to be changed *\t@l4_hash: indicate hash is a canonical 4-tuple hash over transport *\tports. *\t@sw_hash: indicates hash was computed in software stack *\t@wifi_acked_valid: wifi_acked was set *\t@wifi_acked: whether frame was acked on wifi or not *\t@no_fcs: Request NIC to treat last 4 bytes as Ethernet FCS *\t@napi_id: id of the NAPI struct this skb came from *\t@secmark: security marking *\t@offload_fwd_mark: fwding offload mark *\t@mark: Generic packet mark *\t@vlan_proto: vlan encapsulation protocol *\t@vlan_tci: vlan tag control information *\t@inner_protocol: Protocol (encapsulation) *\t@inner_transport_header: Inner transport layer header (encapsulation) *\t@inner_network_header: Network layer header (encapsulation) *\t@inner_mac_header: Link layer header (encapsulation) *\t@transport_header: Transport layer header *\t@network_header: Network layer header *\t@mac_header: Link layer header *\t@tail: Tail pointer *\t@end: End pointer *\t@head: Head of buffer *\t@data: Data head pointer *\t@truesize: Buffer size *\t@users: User count - see {datagram,tcp}.c */ struct sk_buff { union { struct { /* These two members must be first. */ struct sk_buff\t*next; struct sk_buff\t*prev; union { ktime_t\ttstamp; struct skb_mstamp skb_mstamp; }; }; struct rb_node\trbnode; /* used in netem \u0026amp; tcp stack */ }; struct sock\t*sk; struct net_device\t*dev; /* * This is the control buffer. It is free to use for every * layer. Please put your private variables there. If you * want to keep them across layers you have to do a skb_clone() * first. This is owned by whoever has the skb queued ATM. */ char\tcb[48] __aligned(8); unsigned long\t_skb_refdst; void\t(*destructor)(struct sk_buff *skb); #ifdef CONFIG_XFRM \tstruct\tsec_path\t*sp; #endif #if defined(CONFIG_NF_CONNTRACK) || defined(CONFIG_NF_CONNTRACK_MODULE) \tstruct nf_conntrack\t*nfct; #endif #if IS_ENABLED(CONFIG_BRIDGE_NETFILTER) \tstruct nf_bridge_info\t*nf_bridge; #endif \tunsigned int\tlen, data_len; __u16\tmac_len, hdr_len; /* Following fields are _not_ copied in __copy_skb_header() * Note that queue_mapping is here mostly to fill a hole. */ kmemcheck_bitfield_begin(flags1); __u16\tqueue_mapping; __u8\tcloned:1, nohdr:1, fclone:2, peeked:1, head_frag:1, xmit_more:1; /* one bit hole */ kmemcheck_bitfield_end(flags1); /* fields enclosed in headers_start/headers_end are copied * using a single memcpy() in __copy_skb_header() */ /* private: */ __u32\theaders_start[0]; /* public: */ /* if you move pkt_type around you also must adapt those constants */ #ifdef __BIG_ENDIAN_BITFIELD #define PKT_TYPE_MAX\t(7 \u0026lt;\u0026lt; 5) #else #define PKT_TYPE_MAX\t7 #endif #define PKT_TYPE_OFFSET()\toffsetof(struct sk_buff, __pkt_type_offset)  __u8\t__pkt_type_offset[0]; __u8\tpkt_type:3; __u8\tpfmemalloc:1; __u8\tignore_df:1; __u8\tnfctinfo:3; __u8\tnf_trace:1; __u8\tip_summed:2; __u8\tooo_okay:1; __u8\tl4_hash:1; __u8\tsw_hash:1; __u8\twifi_acked_valid:1; __u8\twifi_acked:1; __u8\tno_fcs:1; /* Indicates the inner headers are valid in the skbuff. */ __u8\tencapsulation:1; __u8\tencap_hdr_csum:1; __u8\tcsum_valid:1; __u8\tcsum_complete_sw:1; __u8\tcsum_level:2; __u8\tcsum_bad:1; #ifdef CONFIG_IPV6_NDISC_NODETYPE \t__u8\tndisc_nodetype:2; #endif \t__u8\tipvs_property:1; __u8\tinner_protocol_type:1; __u8\tremcsum_offload:1; /* 3 or 5 bit hole */ #ifdef CONFIG_NET_SCHED \t__u16\ttc_index;\t/* traffic control index */ #ifdef CONFIG_NET_CLS_ACT \t__u16\ttc_verd;\t/* traffic control verdict */ #endif #endif  union { __wsum\tcsum; struct { __u16\tcsum_start; __u16\tcsum_offset; }; }; __u32\tpriority; int\tskb_iif; __u32\thash; __be16\tvlan_proto; __u16\tvlan_tci; #if defined(CONFIG_NET_RX_BUSY_POLL) || defined(CONFIG_XPS) \tunion { unsigned int\tnapi_id; unsigned int\tsender_cpu; }; #endif \tunion { #ifdef CONFIG_NETWORK_SECMARK \t__u32\tsecmark; #endif #ifdef CONFIG_NET_SWITCHDEV \t__u32\toffload_fwd_mark; #endif \t}; union { __u32\tmark; __u32\treserved_tailroom; }; union { __be16\tinner_protocol; __u8\tinner_ipproto; }; __u16\tinner_transport_header; __u16\tinner_network_header; __u16\tinner_mac_header; __be16\tprotocol; __u16\ttransport_header; __u16\tnetwork_header; __u16\tmac_header; /* private: */ __u32\theaders_end[0]; /* public: */ /* These elements must be at the end, see alloc_skb() for details. */ sk_buff_data_t\ttail; sk_buff_data_t\tend; unsigned char\t*head, *data; unsigned int\ttruesize; atomic_t\tusers; };   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  // socket 结构体, include/linux/net.h  /** * struct socket - general BSD socket * @state: socket state (%SS_CONNECTED, etc) * @type: socket type (%SOCK_STREAM, etc) * @flags: socket flags (%SOCK_NOSPACE, etc) * @ops: protocol specific socket operations * @file: File back pointer for gc * @sk: internal networking protocol agnostic socket representation * @wq: wait queue for several uses */ struct socket { socket_state\tstate; kmemcheck_bitfield_begin(type); short\ttype; kmemcheck_bitfield_end(type); unsigned long\tflags; struct socket_wq __rcu\t*wq; struct file\t*file; struct sock\t*sk; const struct proto_ops\t*ops; };   ","date":"2016-10-23T19:33:48+08:00","permalink":"https://bg2bkk.github.io/p/struct_file_socket_tcp_sock/","title":"struct_file_socket_tcp_sock"},{"content":"给你一台服务器，怎样能够全面评估它的性能？需要测试哪些指标？请写出每个指标的具体测试原理和测试代码。假设这台服务器完全处于线下。\n这个问题看似平常，但是细细审题的话，发现还是不一样的。我们过多关注线上机器的性能，但是如果单独拿出来一台服务器，它的性能怎样呢？\n评估和压榨一台服务器性能的话，找到评估的指标，然后进行压测加观察的方式，得到性能参数。\n 观察哪些指标，意义何在？ 如何观察这些指标，测试原理，观测工具/统计代码 如何进行压测，实现测试场景，压测工具/压测代码  bench可以分类为macro bench和micro bench;对于macro bench，很多时候我们得到的是一个整体而粗略的结果，通过top我们可以看到系统负载，这些对于我们定位线上问题，分析应用程序的性能热点很有帮助，然而这并不能精确衡量一台Linux Server的性能；应用程序多种多样，线上系统目的各不相同，所以macro bench一般用于case by case的性能分析，用于解决应用的性能瓶颈；而micro bench可以定量的分析一台机器+操作系统的性能，采用相同的测试基准，通过无干扰的大量重复基本操作，比如从L1 Cache读取单个字节，耗时一个CPU时钟，在大量重复中得到较为宏观的结果，再排除loop损耗、取运行时间的损耗，可以用于基本衡量一台server的运行效率。\n1 2 3 4 5 6 7  ./bin/x86_64-linux-gnu/enough 结果为n=322229, u=5172，执行322229次 TEN( p = *p )， TEN(T)表示循环展开执行10次任务T，可使loop开销对单次执行结果的影响降低1/10； 总共用时5172000ns，单次平均0.623ns；CPU主频1999.830MHz，折合一个cycle 0.500ns，数据基本可信。   提升性能主要是把CPU喂饱，所有的性能都是从CPU的角度来衡量；内存读写快慢，单纯比较数据从内存的一个位置移动到另一个位置，这是设备厂商用来做广告用的，不是计算机系统来评估性能的；把数据从内存读到CPU，然后写到另一个地址，数据流经过CPU即是经过了计算机系统，测量这段时间才是有意义的。以数据流动为基础，其他的bench，比如pipe的性能，需要排除数据流动的时间，排除loop等时间，才是单纯pipe的带宽性能；比如context switch速度，在做bench时，需要用pipe来驱动切换进程，这里需要排除掉数据流动的时间，pipe通信的时间，其余开销时间，才是context switch的时间。\n性能评估主要对CPU、memory、disk IO和network IO四个指标，从带宽和时延两个角度评估。\n所谓带宽，不仅仅是硬件上的读写速度，而是数据从源头到达CPU，然后CPU将其送往目的地的速度，考验的是传输能力；所谓时延，更多的评估传输的效率，读取一定量的数据，数据可以在多长时间内从内存读取到CPU。\n所谓时延，其实也是另一种意义的速度，比如context switch，并没有吞吐量这个概念，但是通过将多个进程切换N次，得到总体时间，平均后可以获得单次切换用时，用以评估context switch的latency。\n测试前的准备 很多很重要的选项，比如设计测试场景，从逻辑上说通一个测试中都包含哪些时间开销，如何测量\n  测量数据块大小\n 测量从内存经过CPU拷贝到另一块内存时，如果数据量过小，比如32KB，可能这个数据只在最次L2 Cache中流动，那么测量结果将会比真实数据大；如果数据量过大，又有可能被从内存换到磁盘上 为此的应对方法是，在循环中逐渐增大一倍数据量，列出不同数据量大小的测试数据，我们其实可以分辨出哪些是L1 Cache，哪些是Cache已经失效，因为他们之间的速度差异是巨大的；另外，当我们每次跨过一页访问该页内存，如果访问时间需要好几个us，那么说明这个内存页不在内存中    测量时间\n 不论用多么精确的时钟，由于benchmark时单次任务执行时间都非常短，因此用多次loop中求整体运行时间，取平均后能够得到误差较小的结果。 lmbench的时间机制写的很精妙，比如针对不同的任务，在每次bench的时候，都会预估执行当前任务执行比如500000us，需要执行多少次，这就是需要loop的次数；比较精妙，能够照顾到即使是相同计算机，在负载不一样的时候，对不同任务有一定的适应能力，在运行足够时间后使得系统表现稳定，得到稳定的结果；使用lmbench对相同任务做bench的时候，每次执行结果的误差都不大，低于2%，这个结果我想还是很稳定的。    考虑多进程，以及编译器可能导致的问题\n 测试时运行的benchmark也都比较小，其实可以视为和单处理器没有区别；或者我们可以将进程绑定到某个CPU上。 用gcc编译benchmark，优化级别为 -O，可以避免优化过度；注意一些load指令，如果load结果没有被用到的话，可能会被优化掉    带宽性能测试   Memory: 数据从内存到CPU的带宽\n rd  单次读取512Byte数据，即128个int整数，并做相加操作以防止编译器优化；循环展开，而非在for中挨个相加 use_int(sum)等指令也是防止编译器优化的 每次读取512Byte，直到读完，算是一次读取完成 如果rd的数据块太小，比如32MB，很快被读完，这时需要调整连续循环读取iterations次，然后求平均；iterations的取值取决于根据系统负载情况，实时计算需要执行的次数。 我的CPU是至强E5-2620，包含632KB的8路组相连数据L1缓存，6256KB的8路组相连L2,15MB的20路共享L3cache 根据读取的数据块大小，我们可以逻辑上推断该数据处于哪级缓存；本机的L1/L2/L3分别为192kb/1536kb/15360kb，  数据块16KB，带宽34999.46MB/s 数据块32KB，带宽19191.28MB/s 数据块320KB，带宽10669.75MB/s 数据块8MB，带宽6394.37MB/s 数据块16MB，带宽4993.96MB/s 数据块1024MB，带宽4979.76MB/s  纯内存带宽       wr  向内存块每一个4字节写入1   rdwr  wr与rd的结合，性能略差      pipe：系统提供的IPC机制的带宽\n 测量方式：父子进程阻塞读写pipe    mmap方式读取文件：从磁盘文件读取数据的带宽\n mmap方式读取文件，首先要打开文件，然后通过mmap将fd映射到匿名内存页，mmap的内存页在读取时才会真正分配 测量方式：  一、多次循环中，open、mmap，然后读取内容，最后close 二、在测量前open文件，并进行mmap；在多次循环中，每次读取目标大小的文件数据； 前者可以得到通过读取文件数据时，mmap的纯开销；后者更贴近实际情况   测量结果  读取1024m数据；测试采用-C标志，复制文件后再进行，可以以冷数据的方式避开文件缓存 结果一：3223.58 MB/s 结果二：7948.87 MB/s      read方式读取文件：从磁盘文件读取数据的带宽\n 测量方式  一、以及包含open、read和close的带宽 二、测试单纯读文件(read)的带宽，   测量结果  读取1024m数据；测试采用-C标志，复制文件后再进行，可以以冷数据的方式避开文件缓存 一、5526.29 MB/s 二、5442.29 MB/s      注：带宽测试中使用的计算机为 至强E5-2620；之后机器收回，我采用我的一台闲置笔记本Thinkpad X220进行时延性能测试，CPU为 i5-2520M\n  时延性能测试 计算机所有的时延几乎都跟memory时延有关，做context switch时首先要store当前进程状态，然后load下一个进程。可以说准确测量计算机内存时延是评估其他时延的前提，虽然内存时延的准确测量不太容易。\n计算机系统中存在的时延主要有内存访问时延、调用操作系统组件如读写文件和系统调用等、进程创建的时延，以及进程切换导致的上下文切换时延。\n内存延时   定义:\n 刨去硬件相关的内存芯片和系统总线时延外，从总线和内存空闲时读数据，和连续读数据这两种场景的差异值得探讨。 总线空闲时读取内存数据  处理器等待从内存中取数据的时间  这个时间通常是一种标称值，有些处理器取数据时并不等待和停顿，因此测量延时可能显得小于标称值 而压测时，由于突发读取导致cache miss，导致实际延时又比这个值大 因此采用这个值也不是那么合理     连续繁忙读内存数据  连续读内存时，每次load都会跟着一个load。 连续读可能会导致时延高于空闲读，有些系统会有\u0026quot;关键字优先\u0026quot;的机制，读取某个字时不等待整个cache line填充就把该line中的要读取数据喂给CPU，然而此时cache依然处于busy状态；如果此时再有第二次load，会因为当前cache busy而停顿等待。在UltraSPARC中空闲读和连续读的差异可达35%.   所以lmbench采用的是测试连续读时的内存时延，一来连续读的测量比空闲读容易些，二来连续读更贴近实际情况。由于处理器速度很快，即使发生cache miss，引起的load latency也和连续读更接近。    测量原理\n 采用不同内存大小、不同读取跨度stride来评估、探测系统的各级内存：L1、L2、L3以及主存的时延 读取内存，每跨读一步，如果跨度很小，比如64B/128B小于Cache line，那么时延会很小，如果跨度很大，比如1M，可能就需要从主存中将该地址内容读出，时延会相应增大 每次测量前先通过分配一块内存将cache内容全部替换掉 与bw_mem不同的是，并不读取数据块，而是通过地址链表跨stride去访问内存，以此测试内存时延，可见目的和测试bandwidth不一样  地址链表的实现方式是，比如512KB的内存块buf，编址从0开始，以512 Byte为一跳 buf = 0x77889900, buf + 512 = 0x77889b00 *buf = 0x77889b00，即用内存块存放下一跳地址，这个时候 buf = 0x77889900, *(long *)buf = 0x77889b00, buf[0] = 0x00, buf[1] = 0x9b等等 这个地址链表非常高效，因为我们不关心buf存放内容，所以就利用buf的空间来存储下一跳地址；类似于如下代码   对一块内存进行跨行访问，依次采用不同大小内存和不同跨度，比如size=32KB，stride=512B，根据访问次数64次，和用时time，可以得出该次访问用时为time/64. 对于L1 Cache 32KB，L2 Cache 256KB和L3 Cache 3072KB来说，通过内存大小可以限定访问主要集中在哪级Cache，控制stride降低各级Cache miss，可以推断出访问时间。    1 2 3 4 5 6 7 8  char *buf = (char *)malloc(sizeof(char ) * 1024); memset(buf, 0, 1024); *(char **)\u0026amp;(buf[0]) = (char *)\u0026amp;(buf[512]); printf(\u0026#34;%p\\t%p\\n\u0026#34;, buf, buf + 512); char **p = (char *)\u0026amp;buf[0]; printf(\u0026#34;%p\\t%p\\n\u0026#34;, p, *p);    测量结果  测量结果如下图所示，原图见，原始数据见文件    图例： 横轴读取的内存块大小，从4KB到8MB，横轴以0.5MB为单位 纵轴是load平均延迟，单位为ns，从1ns到50ns 不同颜色的线表示不同的Stride，即每次读内存时跨越的数据长度 系统L1 Cache 32KB、L2 Cache 256KB、L3 Cache 3072KB getconf命令可以获取系统的必要信息，包括各级Cache   intel CPU的各级缓存latency的官方数据和其他解释  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  Core i7 Xeon 5500 Series Data Source Latency (approximate) L1 CACHE hit, ~4 cycles L2 CACHE hit, ~10 cycles L3 CACHE hit, line unshared ~40 cycles L3 CACHE hit, shared line in another core ~65 cycles L3 CACHE hit, modified in another core ~75 cycles remote L3 CACHE ~100-300 cycles Local Dram ~60 ns Remote Dram ~100 ns   对于测量各级Cache的latency来说，需要对每级进行特定分析。 L1 Cache Latency 对于intel i5-2520M来说，L1 Cache的32KB容量，cache line长64B，8路组相连，每路4KB大小，有64组cache line供选择；在不考虑其他因素的情况下，每32KB连续数据中一定会产生L1 miss，每4KB连续数据一定会有一次组内选择哪路cache line存储数据，可能产生cache miss；一旦产生cache miss，会进行L2乃至下一级的读取，造成时延加大，影响L1 cache的latency测量。因此为了避免cache miss带来的影响，在测量L1时尽量采用小步长，小内存块进行逼近，得到尽可能精确的L1 Cache的latency。\nL2 Cache Latency 对于L2 Cache来说，所用内存块和步长应该加大，尽量使L1 Cache失效，访问L2；也应该注意步长不能过大，造成L2 失效；所采用的内存块大小倒不是关键，因为即使再大的内存块也需要按照步长读取\nL3 Cache Latency L3 Cache的latency反而难以测量，原因一是L3可能是多核共享的，容易受干扰，二是相比L1/L2和DRAM的性能差异，L3与DRAM的访问差异显得不那么大。此外，TLB的因素也应该考虑在内。\n拜读完CacheMemory.pdf的第一章后，发现自己考虑的太少了，所以以上的测量方法其实只能说明一个大概，并不能极具说服力的得出时延数据就是L1 Latency。\nTODO   measure cache line measure tlb  tlb和cache区别   lwn IBM关于lmbench对mem latency的深度benchmark stackoverflow_1 stackoverflow_2 读内存过程  CPU读数据的一系列过程 What Your Computer Dos While You Wait 译文 intel: Cache相关的问题    调用系统组件（系统调用） 调用操作系统的入口，一般指系统调用，比如读写设备的read/write，比如getpid()或getimeofday()。\n对于前者的bench，选择操作/dev/null设备，每次写一个字，一般为4字节，经历了用户进程发起系统调用、转入内核态、查询文件描述符、VFS层等一整个过程，测量这个过程的时间；选择该设备的原因是所有操作系统都没有对该设备进行优化\n而后者，系统调用比如getpid、gettimeofday，各平台不同优化，甚至是实现在用户层，不过在Linux上仍然是实现在内核态的。所以可以通过getpid()了解基本开销，通过写/dev/null设备了解整体开销。\n 原理：  在循环中调用getpid()和write(fd, *buf, 1)   结果：  getpid  Simple syscall: 0.0540 microseconds   write to /dev/null  Simple write: 0.0897 microseconds      信号处理耗时   建立信号sigaction耗时\n 测量原理：  在本进程内部，调用sigaction建立信号 time = sig_installation   测量结果：  Signal handler installation: 0.1492 microseconds      发送信号耗时 kill(pid, sig)\n 测量原理：  设置不捕获信号，进程内向自己发送信号，kill(pid_self, SIGUSR1) time = sig_send   测量结果：  0.1240 microseconds      捕获并处理信号耗时\n 测量原理：  设置捕获信号，向自己发送信号，kill(pid_self, SIGUSR1) sig_handle = total_time - sig_installation - sig_send   测量结果：  Signal handler overhead: 0.9763 microseconds      捕获信号耗时：\n 测量原理：  在bench进程中以只读方式mmap一段内存，如果试图写这块内存，则会一直触发SIGBUS和SIGSEGV信号 在触发信号前设置SIGBUS和SIGSEGV的处理函数，在处理函数中不执行任务，只动态调整捕获次数；捕获次数达到一定数量时，评估单次处理用时 由于重复捕获信号，并且信号处理函数里基本没有任务，可以认为这段时间是捕获信号耗时，或者说是信号传递耗时   测量结果:  Protection fault: 0.4928 microseconds      补充：\n 由于第三项与第四项采用不相同的测试场景测量，前三项是一个场景，进程设置信号捕获，并向自身发送信号，然后捕获处理，第四项是产生page fault后重复触发信号，bench程序统计捕获次数和耗时计算得来。    创建进程开销 进程相关的benchmark主要是衡量几个进程原语：创建新进程、执行新的程序以及上下文切换。\n 创建进程的开销：fork process  测量原理：  通过fork创建子进程，子进程直接执行exit退出；所以最后测量的时间是：fork() + exit()  其实这里的开销还包括了父进程调用wait系统调用和父子进程上下文切换的开销，前者在本机50ns、后者在本机1.93us，相对进程创建来说非常小     测量结果：  Process fork+exit: 107.1001 microseconds     创建进程并执行新程序的开销：fork + execlp  测量原理：  不光测量fork的时间开销，还要通过execlp系统调用加载新程序/tmp/hello，打印一条hello world信息   测量结果：  Process fork+execve: 372.2349 microseconds      上下文切换的开销   上下文切换会受到多个因素影响：切换进程数量、每个进程自身的内存大小，以及Cache在其中的影响\n  测量结果：\n  intel的超线程技术 CPU的超线程机制通过复制、分区和共享 Intel NetBurst 微结构管道中的资源，使得一个物理处理器能包含两个逻辑处理器。逻辑处理器有自己的处理器状态、指令指针、重命名逻辑以及一些较小的资源，共享的资源有乱序执行引擎和高速缓存。超线程机制HT利用各资源的速度差异，在时间上并行模拟出两份计算资源，理论上讲提供多一倍的计算能力，而代价是，既然涉及到共享，那么在一些操作中会因为共享和竞争而有性能损耗。下表是超线程对Linux API的影响，采用lmbench测试结果，这份bench报表在运行有linux-2.4.19内核的Intel Xeon处理器上，主频1.60GHz。\n我认为上表中，ht没有影响的API是一些lmbench单进程可以测试的项，比如read、write等，而ht有影响的选项，比如管道延迟、进程fork+exit等，是lmbench需要发起多个进程进行bench，这些进程在逻辑处理器间有竞争，导致性能有些下降。从报表中可以看到，开启ht的bench结果在有些项目中耗时加长，但是比较小，但是整个系统获得了一倍的计算资源。\nintel的turbo技术 linux的睿频工具可以实时看到CPU的运行频率\n1  sudo i7z   以笔记本CPU i5-2520M 为例，在CPU空闲时主频低至\n1 2 3  Core [core-id] :Actual Freq (Mult.) C0% Halt(C1)% C3 % C6 % Temp VCore Core 1 [0]: 1366.96 (13.72x) 24.9 81.6 4.69 0 62 1.1008 Core 2 [2]: 1381.01 (13.86x) 23.3 79.2 7.89 0 62 1.1008   甚至更低\n运行lmbench时，CPU满载，主频可达\n1 2 3  Core [core-id] :Actual Freq (Mult.) C0% Halt(C1)% C3 % C6 % Temp VCore Core 1 [0]: 2989.17 (30.00x) 16.9 73.4 6.37 0 69 1.1409 Core 2 [2]: 3050.32 (30.61x) 99.1 0 0 0 73 1.1409   可见睿频的主要作用是动态调整CPU主频适应处理任务，当我们运行lmbench时，理所应当的CPU将会满载运行，所以计算CPU主频时完全不用担心睿频导致的频率变化，总是接近最高值的。\nlmbench测试框架  fork出child进程，作为bench执行体；parent作为控制体； parent和child通过pipe互相通信，child通知parent准备好，parent通知child开始，child执行完毕后通知parent完成；parent取完执行结果，通知child结束。 应用程序中child首先执行init程序，将准备工作做好；比如如果是bw_mem中的cp benchmark，需要首先分配好src内存块，然后分配dst内存块，准备好后即返回，init结束； init结束后，benchmp框架进行下一步，while循环中执行benchmark进入warmup状态 child执行benchmark是以状态机方式实现的  首先是warmup状态，在该状态中childparent发送ready信号，阻塞等待parent的start信号。child收到start后，状态设置为timing_interval，取iterations为1，执行benchmark程序；执行完后重入while循环； 然后切换到timing_interval状态。由于之前在warmup状态执行以iterations为1的benchmark，重入循环时满足state-\u0026gt;need_warmup == 0，所以开始统计上一次benchmark开始到现在的用时，并刨去t_overload和l_overload；进入状态机的timing_interval状态，该状态评估本次benchmark的用时是否符合期望，如果符合，将本次bench结果记录，并设置状态为cooldown；如果不符合期望，分情况，如果用时result小于150，说明单次benchmark用时太短，需要多次迭代得到总结果，因此将iterations扩大8倍去计算；如果用时大于150，说明单次benchmark执行时间是够的，但是需要微调迭代次数，按照 enough * 1.1 / (iterations / result)；所以说timing_interval状态是用来在bench过程中微调迭代次数以使执行时间符合预期的过程。 在cooldown状态，child阻塞等待取结果信号，并将结果写回response管道中；执行清理函数后，得到parent发出的exit信号，结束自己。   最终结果存储在全局变量iterations和stop_tv中，其实是通过get_time()和get_n()，以及set_time()/save_n()或者set_results()中，并在用户程序的结束时进行计算。  ","date":"2016-10-23T16:43:44+08:00","permalink":"https://bg2bkk.github.io/p/%E6%80%8E%E6%A0%B7%E5%B0%BD%E5%8F%AF%E8%83%BD%E5%85%A8%E9%9D%A2%E7%9A%84%E8%AF%84%E4%BC%B0%E4%B8%80%E5%8F%B0%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%E6%80%A7%E8%83%BD/","title":"怎样尽可能全面的评估一台服务器的性能"},{"content":"理解TCP/IP协议栈 实现网络应用  遇到好文章我就想给翻译下来，觉得写的很好，现在cubrid的一篇TCP/IP相关的文章详细介绍了TCP协议栈，以及收发数据包的流程，非常有启发意义，所以我就想翻译一下，做个记录。将TCP/IP协议栈在一篇文章内讲明白是不可能的，所以本文能够做到的是讲清楚TCP/IP协议栈收发数据包的流程，我们要做的是首先了解大致流程，然后尝试根据TCP/IP协议和拿着代码去理解。由于我本人能力十分有限，译文都是我个人理解，所以会有大量错误，希望您能帮我纠正。如果您想转载，我必须提醒一句我这个译文是自己学习之用，并未取得版权方同意，因此首先做免责声明。\n 我们不能想象没有TCP/IP，互联网服务将会是何种情况。所有我们开发和使用的Internet服务都基于一个坚实的基础：TCP/IP。理解数据如何在网络中传输可以帮助你通过优化和调试的方式来提升程序性能，引入和使用新的技术。\n本文将通过在linux操作系统和硬件层面的数据流和控制流来描述网络技术栈的整体执行流程。\nTCP/IP的关键字 我如何设计网络协议，能够在保持数据不丢失不乱序的情况下，快速传输数据？\nTCP/IP协议为这些考虑而设计，如下是理解TCP/IP协议栈需要了解的关键字\n确切的说，TCP和IP是两个不同的层，理应分开描述；不过惯例上一直将他俩合成一个概念来讲   CONNECTIONI-ORIENTED，面向连接的  首先通信双方需要建立一条连接，一条TCP连接的标识符是local IP address, local port number和remote IP address, remote port number组成的四元组   BIDIRECTIONAL BYTE STREAM, 双向数据流传输  使用字节流实现双向传输   IN-ORDER DELIVERY，顺序发送  接收方按照数据从发送方发送的顺序接收；采用32bit整型作为数据包的序号，以实现顺序传输   RELIABILITY THROUGH ACK，通过ACK实现可靠性  当发送方发送数据后，没有收到接收方传来的该包的ACK，发送方将重新发送该数据。因此，发送方的TCP需要将未被ACK的数据缓存起来。   FLOW CONTROL，流控  发送方都想尽可能的发送数据给接收方，但是对端也得能够有能力接收，因此接收方要发送自己能够接收的最大数据量给发送方知道，最终发送方发出数据量由接收方的接收窗口决定。   CONGESTION CONTROL，拥塞控制  拥塞窗口是除接收窗口之外的另一个通过限制在途数据流大小以防止网络拥塞的方法。发送方尽可能多的发出拥塞窗口允许的数据量，该窗口大小有诸多方法可以实现，Vegas、Westwood、BIC或者CUBIC。不同于流控中的接收窗口，拥塞窗口是由发送方单独确定的。    数据发送 如下图所示，一个网络栈有很多层，图中包含各层类型。\n图中虽然有多层，但可以简要分为3类：\n User area 用户区 Kernel area 内核区 Device area 设备区  在user area和kerne area处理的任务都是由CPU完成的，所以user area和kernel area统称为host来与device area加以区分。在这里的device是Network Interface Card(NIC)，也就是网卡，用于收发数据，NIC是一个比我们常用的\u0026quot;局域网网卡\u0026quot;更准确的术语。\n让我们大致看看user area，首先应用程序准备好数据(右上角的user data灰色框)，然后调用***write()***系统调用发送数据。假设所用的socket(图中write调用的参数fd)合法，那么当发起系统调用后，发送流程切换到kernel area。\nPOSIX系列操作系统例如Linux和Unix在应用程序通过一个file descriptor，即文件描述符fd来表示所用的socket。在POSIX系系统中，socket也是一种文件，应用程序使用的fd在进程中有其对应的file structure，与socket对应（file-\u0026gt;private_data指向对应的struct socket，此处不影响理解），图1中的文件层进行简单的检查(VFS对write()的权限检查)，然后通过调用socket的相关函数最终实现write()。\n内核中每个socket有两个buffer：\n 一个是send socket buffer，发送缓冲区，用于发送 一个是receive socket buffer，接收缓冲区，用于接收  当write系统调用被调用时，待发送数据从用户空间复制到内核内存中，然后添加进发送缓冲区的链表末尾。这样就可以按顺序发出数据。图一中的\u0026rsquo;Sockets\u0026rsquo;那层对应的右边灰色的小格子指向socket send buffer中的数据。然后，调用TCP/IP协议栈。\n每个tcp类型的socket都有一个***TCP Control Block(TCB)***tcp控制块的数据结构，TCB包括了一个TCP连接所需要的成员，比如connection state连接状态(LISTEN, ESTABLISHED, TIME_WAIT等)、receive window接收窗口，congestion window拥塞窗口、sequence number包序号和resending timer重传定时器等。可以认为一个TCB 代表一条TCP连接。\n如果当前TCP状态允许数据传输，会新建一个新的TCP segment(packet，报文)；否则系统调用结束并返回错误码。\n下图是一个TCP报文，包括两个TCP片段：TCP header和Payload，如图2所示\npayload部分是待发送的数据，处于socket的未确认(unACK)发送缓冲区，每个包的payload的最大长度由对方接收窗口大小、拥塞窗口大小和maximum segment size（MSS，最大报文长度）共同决定。\n然后计算packet的checksum校验码，实际上，checksum计算目前由NIC用硬件实现，放在这里只是为了逻辑通顺。\n然后TCP报文进入下一层IP层处理，IP层添加IP头部和checksum，并进行IP路由选择。IP路由选择是选择下一跳的过程。当IP层计算并添加IP头部校验checksum后，将数据包发送到下一层Ethernet层，即数据链路层。Ethernet层采用ARP协议搜索查询下一跳IP的MAC地址，然后向报文添加Ethernet头部。添加完Ethernet头部后，host部分的报文就处理完毕了。\n在IP路由选择执行完毕后，根据结果选择哪个NIC作为传输接口；在host处理完报文后，调用NIC驱动发送数据。（一定要注意，NIC和NIC驱动不是一体的，前者是NIC网卡硬件，后者是运行在host和内核的驱动程序，硬件是CPU）\n此时，如果一个抓包软件比如tcpdump或者wireshark正在运行，kernel将报文从内核态复制一份到这些软件内存中。同样的，如果是抓接收到的包，也同样是从NIC驱动这里抓取的。一般来说，流量整形工具也是在这一层实现的。\nNIC驱动程序通过厂商制定的网卡与主机的通信协议向NIC请求发送packet。\nNIC收到发送网络包请求后，将报文复制到自己的内存中然后发送到网络。发送前，为遵守以太网标准，还要修改一些标志，包括packet的CRC校验码，IFG（Inter-Frame Gap）包内间隔和报文头等标志；CRC校验码用于数据保真，其他二者用于区分其实包还是中间包（需要翻译调整）。数据包传输速度根据网络物理速度和以太网流控制条件来调整，一般取低值，并留有一定余量。\n当NIC发出一个数据包，NIC向CPU发出中断；每个中断有其自己的中断号，操作系统根据中断号调用对应的驱动程序处理中断，驱动的中断处理函数是NIC驱动在OS启动时注册中断回调函数；当中断发生时，OS调用中断服务程序，然后中断服务程序向OS返回发送完成的数据包（编号）。\n至此我们讨论了应用程序数据发送的流程，贯穿kernel和NIC设备。而且，即使没有应用程序的写请求，kernel可以调用TCP/IP协议栈直接发送数据包。例如，当收到一个ACK后并且得知对端接收窗口扩大，kernel将自动的把仍在发送缓存中的数据打包，直接发出。\n数据接收 现在我们看看数据的接收流程，当数据包到来的时候，网络栈是如何处理的，如图3所示。\n首先，NIC将数据包写入自身内存，检查该包是否CRC合法，然后将该包发送给host的内存，host的内存是NIC驱动事先向kernel申请的内存，用于接收数据包，当host分配成功，通过NIC驱动告诉NIC这块内存的地址和大小。如果NIC driver没有实现分配好内存，NIC收到数据包后会直接丢弃。\n当NIC将数据包写入到host的内存缓冲区后，NIC向host 操作系统发出中断信号。\n然后，NIC驱动来确认它是否可以处理这个新包，这个过程使用的是NIC和NIC驱动之间的通信协议。\n当驱动需要将数据包发送到上一层时，这个数据包必须被包装成OS可以理解的包格式。比如，linux上的sk_buff，BSD系列内核的mbuf结构，或者MS系统的NET_BUFFER_LIST结构。NIC驱动将封装后的数据包转给上层处理。\n链路层Ethernet层检查数据包是否合法，然后根据数据包头部的ethertype值选择上层网络协议。IPV4类型的值为0x0800。本层的工作就是去掉数据包的Ethernet头部，传送给上层IP层。\nIP层同样首先检查数据包合法性，采用检查IP头部的checksum字段的方式。在逻辑上进行IP路由选择，决定是否本机操作系统处理这个包，还是转发给另一个系统。如果本机处理数据包，那么IP层将根据IP头部的协议proto值选择上层传输层协议，比如TCP协议的proto值是6.本层的工作就是移除IP头部，发送给上层TCP层。\n同样的，TCP层检查数据包的checksum是否正确。之前说过，TCP的checksum也是由NIC计算得到的。（可以理解这些CRC校验的工作都是由NIC硬件实现的，如果硬件层没有校验通过，可以直接在网卡丢弃）\n然后开始采用IP:PORT四元组作为标志搜索这个数据包对应的TCP Control Block。找到TCP控制块后就找到了TCP连接，根据包协议处理数据包。如果是收到新数据，那么将其加入socket接收缓冲区中。根据TCP状态，协议栈发送TCP回复包（比如ACK包）。现在TCP/IP的接收数据流程完成了。\nsocket接收缓冲区的大小是TCP接收窗口大小。数据接收时，TCP接受窗口扩大时TCP的吞吐能力增大；在此之前，socket的缓冲区大小由应用程序或者操作系统配置来调整，而现在新的网络栈具有自动调整接受缓冲区大小的功能。\n当应用程序调用read系统调用时，从user area切换到kernel area，数据从socket的缓冲区复制到user area，然后从socket缓冲区中释放。然后调用TCP协议栈；因为socket缓冲区有了新的空间，所以TCP增大接受窗口；然后根据该连接的状态发送ACK包或者其他包比如RST。如果进行read系统调用时没有新数据包，那么read()就终止返回。\n网络栈进化方向 以上描述的网络栈各层的功能都是一些基本的功能。90年代早期的网络栈功能比以上描述的还少。不过，目前最新的网络栈的功能更加丰富，复杂度更高，这些新功能根据用途有如下分类：\n Packet Processing Procedure Manipulation, 控制修改包处理流程  类似于Netfilter(firewall, NAT)和流量控制。通过在数据包基本处理流程中插入用户代码可以实现不同功能。\n Protocol Performance, 协议性能提升  目的是在同样的网络质量情况下，提升吞吐量、降低时延，提高稳定性。多种拥塞控制算法和附加TCP功能比如SACK（选择确认）就是这类功能。通过协议提升性能在本文中不作重点讨论。\n Packet Processing Efficiency, 数据包处理效率  包处理效率相关的功能旨在提升每秒能够处理最大量的数据包，通过降低单机处理数据包的CPU时间、内存占用和内存访问次数。目前有多种降低系统时延的尝试，包括并行处理、头部预测、零拷贝、单一副本、免校验、TSO、LRO和RSS等。\n网络栈的控制流 现在我们可以从更细节的角度观察linux网络栈的内部流程。就像其他非网络栈的子系统，linux的网络站以事件驱动的方式，当网络事件发生时进行相应处理，也就是说网络栈内只有一个进程或者控制流处理运行（其实就是kernel）。上文的图1和图3表示数据包的简化版控制流，图4将显示更多细节。\n图4的控制流(1)中，应用程序通过系统调用比如read()和write()调用TCP/IP协议栈，在这里没有数据包的发送，需要经过协议栈传输。控制流(2)与控制流(1)的不同之处在于，它要求调用TCP后直接发送数据包，参考raw socket的用法。它创造一个数据包然后将该包发送到NIC驱动前的一个队列中，然后队列的实现方式决定何时将该包发送给NIC驱动。这其实就是linux中的队列方式(queue discipline, qdisc)，linux的流量控制功能就是操作这个队列实现的，默认的操作方式是FIFO，先进先出。通过使用其他队列控制方式，linux可以实现多种效果，比如人工控制丢包、包延迟和流量限制等等功能待查：同一个队列的不同控制方式discipline，还是多个队列。在控制流(1)和(2)中，应用程序的处理流程最终将调用NIC驱动。\n控制流(3)表示TCP用到的一些定时器，比如当TIME_WAIT定时器超时后，TCP协议栈将响应并删除超时的连接。\n与控制流(3)类似，(4)表示超时后TCP将处理一系列待处理的数据包。比如，当重传定时器超时后，未得ACK确认的包将被重传。\n控制流(3)和(4)显示定时器软中断的处理流程。\n当NIC驱动收到NIC中断，它将释放已传输完成的数据包。大部分情况下，NIC驱动的处理流程在这里就终止了。控制流(5)表示数据包在传输队列中累积，NIC驱动请求软中断，然后软中断处理函数从发送队列中将累积的数据包发送给NIC驱动（请结合(5)左边的黑线）。\n当NIC驱动收到中断并且发现一个新的数据包到来，它将请求软中断。处理接收数据包的软中断调用NIC驱动接收并将收到的数据包传给上层处理。在LInux中，如上描述的处理接受数据包的处理方式称为New API(NAPI)。NAPI与轮询类似，因为NIC驱动并不直接向上层发送数据，而是上层从NIC驱动中主动拿数据包，这段代码称为NAPI poll(NAPI轮询)。这里的实现方式有很多，比如NIC收到大量包时，就不会采用中断方式接收，而是改为轮询方式，总之实现比较精妙，值得看看\n控制流(6)显示TCP协议栈接受数据包的完整处理流程，控制流(7)表示请求额外数据包发送的过程比如ACK包？。控制流(5)、(6)、(7)都是由NIC发起中断，软中断服务程序处理NIC中断实现的。\n怎样处理中断然后接收数据包 中断处理是复杂的，毕竟你需要理解与接受数据包有关的各个环节。图5显示了中断处理流程图。\n想象下CPU 0正在执行应用程序，这个时候NIC收到一个数据包，向CPU 0产生一个中断。然后CPU执行内核中断处理程序。内核通过中断号调用中断处理程序，响应NIC驱动，然后NIC驱动释放已发送完成的数据包，然后调用napi_schedule()函数去准备接受数据包，该函数请求软中断并返回，此时NIC驱动的中断处理程序结束，控制权交回内核软中断处理程序。硬中断上下文执行完成后，软中断开始执行（这里是内核的tasklet或者work_queue了吧，处于中断上下文的话，只能是tasklet，涉及到阻塞方法，比如与NIC设备的通信，就需要wait_queue了），软硬中断上下文都是由同一个进程执行的（linux kernel）。不过，软硬中断的执行栈不一样，硬中断将会屏蔽硬件中断，软中断执行期间是不屏蔽的（老生常谈）。\n内核软中断程序处理napi_schedule()产生的softirq，调用net_rx_action()处理收到的数据包，这个函数调用驱动的poll()方法。poll()方法调用netif_receive_skb()方法收取所有数据包，然后将其逐层向上层传送。处理完以上软中断后，应用程序从断点继续执行，此时可以开始调用系统调用比如read读取数据。\n这就是CPU从收到硬中断到完成接收数据包的完整过程，Linux、BSD和MS Windows系统都是大同小异的。\n当你查看服务器CPU使用率时，有时你看到只有一个CPU在辛苦的执行软中断，这个现象我们上文描述的可以解释，只有CPU 0在响应网卡中断，使用多队列网卡、RSS和RPS（在软件层面模拟实现硬件的多队列网卡功能）可以解决这个问题，将软中断绑定到多个CPU上。\n相关数据结构 下文列出一些关键性的数据结构\nsk_buff structure 首先，sk_buff结构体或者skb结构体表示一个数据包，图6表示sk_buff结构体的主要部分。虽然sk_buff的功能越来越丰富，也越来越复杂，但图6足以说明sk_buff相关的通用方法。\nsk_buff包括数据包的Data部分和元数据部分 sk_buff直接包括数据包的数据部分，或者用指针指向它。在图6中，sk_buff结构体中的data成员指向一个skb_shared_info结构体的Ethernet到buffer成员之间的内存，而额外的数据由skb_shared_info的frags成员指向具体的内存页。\nsk_buff的一些基本信息，比如头部信息和包数据长度存在元数据区域(元数据待理解，初步认定是skb_shared_info)。如图6所示，链路层头部mac_header、网络层头部network_header和传输控制层头部transport_header都有对应的指针依次指向从元数据开始的地方。这种方式使得TCP协议处理更容易一些。\n如何添加或删除头部 当在网络协议栈各层处理时，数据包的头部将会被添加或者删除，此时采用指针来移动到不同层的header位置最为方便高效，比如如果要删除Ethernet头部，只需要将头部指针，即sk_buff的head成员指向上一层IP头部位置即可。\n怎样合并或者分解数据包 在向socket缓冲区高效添加或者删除数据包的数据量时，采用链表的方式最为方便。sk_buffer的next和prev指针成员的目的就是在此。\n快速分配或者释放内存 当创建一个packet时，一个sk_buff结构体要被分配，这里需要快速分配器。比如，如果数据在万兆网卡传输，那么每秒最多将超过百万包被分配和释放。\nTCP Control Block 第二，需要有一个结构体来表示一条TCP连接。此前，它被笼统的称为TCP控制块。Linux使用tcp_sock结构体表示TCP Control Block，如图7所示，你可以看到socket、tcp_socket和struct file之间的关系。\n当一个系统调用执行时，首先搜索进程的fd对应的struct file结构，对于类Uinx操作系统来说，一个socket、一个文件或者一个设备对于普通文件系统来说都抽象成struct file结构。因此，文件系统包括了基本信息，对于一个socket结构体来说，struct socket包含了与socket相关的信息，以及一个file指针，该socket结构体同样有一个struct sock类型的指针sk成员，struct sock可强制类型转换到struct tcp_sock（参考tcp_sk函数）。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  // socket 结构体, include/linux/net.h  /** * struct socket - general BSD socket * @state: socket state (%SS_CONNECTED, etc) * @type: socket type (%SOCK_STREAM, etc) * @flags: socket flags (%SOCK_NOSPACE, etc) * @ops: protocol specific socket operations * @file: File back pointer for gc * @sk: internal networking protocol agnostic socket representation * @wq: wait queue for several uses */ struct socket { socket_state\tstate; kmemcheck_bitfield_begin(type); short\ttype; kmemcheck_bitfield_end(type); unsigned long\tflags; struct socket_wq __rcu\t*wq; struct file\t*file; struct sock\t*sk; const struct proto_ops\t*ops; };   socket结构体指向的tcp_sock结构体除了支持TCP协议类型外还有别的比如sock，inet_sock等类型，这点可以视为某种意义上的多态。\n所有TCP协议的状态信息保存在tcp_sock结构体中，比如TCP的序号sequence number、接受窗口receive window、拥塞窗口和重传定时器等。\nsocket发送缓冲区和socket接收缓冲区都是tcp_sock的sk_buff链表；tcp_sock的dst_entry成员，存储IP路由选择结果，避免再次进行路由选择，dst_entry可以进行ARP结果的快速检索，比如对端MAC地址。dst_entry是路由表的一部分，由于路由表的复杂结构，所以不在本文讨论，总之记住dst_entry可用来选择传输本数据包的网络设备NIC，NIC就是dst_entry指向的net_device成员。\n因此，通过struct file我们可以很容易的找到与TCP连接的所有信息，只占用少量内存，几KB而已（有很多功能添加进来，所以这部分内存从过去到现在不断增长）。\n最后，我们看下TCP连接的查找表，这是一个用于查找所收到数据包对应的TCP连接的哈希表，索引通过数据包的IP:PORT四元组进行Jenkins哈希算法计算得到。选择这个算法的原因是考虑到防范对此哈希表的攻击（待查）。\n追踪代码：如何发送数据 我们通过追踪阅读Linux kernel源码来学习TCP/IP协议栈如何执行，通过常用的读数据和写数据来观察。\n首先，应用程序调用write()来实现数据发送\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  SYSCALL_DEFINE3(write, unsigned int, fd, const char __user *, buf, ...) { struct file *file; [...] file = fget_light(fd, \u0026amp;fput_needed); [...] ===\u0026gt; ret = filp-\u0026gt;f_op-\u0026gt;aio_write(\u0026amp;kiocb, \u0026amp;iov, 1, kiocb.ki_pos); struct file_operations { [...] ssize_t (*aio_read) (struct kiocb *, const struct iovec *, ...) ssize_t (*aio_write) (struct kiocb *, const struct iovec *, ...) [...] }; static const struct file_operations socket_file_ops = { [...] .aio_read = sock_aio_read, .aio_write = sock_aio_write, [...] };   当应用程序调用write()系统调用，内核在文件层执行write()，首先找到fd对应的struct file，然后调用file_operations中的aio_write()，它是一个函数指针，最终调用的是socket_file_ops的sock_aio_write()方法。kenerl中通过函数表的方式实现接口，这点十分常见，但是对于TCP的具体指向方式，可以以后详查(TODO LIST)。\n接下来是sock_aio_write()的具体调用过程。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34  static ssize_t sock_aio_write(struct kiocb *iocb, const struct iovec *iov, ..) { [...] struct socket *sock = file-\u0026gt;private_data; [...] ===\u0026gt; return sock-\u0026gt;ops-\u0026gt;sendmsg(iocb, sock, msg, size); struct socket { [...] struct file *file; struct sock *sk; const struct proto_ops *ops; }; const struct proto_ops inet_stream_ops = { .family = PF_INET, [...] .connect = inet_stream_connect, .accept = inet_accept, .listen = inet_listen, .sendmsg = tcp_sendmsg, .recvmsg = inet_recvmsg, [...] }; struct proto_ops { [...] int (*connect) (struct socket *sock, ...) int (*accept) (struct socket *sock, ...) int (*listen) (struct socket *sock, int len); int (*sendmsg) (struct kiocb *iocb, struct socket *sock, ...) int (*recvmsg) (struct kiocb *iocb, struct socket *sock, ...) [...] };   sock_aio_write()函数从struct file中获取struct socket，然后调用socket的sendmsg方法，sendmsg依然是个函数指针，指向的是struct socket中的proto_ops函数表的sendmsg，IPv4协议族的TCP类型的proto_ops操作表是inet_stream_ops，将sendmsg实现为tcp_sendmsg。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56  int tcp_sendmsg(struct kiocb *iocb, struct socket *sock, struct msghdr *msg, size_t size) { struct sock *sk = sock-\u0026gt;sk; struct iovec *iov; struct tcp_sock *tp = tcp_sk(sk); struct sk_buff *skb; [...] mss_now = tcp_send_mss(sk, \u0026amp;size_goal, flags); /* Ok commence sending. */ iovlen = msg-\u0026gt;msg_iovlen; iov = msg-\u0026gt;msg_iov; copied = 0; [...] while (--iovlen \u0026gt;= 0) { int seglen = iov-\u0026gt;iov_len; unsigned char __user *from = iov-\u0026gt;iov_base; iov++; while (seglen \u0026gt; 0) { int copy = 0; int max = size_goal; [...] skb = sk_stream_alloc_skb(sk, select_size(sk, sg), sk-\u0026gt;sk_allocation); if (!skb) goto wait_for_memory; /* * Check whether we can use HW checksum. */ if (sk-\u0026gt;sk_route_caps \u0026amp; NETIF_F_ALL_CSUM) skb-\u0026gt;ip_summed = CHECKSUM_PARTIAL; [...] skb_entail(sk, skb); [...] /* Where to copy to? */ if (skb_tailroom(skb) \u0026gt; 0) { /* We have some space in skb head. Superb! */ if (copy \u0026gt; skb_tailroom(skb)) copy = skb_tailroom(skb); if ((err = skb_add_data(skb, from, copy)) != 0) goto do_fault; [...] if (copied) tcp_push(sk, flags, mss_now, tp-\u0026gt;nonagle); [...] }   tcp_sendmsg()首先从参数struct socket *sock获取tcp_sock，即TCP Control Blcok，然后将应用程序请求发送的数据复制到socket的发送缓冲区中。当复制数据到sk_buff中前，首先获取socket的Maximum Segment Size(MSS，最大消息长度)，MSS代表一个TCP包可携带的最大数据量（当然如果支持TSO或者GSO的话可以大于MSS），然后创建数据包，即sk_stream_alloc_skb()函数创建一个新的sk_buff，返回skb，skb_entail()函数将新建的skb添加到socket的发送缓冲区中（前文提到该缓冲区是一个链表）。skb_add_data函数将应用程序的数据复制到skb的buffer中。所有的数据将在重复调用这一过程中复制完成。此时，socket的发送缓冲区将以链表形式组织起MSS大小的若干个sk_buff。最后，调用tcp_push()函数将可发送的数据以数据包的形式发送出去，实现write()掉用的完整流程。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  static inline void tcp_push(struct sock *sk, int flags, int mss_now, ...) [...] ===\u0026gt; static int tcp_write_xmit(struct sock *sk, unsigned int mss_now, ...) int nonagle, { struct tcp_sock *tp = tcp_sk(sk); struct sk_buff *skb; [...] while ((skb = tcp_send_head(sk))) { [...] cwnd_quota = tcp_cwnd_test(tp, skb); if (!cwnd_quota) break; if (unlikely(!tcp_snd_wnd_test(tp, skb, mss_now))) break; [...] if (unlikely(tcp_transmit_skb(sk, skb, 1, gfp))) break; /* Advance the send_head. This one is sent out. * This call will increment packets_out. */ tcp_event_new_data_sent(sk, skb); [...]   tcp_push()函数尽可能的将TCP允许发送的sk_buff按序号发送出去。首先调用tcp_send_head()函数获取发送缓冲区队列头的sk_buff，然后tcp_cwnd_test()和tcp_snd_wnd_test()函数用来检查拥塞窗口和接收窗口是否允许新的数据包发送，如果可以，调用tcp_transmit_skb()函数新建网络数据包，用于发送。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44  static int tcp_transmit_skb(struct sock *sk, struct sk_buff *skb,int clone_it, gfp_t gfp_mask) { const struct inet_connection_sock *icsk = inet_csk(sk); struct inet_sock *inet; struct tcp_sock *tp; [...] if (likely(clone_it)) { if (unlikely(skb_cloned(skb))) skb = pskb_copy(skb, gfp_mask); else skb = skb_clone(skb, gfp_mask); if (unlikely(!skb)) return -ENOBUFS; } [...] skb_push(skb, tcp_header_size); skb_reset_transport_header(skb); skb_set_owner_w(skb, sk); /* Build TCP header and checksum it. */ th = tcp_hdr(skb); th-\u0026gt;source = inet-\u0026gt;inet_sport; th-\u0026gt;dest = inet-\u0026gt;inet_dport; th-\u0026gt;seq = htonl(tcb-\u0026gt;seq); th-\u0026gt;ack_seq = htonl(tp-\u0026gt;rcv_nxt); [...] icsk-\u0026gt;icsk_af_ops-\u0026gt;send_check(sk, skb); [...] err = icsk-\u0026gt;icsk_af_ops-\u0026gt;queue_xmit(skb); if (likely(err \u0026lt;= 0)) return err; tcp_enter_cwr(sk, 1); return net_xmit_eval(err); }   tcp_transmit_skb()首先调用pskb_copy()创建待发送sk_buff的副本，仅复制sk_buff的元数据；然后调用skb_push()锁定tcp头部区域，然后填充头部字段，send_check()计算TCP头部的checksum。最后，queue_xmit()将数据包skb转移到下一层IP层，IPv4的queue_xmit指针指向函数ip_queue_xmit()。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46  int ip_queue_xmit(struct sk_buff *skb) { [...] rt = (struct rtable *)__sk_dst_check(sk, 0); [...] /* OK, we know where to send it, allocate and build IP header. */ skb_push(skb, sizeof(struct iphdr) + (opt ? opt-\u0026gt;optlen : 0)); skb_reset_network_header(skb); iph = ip_hdr(skb); *((__be16 *)iph) = htons((4 \u0026lt;\u0026lt; 12) | (5 \u0026lt;\u0026lt; 8) | (inet-\u0026gt;tos \u0026amp; 0xff)); if (ip_dont_fragment(sk, \u0026amp;rt-\u0026gt;dst) \u0026amp;\u0026amp; !skb-\u0026gt;local_df) iph-\u0026gt;frag_off = htons(IP_DF); else iph-\u0026gt;frag_off = 0; iph-\u0026gt;ttl = ip_select_ttl(inet, \u0026amp;rt-\u0026gt;dst); iph-\u0026gt;protocol = sk-\u0026gt;sk_protocol; iph-\u0026gt;saddr = rt-\u0026gt;rt_src; iph-\u0026gt;daddr = rt-\u0026gt;rt_dst; [...] res = ip_local_out(skb); [...] ===\u0026gt; int __ip_local_out(struct sk_buff *skb) [...] ip_send_check(iph); return nf_hook(NFPROTO_IPV4, NF_INET_LOCAL_OUT, skb, NULL,\tskb_dst(skb)-\u0026gt;dev, dst_output); [...] ===\u0026gt; int ip_output(struct sk_buff *skb) { struct net_device *dev = skb_dst(skb)-\u0026gt;dev; [...] skb-\u0026gt;dev = dev; skb-\u0026gt;protocol = htons(ETH_P_IP); return NF_HOOK_COND(NFPROTO_IPV4, NF_INET_POST_ROUTING, skb, NULL, dev, ip_finish_output, [...] ===\u0026gt; static int ip_finish_output(struct sk_buff *skb) { [...] if (skb-\u0026gt;len \u0026gt; ip_skb_dst_mtu(skb) \u0026amp;\u0026amp; !skb_is_gso(skb)) return ip_fragment(skb, ip_finish_output2); else return ip_finish_output2(skb);   ip_queue_xmit()方法负责执行IP层的任务，__sk_dst_check()检查缓存的路由结果是否合法。如果此时没有缓存的路由，或者缓存路由结果过期，就会进行IP路由查找。然后调用skb_push()锁定IP包头，填充IP包头部字段。接着调用ip_send_check()计算IP头的checksum，然后使用nf_hook调用netfilter模块，nf_hook()方法设置回调函数为dst_output，该函数被调用时，作为函数指针指向的是ip_output()函数。在ip_output()函数中，设置ip_finish_output()为回调函数，当发送数据包需要被分片发送时，进行分片，否则调用ip_finish_output2()，添加Ethernet Header，进入链路层Ethernet层。这样，一个数据包最终生成。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  int dev_queue_xmit(struct sk_buff *skb) [...] ===\u0026gt; static inline int __dev_xmit_skb(struct sk_buff *skb, struct Qdisc *q, ...) [...] if (...) { .... } else if ((q-\u0026gt;flags \u0026amp; TCQ_F_CAN_BYPASS) \u0026amp;\u0026amp; !qdisc_qlen(q) \u0026amp;\u0026amp; qdisc_run_begin(q)) { [...] if (sch_direct_xmit(skb, q, dev, txq, root_lock)) { [...] ===\u0026gt; int sch_direct_xmit(struct sk_buff *skb, struct Qdisc *q, ...) [...] HARD_TX_LOCK(dev, txq, smp_processor_id()); if (!netif_tx_queue_frozen_or_stopped(txq)) ret = dev_hard_start_xmit(skb, dev, txq); HARD_TX_UNLOCK(dev, txq); [...] } int dev_hard_start_xmit(struct sk_buff *skb, struct net_device *dev, ...) [...] if (!list_empty(\u0026amp;ptype_all)) dev_queue_xmit_nit(skb, dev); [...] rc = ops-\u0026gt;ndo_start_xmit(skb, dev); [...] }   上层最终生成数据包后，函数dev_queue_xmit()将数据包发送出去。首先，数据包以qdisc方式传递过去；如果采用默认数据包入队规则（FIFO）并且队列为空，sch_direct_xmit()函数将直接把数据包发送给网卡驱动，越过缓冲队列；该函数调用dev_hard_start_xmit()函数选择对应的驱动并发送。在调用网卡驱动前，设备的TX队列将被加锁，防止在多任务同时访问网络设备。由于kernel已经向设备的TX队列加锁，所以设备驱动的发送代码不需要额外加锁。这和接下来要讨论的并行处理紧密相关。\nndo_start_xmit()函数负责调用NIC驱动代码。在调用之前你可以看到ptype_all和dev_queue_xmit_nit()语句，ptype_all是一个包括处理模块的链表，比如抓包模块，如果一个抓包程序在运行中，这个数据包将被ptype_all复制给这个程序。所以，类似于tcpdump这类软件显示的数据包，其实是发送给网卡驱动的；响应的tcpdump显示收到的数据包也是从这层拿到的。此时数据包未携带checksum，或者如果此时TSO使能的话，NIC将会操作编辑这个包。所以tcpdump抓到的包和实际发到网络的包还是有一定区别的。当完成发送数据包后，网卡驱动的终端处理程序返回发送的sk_buff。\n追踪代码：如何接收数据 姑且认为接收代码的流程与发送代码区别不大，所以我们先进行下一部分。\nNIC和NIC驱动是怎样通信的 NIC和NIC驱动之间的通信属于网络栈的最底层，往往被人忽视。然而NIC目前在网络性能方面承担着越来越多的任务，了解基本的操作模式将帮你学习到更多。\n驱动和NIC之间是异步通信的。首先，NIC驱动请求发送一个数据包后，CPU转向执行其他任务，并不阻塞等待响应；然后NIC发送数据包，通知CPU；最后NIC驱动将发送完成的数据包返回给上层。与发送一样，数据接收也一样是异步的，首先，NIC驱动请求接收一个包，然后CPU转而执行其他任务，然后NIC收到包后，通知CPU，NIC驱动处理收到的包处理并返回（由之前图4所示，NIC驱动注册时会请求kernel提前分配好缓存收到数据包的内存，NIC接受指令将数据包写入这部分内存）。\n所以，有一个空间，用于存放请求和响应是很必要的。大部分NIC使用环状结构(ring structure)，环状结构与普通队列结构类似，有固定的容量，一个单位存储一个请求或者响应。使用时也是按序处理，区别在于到达队列末尾后重头开始，形成一个环。\n如图8所示的包发送流程图，我们可以看到ring是怎样工作的。\nNIC驱动收到上层发来的数据包后，创建NIC可以理解的发送描述符(send descriptor)，发送描述符包括包大小、物理地址等信息；NIC要求通过物理地址访问NIC驱动的内存，所以NIC驱动需要将包的虚拟地址转换为物理地址。然后NIC驱动将send descriptor加入到发送环状缓冲(Send TX Ring Buffer)，如图8的流程(1)所示。\n然后，NIC驱动通知NIC有新的发送请求，见流程(2)，NIC驱动直接将这个请求写入到NIC的内存地址中，在这里，CPU采用Programmed I/O(PIO)的方法，直接将数据写到设备（其实这里如果开发过Linux 设备驱动，比如以前开发过的 PCIE驱动就知道，将PCIE设备的配置寄存器映射到Host的内存空间中，kernel可以像访问自身内存一样读写这些地址，进而将控制指令写入设备中）。被通知的NIC从host的内存（发送环状内存缓冲区）以DMA方式获取发送描述符，见流程(3)。拿到发送描述符后，获得数据包在host内存的的物理地址和大小，然后将数据包以DMA方式读出。\nNIC取得发送数据包后，计算包的checksum然后加到数据包里，然后发送，见流程(5)。发送完成后，NIC将发送的数据包数量写回host内存(流程6)；然后向CPU发起中断(流程7)。NIC驱动独处发送了哪些数据包后，将数据包返回。(The NIC sends packets (5) and then writes the number of packets that are sent to the host memory (6). Then, it sends an interrupt (7). The driver reads the number of packets that are sent and then returns the packets that have been sent so far.)\n如图9所示，我们可以看到读取数据包流程图.\n首先，NIC驱动在host分配用于存储接收数据包和接收描述符的内存。接收描述符包括缓冲区大小和物理地址，与发送描述符一样都是物理地址，用于DMA传输。然后，NIC驱动将接收描述符添加到RX ring中(流程1)。通过PIO，NIC驱动将新的接收描述符地址写入NIC中(流程2)，NIC从Rx ring中以DMA方式获取接收描述符，获得用于接收数据包的缓冲区的大小和物理地址并存储(流程3)。\nNIC收到数据包后(流程4)，NIC将数据包写入实现分配好的host内存中(流程5),如果网卡有计算数据包checksum的功能，那么NIC此时计算数据包的checksum。接收数据包的大小、checksum和其他信息存储在另一个环状buffer(the receive return ring，接收返回环 )中(流程6)。接收返回环也存储NIC处理接收到数据包的结果，比如返回包。然后NIC发出中断(流程7)，NIC驱动从接收返回包中获取包的信息，然后处理数据包。如果必要的话，NIC驱动还会继续分配内存并重复流程(1)和(2).\n在调优网络栈的时候，大家都认为环状缓存大小和中断设置要互相匹配。当发送环状缓存Tx ring比较大时，可以一次发出较多请求；当Rx ring比较大时，可以一次收到较多数据包。大Ring buffer可以并发大量发送操作，提高工作能力；实际实现中，NIC使用一个定时器定期收集处理中断，减少CPU中断的次数，以免CPU为处理中断而分心。\n缓存和流控制 流控制是网络栈各层通力合作实现的。图10显示发送数据时网络栈的各级缓存。首先，应用程序创建数据，添加到socket发送缓存中，如果缓存没有内存可用，则send/write系统调用返回失败或者堵塞。因此，应用程序流向kernel的数据流速由socket缓冲区大小来限制。\nTCP协议栈创建和发送数据包，通过发送队列transmit queue(qdisc)向NIC驱动发送。这是个典型的FIFO队列，队列长度可以由ifconfig工具配置，执行ifconfig工具结果中的txqueuelen的值，一般为1000，意味着缓存1000个数据包。\n环状发送队列(TX ring)处于NIC驱动和NIC之间，正如上一章提到的，Tx ring可被认为是发送请求队列。如果Tx ring满，此时NIC驱动不能发出发送请求，那么待发送的数据包将会累积在TCP/IP协议栈和NIC驱动之间的qdisc中，如果累积数据包超过qdisc大小，那么再想发送新包，会被直接丢弃。\nNIC将待发送数据包存储在自身缓存中，包速率主要由NIC的物理速度决定。而且由于链路层Ethernet layer的流控制，如果NIC的接收缓冲区没有空间，那么发送数据包也将停止（可以猜测原因是自身停止发送后，对端将不会再发送数据包过来，有助于NIC和NIC驱动将拥塞在接受缓冲区的数据包处理完）。\n当发送自kernel的数据包速度大于发送自NIC的数据包速度时，包将拥堵在NIC的缓存中。如果NIC自身缓存没有多余空间，NIC将不会从Tx ring中去取发送请求request；这样的话，越来越多的发送请求累积在Tx ring中，最终Tx ring也堵满；此时NIC驱动再也不能发起新的发送请求，并且要发送的新包将堵塞在qdisc中；就这样，性能衰退从底向上传递。（感觉这里我们可以通过检测各级buffer的堵塞情况，判断程序堵塞在哪一步）\n图11显示接受数据包的传递过程。首先，收到的数据包将缓存在NIC自身缓存中。从流控制的角度来看，NIC和NIC驱动之间的Rx ring队列作为缓存，NIC驱动从Rx ring中将已接受数据包的请求取出，发给上层，在这里NIC驱动和协议栈之前没有缓冲区，因为这里是通过kernel调用NAPI去poll已收到的数据包的。(需要想想怎么翻译).这里可以认为上层直接从Rx ring中获取数据包。网络包的数据部分将上传缓存在socket的接收缓冲区中，应用程序随后从socket的接受缓冲区中读取数据。\nTo Be Continued ldd\n","date":"2016-10-20T22:21:55+08:00","permalink":"https://bg2bkk.github.io/p/understanding-tcpip-network-stack-writing-network-apps/","title":"Understanding TCPIP Network Stack \u0026 Writing Network Apps"},{"content":"学习cpp内存布局和虚函数表相关的内容时，图说C++对象模型：对象内存布局详解这篇文章很不错，学习到如何通过对象地址找到虚函数表并调用其中的虚函数，然后我遇到了一个有意思的点，在C++11标准下编译不通过，但是在之前的C++标准可以编译通过。具体如下：\n1 2 3 4 5  // p为对象  cout \u0026lt;\u0026lt; \u0026#34;虚函数表第一个函数的地址：\u0026#34; \u0026lt;\u0026lt; (void *)*((int*)(\u0026amp;p)) \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; \u0026#34;析构函数的地址:\u0026#34; \u0026lt;\u0026lt; (void* )*(int *)*((int*)(\u0026amp;p)) \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; \u0026#34;虚函数表中，第二个虚函数的地址：\u0026#34; \u0026lt;\u0026lt; ((void *)*(int*)(\u0026amp;p) + 1) \u0026lt;\u0026lt; endl;   1 2  // std=c++11编译不通过 cout \u0026lt;\u0026lt; \u0026#34;虚函数表第一个函数的地址：\u0026#34; \u0026lt;\u0026lt; (void *)*((void *)(\u0026amp;p)) \u0026lt;\u0026lt; endl;   代码\n","date":"2016-10-19T11:18:04+08:00","permalink":"https://bg2bkk.github.io/p/cpp%E7%B1%BB%E5%9E%8B%E8%BD%AC%E6%8D%A2%E4%B8%ADc-11%E6%A0%87%E5%87%86%E7%9A%84%E4%B8%8D%E5%90%8C/","title":"cpp类型转换中C++11标准的不同"},{"content":"","date":"2016-10-18T10:50:27+08:00","permalink":"https://bg2bkk.github.io/p/1pc-2pc-and-paxos%E7%AD%89%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0/","title":"1PC 2PC and Paxos等一致性算法学习"},{"content":"","date":"2016-10-17T11:21:06+08:00","permalink":"https://bg2bkk.github.io/p/linux_kernel%E4%B9%8B%E5%86%85%E6%A0%B8%E9%94%81%E7%9A%84%E4%BB%8B%E7%BB%8D/","title":"Linux_Kernel之内核锁的介绍"},{"content":" 详细  ","date":"2016-10-14T18:45:37+08:00","permalink":"https://bg2bkk.github.io/p/linux-kernel-%E4%B8%AD%E6%96%AD%E4%B8%8A%E5%8D%8A%E9%83%A8%E4%B8%8B%E5%8D%8A%E9%83%A8%E8%BD%AF%E4%B8%AD%E6%96%ADtasklist%E4%BB%A5%E5%8F%8Awork_queue/","title":"linux kernel 中断、上半部下半部、软中断、tasklist以及work_queue"},{"content":"  page cache 和 buffer cache\n  磁盘的块大小(Block Size)和扇区大小(Sector Size)\n 查看分区 /dev/sda1 的块大小  blockdev \u0026ndash;getbsz /dev/sda1 一般是4096，也就是4KB   查看硬盘的扇区大小  fdisk -l 可以查看，下表是512B      1 2 3 4  Disk /dev/sda1: 111.8 GiB, 120032591872 bytes, 234438656 sectors Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes   碎碎念   inode结构体中包含文件对应的磁盘快号\n  inode中包含对应的存储设备驱动\n  page buffer和page cache都是为了处理块设备和内存交互时高速访问的\n  page cache面向文件、面向内存，通过inode、address_space和page等数据结构，将一个文件映射到page级别，通过page+offset就可以定位到一个文件的具体位置。\n kernel抽象了address_space来作为文件系统和页缓存的中间适配器，屏蔽了底层设备的细节问题。    page buffer用在按块传输的场景\n  page cache和page buffer可以集成在一起，属于一个page的块缓存使用buffer_head链表组织起来，page cache维护一个private指针指向buffer_head链表\n  inode结构体包含文件的所有的block的块号，通过对文件偏移量offset取模可以定位出该偏移量的块号，然后是磁盘的扇区号；同时对offset取模可以算出其所在的页中的偏移量，\n  ","date":"2016-10-14T18:18:41+08:00","permalink":"https://bg2bkk.github.io/p/page-cache%E5%92%8Cbuffer-cache/","title":"page cache和buffer cache"},{"content":" futex初体验 阿里基础架构事业群的博客关于futex的文章 linux线程同步机制  Linux中的线程同步机制(二)–In Glibc  大部分的glibc的同步方式，mutex或者semaphore，大多基于futex的方式，首先进行用户态检查，未果的话进行futex系统调用。这是我疑惑为什么futex这么常用却在代码层面上看不到它，原因是我们使用的都是基于futex的机制   Linux中的线程同步机制(三)–Practice  pthread库中的pthread_join也是基于futex的哦，当父进程执行pthread_join它的某一个子线程时，如果子线程已经执行完毕，则父进程不会调用futex系统调用，如果子线程仍然执行中，那么父进程调用futex系统调用进行FUTEX_WAIT休眠，等待子线程的唤醒   好文章，值得深挖和思考   man page  先通过__sync_bool_compare_and_swap等原子操作比对futex的值是否有变化，如果没有，说明没有进程竞争。这里都是用户态执行的 如果有变化，说明有进程竞争了，所以这时系统调用futex进行FUTEX_WAIT，使得本进程休眠或休眠一段时间，直到有别的进程FUTEX_WAKE它 说白了，futex针对有些同步场景中，尽管没有竞争发生，但是还要陷入内核态去获得锁或者标志位然后同步的情况，futex可以仅通过原子性的内核态即可实现线程安全 提供futex_demo.c  如果将futex1和futex2互换下，画面太美不敢看，CPU暴涨100%      1 2 3 4 5 6 7  futex(0x7f99372d3004, FUTEX_WAIT, 0, NULL) = -1 EAGAIN (Resource temporarily unavailable) futex(0x7f99372d3004, FUTEX_WAIT, 0, NULL) = -1 EAGAIN (Resource temporarily unavailable) futex(0x7f99372d3004, FUTEX_WAIT, 0, NULL) = -1 EAGAIN (Resource temporarily unavailable) futex(0x7f99372d3004, FUTEX_WAIT, 0, NULL) = -1 EAGAIN (Resource temporarily unavailable) futex(0x7f99372d3004, FUTEX_WAIT, 0, NULL) = -1 EAGAIN (Resource temporarily unavailable) futex(0x7f99372d3004, FUTEX_WAIT, 0, NULL) = -1 EAGAIN (Resource temporarily unavailable) futex(0x7f99372d3004, FUTEX_WAIT, 0, NULL) = -1 EAGAIN (Resource temporarily unavailable)   ","date":"2016-10-13T13:57:31+08:00","permalink":"https://bg2bkk.github.io/p/futex%E5%92%8Clinux%E7%9A%84%E7%BA%BF%E7%A8%8B%E5%90%8C%E6%AD%A5%E6%9C%BA%E5%88%B6/","title":"futex和linux的线程同步机制"},{"content":"我们都知道实验新药的时候首先要在实验大鼠身上实行，有些时候我们发现，明明在大鼠身上具有良好功效的药品，在人身上的临床效果并不明显。我们此时可能会从鼠和人类的基因的区别、体质等方面找原因，这是受过基本科研训练的人会有的正常想法：控制变量法。其实我们可能忽略了一个点，那就是，实验大鼠从小生活在无菌环境下，而人并不是。实验大鼠在无菌环境下出生和长大，并不会遇到某些细菌，自然不会建立起免疫机制，可与之类比的大概是人类婴儿吧。科学家们通过对比实验大鼠和农场中生活的野鼠，确认野鼠体质与成年人类更为接近，因此在实验新药的时候会更倾向于使用农场大鼠。这个案例告诉我们，遇到问题时，我们一般会从受到过的训练中获取方法，快速反应去比对变量，但同时眼睛将固定于自己更想看到的部分，而没有跳出来看问题。在分析系统性能问题时，对某个瓶颈点百思不得其解时，这个时候是否可以把自己跳出来，多想想其他变量，甚至是其他更显得“弱智”的因素。\n有时候阅读一些技术文章时，会有这样一种感觉：这和理论不太一样啊。读林佩满的wireshark的书时，他分析过这样一个问题：某厂某个文件传输的产品在竞标时，发现大文件通过网络传输，从上海发往北京时很慢，需要很长时间才能将文件发送完成，而同时测试网速发现完全不是瓶颈，带宽利用率低到个位数；林在通过wireshark抓包时，发现有非常多的数据包被重传了多次，并且是毫无意义的重传；配管人员配置数据传送采用UDP方式，理论上讲不需要三次握手，且不需要发送确认的UDP传输更适合发送大文件，比如FTP协议就是基于UDP实现的，课本上都这么说。然而实际情况是，发送数据从上海到北京，会经过多多少少的中间结点，客户端发送较大的数据包，中途转发时，一些设备可能将大包拆成小包发送，对于UDP协议而言，如果最终小包里有一个包传输失败，那么需要将整个大包重传，而对于TCP协议而言，哪个小包没有收到，由于TCP头部的序号，客户端将只需要重传丢失的这个小包即可，避免了大量的无意义的重传；将传输方式改为TCP传输后，带宽利用率果然一下就上去了，这里我们的结论是远途传输大文件或大数据包时，TCP的性能由于UDP，这和课本上讲的很不一样。很多知识都不是一成不变的，会根据落地情况而调整、而改变，更有可能进化成不同形态。我想起前几天在火车上看到的一篇文章，城市里的灯光将会吸引虫子，趋光的虫子绕着灯泡一圈圈转，最后力竭饿死，这是个老知识了；而科学家经过实验，从城市和郊区抓取同样数量的飞虫，放在一个房间里观察，发现郊区的飞虫全部围绕着灯泡，而城市中的飞虫则有一小部分对灯光不感兴趣。科学家做出的结论是，城市中的飞虫有一部分进化出了不那么趋光的特性，基因得以保留。所以，我们看到，知识不是一成不变的，尽量做到不先入为主，从实际情况出发来分析问题。\n说到实际情况出发，与一个朋友聊epoll在实际使用中会遇到的一些问题，对于多进程（线程）程序而言，具有父子关系的两个进程共享一个epoll fd，A进程通过epoll_ctl将fd添加进epfd的监听fd列表中，如果有fd有事件发生，发生事件的fd有的是A添加的，有的是B添加的，如果此时唤醒的是B进程，B进程将该epfd监听的所有有事件发生的fd取出，进行处理时，遇到有些不是自己添加的fd时，这个fd对B进程而言是无效的，如果不做处理，去read或者write它，可能会导致core dump，当然，我还没有自己做实验验证，但是理论上讲，这是会发生的。\n在技术书之外，其实还有非常多的有趣的书，使人明事里、断情势，提升人的气质，这是一个大的范畴，我愿接下来一点点的分享我的读书感受。\n","date":"2016-09-18T19:43:59+08:00","permalink":"https://bg2bkk.github.io/p/%E4%B8%BA%E4%BB%80%E4%B9%88%E6%88%91%E5%96%9C%E6%AC%A2%E8%AF%BB%E4%B9%A6/","title":"为什么我喜欢读书"},{"content":"  toa, option字段，淘宝lvs，换成直连\n  x-real-ip的错误，线上的错误日志\n  https://imququ.com/post/x-forwarded-for-header-in-http.html\n  proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $remote_addr;\nnginx作为proxy server时，将remote_addr附加到x-real-ip或者x-forwarded-for头部字段中\n一般做法是在x-forwarded-for字段中添加remote_addr，nginx只用到后一句配置；阿里云和新浪的7层都是，所以从xff字段中获取用户ip比较靠谱\n1 2 3 4 5  curl http://t1.imququ.com/ -H \u0026#39;X-Forwarded-For: 1.1.1.1\u0026#39; -H \u0026#39;X-Real-IP: 2.2.2.2\u0026#39; remoteAddress: 127.0.0.1 x-forwarded-for: 1.1.1.1, 114.248.238.236 x-real-ip: 114.248.238.236   真正的转发，xff字段是逗号分隔的我去\n","date":"2016-09-08T17:06:19+08:00","permalink":"https://bg2bkk.github.io/p/ngx_lua%E8%8E%B7%E5%8F%96%E7%94%A8%E6%88%B7%E7%9C%9F%E5%AE%9Eip/","title":"ngx_lua获取用户真实ip"},{"content":"C++的原子类型atomic types提供了多种数据类型的原子类型，在学习《C++并发编程》时，我知道C++的互斥锁基于原子类型std::atomic_flag实现，而原子类型是基于其内存访问模型的。\natomic_flag是最简单的原子模型，表示一个布尔标志，只有两种状态：设置和清除；该类型的对象必须被ATOMIC_FLAG_INIT初始化，初始化状态是“清除”；使用该类型实现自旋互斥锁非常简单：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  class spinlock_mutex { std::atomic_flag flag; public: spinlock_mutex(): flag(ATOMIC_FLAG_INIT) {} void lock() { while(flag.test_and_set(std::memory_order_acquire)); } void unlock() { flag.clear(std::memory_order_release); } };   ","date":"2016-08-24T08:50:11+08:00","permalink":"https://bg2bkk.github.io/p/c-%E5%8E%9F%E5%AD%90%E7%B1%BB%E5%9E%8B%E5%8F%8A%E5%85%B6%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/","title":"C++原子类型及其内存模型"},{"content":"  http://stackoverflow.com/questions/27175281/epollrdhup-not-reliable\n  http://stackoverflow.com/questions/8707458/epoll-and-remote-1-way-shutdown\n  http://stackoverflow.com/questions/6437879/how-do-i-use-epollhup\n  http://unix8.net/home.php/linux%E4%B8%8Brst%E6%97%B6%E4%B8%8Eepoll%E7%9A%84epollhup%E4%BA%8B%E4%BB%B6.html\n  ","date":"2016-08-24T08:45:21+08:00","permalink":"https://bg2bkk.github.io/p/epoll%E7%9A%84%E4%B8%80%E4%BA%9B%E4%BD%BF%E7%94%A8%E5%BF%83%E5%BE%97/","title":"epoll的一些使用心得"},{"content":" setsockopt方式设置keepalive，可以设置空闲多长时间后开始发送探测报文； 原理是，一定时间空闲后，发送keepalive probe报文，如果对端回复ACK，那么可以认为该连接仍然有效；如果对端不回复，则认为该连接已经失效；这时对该连接进行读写操作，返回码-1，错误描述是timedout  那么现在的问题是，keepalive probe包是否也和其他普通tcp包一样，重传收不到ack的话，会根据tcp_retries1和tcp_retries2重传，这样的话，时间会很长吧\n上面那句的担忧是没有必要的，因为keepalive probe是一个必须被回应的报文，如果没有回复，那就报timedout错误\nrfc\n加入heartbeat机制，定期发送心跳包，从应用层保证联通  参考链接\nclose后，两端的行为\n读一个已经是RST状态的tcp，返回值-1，错误描述connection reset by peer\n关于如何处理RST包\n","date":"2016-08-24T00:01:05+08:00","permalink":"https://bg2bkk.github.io/p/%E6%A3%80%E6%B5%8Btcp%E8%BF%9E%E6%8E%A5%E6%98%AF%E5%90%A6%E6%96%AD%E5%BC%80/","title":"检测TCP连接是否断开"},{"content":"lamba学习  直观认识 cppreference 微软cpp function bind 和lambda的关系  static和const关键字各自的作用   static关键字\n 在函数体内声明的话，static变量只分配一次，作用域范围也在该函数体内；当下次调用该函数时，该值保持不变 模块内的static变量的作用域是模块内 类的static变量属于整个类，而不是某个对象，所有对象都共有这一份拷贝    const关键字\n 定义常量；首次定义必须初始化，之后不能赋值 函数声明时，用const修饰形参，可以保证不被函数体修改 可以修饰类的成员函数，保证其返回值不为“左值”    拷贝构造函数和赋值构造函数 C++的拷贝构造函数、重载赋值构造函数，以及析构函数，属于C++赋值控制的范畴\n如果没有手动实现，编译器会自动生成一个；编译器会自动生成以下四个成员函数\n   构造函数    析构函数    拷贝构造函数    赋值构造函数    1 2 3 4 5 6 7 8 9 10  class String { public: String(const char *);\t// 构造函数 \tString(const String \u0026amp;other);\t// 拷贝构造函数 \tString \u0026amp; operator=( const String \u0026amp;other); // 赋值构造函数 \t~String();\t// 析构函数 private: char *m_data; }   如果有手动实现，则会替代编译器的行为；除了析构函数，析构函数用于完成对象的释放操作，即使我们手动实现，编译器也会实现一份，这时析构函数可以让我们用来释放动态分配的内存.\n 拷贝构造函数  1 2 3 4 5  String::String(const String \u0026amp;other) { int len = strlen(other.m_data); m_data = new char[len + 1]; strcpy(m_data, other.m_data); }   * 如下几种情况下，拷贝构造函数被调用: * 1. 定义新对象，并用已有对象初始化新对象：即 String obj = other，或者 String obj(other)时，此时String(const String \u0026amp;other)被调用 * 2. 对象作为参数传递时，函数将建立对象的临时拷贝 * 3. 对象作为函数的返回值时，函数建立临时拷贝，并将其返回   赋值构造函数  1 2 3 4 5 6 7 8 9 10 11  String \u0026amp; operator=(const String \u0026amp;other) { if( this == \u0026amp;other) return *this; delete []m_data; int len = strlen(other.m_data); m_data = new char[len + 1]; strcpy(m_data, other.m_data); return *this; }   * 赋值构造函数的用法  1 2 3  String obj; obj = other;   * 拷贝构造函数  1 2  String obj = other; //或者 String obj(other);   而在前者的obj = other 和后者的String obj=other不同，前者表示obj是一个未初始化的对象，通过***=进行赋值，后者中的=***是使用other对obj进行初始化。\n在赋值构造函数中，***=缺省操作是将成员变量的值赋值，这时函数成员的旧值自然被丢弃，比如指针被赋予新值，旧值丢弃；然而指针旧值指向的内存却并未释放；因此包含动态分配成员的类提供拷贝构造函数外，还应该考虑重载=***赋值操作符\n抽象类与纯虚函数 纯虚函数是在基类中声明的虚函数，在基类中没有定义，声明方法是在函数原型后加***=0***，例如\n1  virtual void function() = 0;   纯虚函数要求基类的所有派生类都要定义自己的实现方法，除非派生类也是抽象类，因此纯虚函数主要功能是实现接口声明。至少含有一个纯虚函数的类被称为抽象类。\n基类的虚析构函数 在多态使用时，如果new一个子类对象，而用父类类型指针指向它来使用，delete父类类型指针的时候，只释放父类类型的资源，子类的虚构函数并不存在，导致资源不能及时释放。因此将父类的析构函数设置为虚函数，释放派生类对象时，链式调用析构函数，派生类析构函数先调用，父类的析构函数后调用。参考链接\n一句话，基类的析构函数设置为虚，可以在释放时链式释放子类对象内存，防止内存泄露。不过这个机制，还是无法释放类中的动态分配的内存，所以良好的编程习惯是不挖坑的基础。\n","date":"2016-08-23T19:52:25+08:00","permalink":"https://bg2bkk.github.io/p/c-%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%AD%A6%E4%B9%A0/","title":"C++基础知识学习"},{"content":"http://suda-morris.github.io/blog/2015/12/06/esp8266/\n  ESP8266 SDK官方使用指南\n  NodeMCU的ESP8266 SDK使用\n  NodeMcu碎碎念\n ESP8266 启动模式和管脚控制方法,二 ESP8266启动方式由三个管脚决定：[GPIO15, GPIO0, GPIO2]    1 2 3  001 – UART Download Mode (Programming) 011 – Flash Startup (Normal) 100 – SD-Card Boot     ESP乐鑫文档\n faq  软硬件看门狗 AT指令等      ESP重启原因\n  ESP8266 Arduino i2c\n  ","date":"2016-08-22T16:25:34+08:00","permalink":"https://bg2bkk.github.io/p/esp8266%E5%BC%80%E5%8F%91/","title":"esp8266开发"},{"content":" http://blog.csdn.net/jnu_simba/article/details/9068059  ","date":"2016-08-18T19:40:53+08:00","permalink":"https://bg2bkk.github.io/p/shutdown_vs_close_in_tcp/","title":"shutdown_vs_close_in_tcp"},{"content":"  redis客户端的两个buffer\n query buffer  相当于redis为客户提供的输入buffer，不论用户执行get，还是set，都会将命令和参数写到该buffer   output buffer  相当于redis为客户提供的输出buffer，所以对客户的输出，不论大还是小，都会写到该buffer然后输出      查询redis client属性\n redis命令：client list    1 2 3 4 5 6 7 8 9  10.13.112.54:6379\u0026gt; client list id=222464 addr=10.13.112.54:46957 fd=8 name= age=46008 idle=1 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=0 qbuf-free=0 obl=0 oll=0 omem=0 events=r cmd=expire id=222543 addr=10.13.112.54:34158 fd=7 name= age=41737 idle=0 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=0 qbuf-free=32768 obl=0 oll=0 omem=0 events=r cmd=select id=223496 addr=10.13.112.54:36934 fd=10 name= age=593 idle=2 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=0 qbuf-free=0 obl=0 oll=0 omem=0 events=r cmd=expire id=223514 addr=10.75.12.239:60522 fd=26 name= age=32 idle=32 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=0 qbuf-free=0 obl=0 oll=0 omem=0 events=r cmd=hincrby id=223505 addr=10.13.112.54:43949 fd=16 name= age=64 idle=64 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=0 qbuf-free=0 obl=0 oll=0 omem=0 events=r cmd=hincrby id=223506 addr=10.13.112.54:44754 fd=17 name= age=61 idle=61 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=0 qbuf-free=0 obl=0 oll=0 omem=0 events=r cmd=select id=223519 addr=172.16.193.186:32256 fd=31 name= age=22 idle=22 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=0 qbuf-free=0 obl=0 oll=0 omem=0 events=r cmd=hincrby id=223504 addr=172.16.193.186:40687 fd=15 name= age=68 idle=33 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=0 qbuf-free=0 obl=0 oll=0 omem=0 events=r cmd=hincrby     qbuf: query buffer 大小\n  qbuf-free: query free buffer 大小\n  obl: 定长 output buffer的使用字节数\n  oll: 可变 output buffer的对象个数\n  omem: 可变 output buffer的使用字节数\n  query buffer redis动态调整每个客户端的query buffer大小，范围0~1GB之间，当某个客户端query buffer使用超过1GB，redis会立刻关闭它，以防OOM\n query buffer的大小限制是硬编码的：  1 2 3  server.h#163 /* Protocol and I/O related defines */ #define PROTO_MAX_QUERYBUF_LEN (1024*1024*1024) /* 1GB max query buffer. */   query buffer大小不受maxmemory限制  文章中作者模拟100个客户端，连续写入500MB的Key，此时内存占用43GB，而maxmemory限制为4GB，因此这相当于是一个bug。 虽然maxmemory不能限制该buffer，但是该buffer大小却会计入maxmemory，此时会触发redis的LRU淘汰机制，或者无法写入    output buffer 客户端output buffer有两种：静态大小buffer和动态buffer\n 静态大小buffer  定长16KB，用于存储返回小结果   动态大小buffer  存储大的结果 redis提供配置动态output buffer的指令    1 2 3  client-output-buffer-limit normal 10mb 5mb 60\t配置普通客户端的output buffer大小，硬限制是10mb，软限制为5mb/持续60s client-output-buffer-limit slave 256mb 64mb 60\t配置redis从机的output buffer大小，硬限制是256mb，软限制为64mb/持续60s client-output-buffer-limit pubsub 32mb 8mb 60\t配置pub/sub客户端的output buffer大小，硬限制是32mb，软限制为8mb/持续60s   client-output-buffer-limit的解读是，如果buffer大小超过硬限制，redis立刻断开客户端；如果buffer大小超过软限制，并且持续时长超过60s，则redis断开客户端连接\n如果硬限制和软限制设置为0，则redis将不会主动断开，显然这是不安全的\nredis主动断开的设置，在设置timeout时，如果设置为0，也不会主动断开客户，而是等待客户主动断开\n由于每个客户端都会有大小不等的output buffer，所以当客户端总量很大时，占用内存也是非常客观的；因此开发时客户端应该节省使用redis，尽量使用小一点的key；限制slave的buffer大小，避免返回被杀；还有就是，如果监控redis发现 used memory 抖动严重，那么极有可能是client的大量来袭或者请求访问的动态变化导致。\n","date":"2016-08-18T11:51:16+08:00","permalink":"https://bg2bkk.github.io/p/redis-client-buffer/","title":"redis client buffer"},{"content":"饶琛琳(251562081) 19:53:00 哈哈。一个是es打开lucene索引的内存消耗较大，所以无法保存较长时间索引。现在是close掉，但是close状态的如果宕机是不会自动恢复的，如果连着挂就彻底废了。所以修改方向是钻研lucene源码，用很小的内存维护索引的打开状态，不用的信息只在真正查询到的时候才动态加载 饶琛琳(251562081) 19:54:52 另一个方向是利用snapshot API导出索引到HDFS上，但是不用restore回来查，而是针对es的snapshot格式开发一个hadoop的inputformat，可以直接在hdfs上查询 饶琛琳(251562081) 19:57:18 第三个是es目前各线程是抢cpu的，如果搜一个特别大的范围的结果，可能这一个请求就hang住整个集群其他所有任务，读写都死了，甚至节点掉线啥的。修改方向两种：利用cgroup机制限制每个search thread的资源占用；或者自动切分大请求成多个小请求。\n","date":"2016-08-17T20:00:25+08:00","permalink":"https://bg2bkk.github.io/p/%E4%B8%89%E6%96%97%E5%A4%A7%E7%A5%9E%E5%9C%A8es%E4%B8%8A%E7%9A%84%E4%B8%89%E4%B8%AA%E9%97%AE%E9%A2%98/","title":"三斗大神在es上的三个问题"},{"content":"ffmpeg和opencv是我的老朋友了，读研的时候犯轴，非要自己编译，每次编译好几个小时，在arm板子上。其实我需要的就是个库，先把应用写好，优化的事情可以以后再说，优先级不能变。因此现在我做应用，怎么省事怎么来，这是资源和时间的合理配置。能docker就都docker了，不能的话也要找apt-get，总之时间不能花费在编译这些库上，今天编译，下次还编译，这是很什么效率？\n树莓派是有opencv的apt-get软件包的，所以可以直接安装；ffmpeg麻烦点，不过也找到有人打包好的\n树莓派model 1B+上手，model 1B+是高于model 1低于model 2的奇葩版本，希望广大网民不要像我这样，买个奇葩的板子哈哈\n 树莓派3 上手  https://ubuntu-pi-flavour-maker.org/download/  镜像: ubuntu standard server 烧写方法      1 2 3 4  sudo apt-get install gddrescue unxz ubuntu-mate-16.04-desktop-armhf-raspberry-pi.img.xz sudo ddrescue -d -D --force ubuntu-mate-16.04-desktop-armhf-raspberry-pi.img /dev/sdx   \t* 初始账号密码：　ubuntu : ubuntu * [resize file system](https://ubuntu-pi-flavour-maker.org/faq/) * sudo fdisk /dev/mmcblk0 * Delete the second partition (d, 2) * recreate it using the defaults (n, p, 2, enter, enter), * 设置partition大小，默认，按enter即可 * write(w) and exit * reboot * resize2fs /dev/mmcblk0p2 * 国内源  1 2 3 4 5 6 7 8 9 10  # https://www.zhihu.com/question/26054875 deb http://mirrors.ustc.edu.cn/ubuntu-ports/ xenial-updates main restricted universe multiverse deb-src http://mirrors.ustc.edu.cn/ubuntu-ports/ xenial-updates main restricted universe multiverse deb http://mirrors.ustc.edu.cn/ubuntu-ports/ xenial-security main restricted universe multiverse deb-src http://mirrors.ustc.edu.cn/ubuntu-ports/ xenial-security main restricted universe multiverse deb http://mirrors.ustc.edu.cn/ubuntu-ports/ xenial-backports main restricted universe multiverse deb-src http://mirrors.ustc.edu.cn/ubuntu-ports/ xenial-backports main restricted universe multiverse deb http://mirrors.ustc.edu.cn/ubuntu-ports/ xenial main universe restricted deb-src http://mirrors.ustc.edu.cn/ubuntu-ports/ xenial main universe restricted   * [wifi设置](https://i.cmgine.net/archives/11053.html) * 软件安装 * wpasupplicant * wireless-tools * vim * libopencv* * ffmpeg  https://wiki.ubuntu.com/ARM/RaspberryPi\nhttps://i.cmgine.net/archives/11053.html\n","date":"2016-08-15T08:00:14+08:00","permalink":"https://bg2bkk.github.io/p/raspberry%E5%AE%89%E8%A3%85ffmpeg/","title":"raspberry安装ffmpeg"},{"content":"docker学习操作\n  docker info\n 查看docker是否正常工作    systemctl status docker\n 查看docker守护进程是否工作    docker ps\n 查看正在运行的容器 docker ps -a 查看所有容器    docker images\n 查看镜像    docker run -t -i ubuntu /bin/bash\n 运行docker镜像 -t 开启terminal -i 保证stdin开启 docker run \u0026ndash;name huang_ubuntu -t -i ubuntu /bin/bash  别名huang_ubuntu      docker attach huang_ubuntu\n 重新附着到运行容器中    运行守护式容器\n docker run \u0026ndash;name daemon_ubuntu -d ubuntu /bin/bash -c $CMD docker logs -f daemon_ubuntu  查看docker日志   docker logs -ft daemon_ubuntu  加上时间戳      docker stats huang_ubuntu\n 容器运行信息    docker exec -t -i huang_ubuntu /bin/bash\n docker容器中执行程序，采用-t -i方式打开/bin/bash可以打开容器终端，能够附着在运行中容器里    docker build\n mongoDB    ","date":"2016-08-14T16:09:53+08:00","permalink":"https://bg2bkk.github.io/p/docker%E6%93%8D%E4%BD%9C%E6%8C%87%E5%8D%97/","title":"docker操作指南"},{"content":"","date":"2016-08-12T00:26:03+08:00","permalink":"https://bg2bkk.github.io/p/docker%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF/","title":"docker学习之路"},{"content":"  nginx从启动worker到处理一个用户请求\n  1、nginx启动时，在init_process阶段首先注册事件和处理方法。首先为每个listen fd分配一个ngx_connection_t，并为它设置读时间处理函数，ngx_event_accept\n 如果nginx没有开启accept_mutex，则直接将ngx_event_accept挂载nginx的事件处理模型epoll上 否则等到init_process阶段结束，在worker的事件处理循环中竞争到锁之后才挂载用于接收新请求的读事件    2、当worker监听到读事件，nginx就可以接收客户端的请求；用户向nginx发起请求后，nginx的事件处理模型收到读事件，然后调用ngx_event_accept处理\n ngx_event_accept中，nginx调用accept，从TCP协议栈的已连接队列中取到一个连接和对应的socket，接着分配一个ngx_connection_t，将其与该socket对应 接着初始化该连接：  src/event/ngx_event_accept.c 为该连接分配一个256B大小的内存池 初始化读写事件对应的处理和回调函数handler: c-\u0026gt;rev = ngx_recv等 分配log结构，以便后续log系统使用 分配一个套接口地址sockaddr，将对端tcp地址保存在其中 将本地套接口地址保存在local_sockaddr中；因为有时候从监听结构ngx_listenging_t中获得的监听地址可能是通配符*******，而本地套接地址是真实地址 设置ready为1，即设置该连接的写事件就绪 如果socket设置了TCP_DEFER_ACCEPT属性，则表示该连接上已经有数据包了，于是设置事件为读就绪 将sockaddr保存的对端地址格式化为可读字符串 最后调用ngx_http_init_connection初始化该连接的其他部分      1 2 3 4 5 6 7 8  TCP_DEFER_ACCEPT (since Linux 2.4) Allow a listener to be awakened only when data arrives on the socket. Takes an integer value (seconds), this can bound the maximum number of attempts TCP will make to complete the connection. This option should not be used in code intended to be portable. 允许只有当监听事件者只有当有数据时才被唤醒；参数是整数，可以限制一个TCP为了处理完成一个连接所做的最多尝试次数   \t* ngx_http_init_connection * 初始化读写事件处理函数 * 写事件：ngx_http_empty_handler * 读事件：ngx_http_init_request * 如果连接上有数据过来，则调用该函数处理数据 * 否则设置定时器，等待数据到来或者超时，再在该函数中处理 * 初始化用户请求：ngx_http_init_request * 它是一个事件处理函数，唯一的参数是ngx_event_t *； * 进入该事件处理函数后，判断是否超时，如果超时，则直接关闭连接并返回；否则继续 * 在连接的内存池中分配一个ngx_http_request_t结构，用于保存请求的所有信息，并设置为该连接的request字段 * nginx根据该请求的端口和地址，找到一个默认vhost(第一个定义的server)，或者根据域名来区分监听相同端口和地址的vhost，临时使用，最终找到真正的目标vhost； * 进入vhost后，将连接的读事件处理函数ngx_http_process_request_line函数，解析请求行；为这个请求分配缓冲区，保存header头在request-\u0026gt;header_in，默认1024B，在该请求所在连接的内存池中分配 * 将请求的引用计数count字段设置为1；将当前时间设置为start_sec和start_mset；nginx以接收到客户端的第一个数据包的时间作为起始，apache则以接收到整个request line开始 * 初始化请求的其他字段，比如将uri_changes设置为11，表示最多可以将该请求的uri改写10次，subrequests被设置为201，表示一个请求最多可以发起200个子请求；  ","date":"2016-08-11T18:07:19+08:00","permalink":"https://bg2bkk.github.io/p/nginx%E6%8E%A5%E6%94%B6%E7%94%A8%E6%88%B7%E8%AF%B7%E6%B1%82%E7%9A%84%E8%BF%87%E7%A8%8B/","title":"nginx接收用户请求的过程"},{"content":"参考链接\n  nginx为每个连接分配内存池\n r-\u0026gt;pool是r的连接池，所有内存操作都在这里完成；请求结束后，该pool将会释放，因此没有内存泄露问题    nginx的异步通信\n 回调函数是nginx实现异步操作的方式 以ngx读取POST请求的request body为例，每次epoll监听到socket有数据进来的时候，就非阻塞的调用recv接收数据并累计，直到数据大于等于Header头部中的\u0026quot;Content-Length\u0026quot;(HTTP请求的Header部分此时已经被处理)，然后调用模块的回调函数对所有POST数据进行处理。    nginx的sendfile、TCP_NODELAY和TCP_NOPUSH\n 互联网早期，由于网络链路质量不好，在发送数据时，如果只是很小的数据包，TCP/IP协议栈将会等待200ms，收集更多数据包后一次发出，可以提高吞吐量，这个算法成为Nagle算法；随着通信技术进步，Nagle算法逐渐不合实际，在nginx中甚至需要TCP_NODELAY来禁用socket的Nagle算法，要求有数据包后立刻发出 TCP_NOPUSH显然是与TCP_NODELAY相冲突的，那为什么它存在呢？ 对于sendfile on这一配置而言，由于系统调用sendfile有着“零拷贝”的优势，在内核中从in_fd复制到out_fd，不足之处是in_fd只能是文件fd，因此sendfile只能用于发送文件到网络IO；当TCP_NOPUSH、TCP_NODELAY和sendfile配合起来，就很有意思了：在调用sendfile之前，将out_fd这一socket设置为TCP_NOPUSH的，sendfile将文件数据写到socket缓冲区，在sendfile完成后，去掉out_fd的TCP_NOPUSH选项，将文件数据一次发出，可以提高性能。    nginx的sendfile，还有读取用户请求的post数据等，灵活的操作内存缓冲区，代码质量很高，值得品味\n  参考链接\n sendfile, tcp_nodelay和tcp_nopush是怎样对nginx产生影响的呢？ *  ","date":"2016-08-11T17:44:27+08:00","permalink":"https://bg2bkk.github.io/p/nginx%E6%A8%A1%E5%9D%97%E5%BC%80%E5%8F%91%E9%82%A3%E4%BA%9B%E4%BA%8B/","title":"nginx模块开发那些事"},{"content":" https://yjhjstz.gitbooks.io/deep-into-node/content/chapter7/chapter7-1.html  ","date":"2016-08-10T20:58:28+08:00","permalink":"https://bg2bkk.github.io/p/nodejs%E6%8B%BE%E7%96%91/","title":"nodejs拾疑"},{"content":"  http://www.cnblogs.com/flyfy1/archive/2011/02/24/1963347.html\n  http://blog.csdn.net/zy825316/article/details/22600003\n  http://blog.csdn.net/ict2014/article/details/17394259\n  http://www.leoox.com/?p=347\n  http://www.cnblogs.com/xuqiang/archive/2011/05/22/2053516.html\n  http://redisbook.readthedocs.io/en/latest/internal-datastruct/skiplist.html\n  ","date":"2016-08-10T20:44:15+08:00","permalink":"https://bg2bkk.github.io/p/skiplist/","title":"skiplist"},{"content":"有序集 参考链接\n 编码方式  ziplist 编码方式 skiplist 编码方式 在redis配置文件中，有如下配置  zset-max-ziplist-entries和zset-max-ziplist-value不满足其中之一的时候，采用ziplist编码 否则采用skiplist方式编码      1 2 3 4 5 6  # Similarly to hashes and lists, sorted sets are also specially encoded in # order to save a lot of space. This encoding is only used when the length and # elements of a sorted set are below the following limits: zset-max-ziplist-entries 128 zset-max-ziplist-value 64     ziplist编码方式\n ziplist将节点KV按顺序压缩排序在一块内存，类型为ZIPLIST，查找特定元素时按序查找，时间复杂度为O(N)，增删查等更新操作的时间复杂度都会大于O(N)    skiplist编码方式\n 采用skiplist编码方式时，zset定义如下：    1 2 3 4 5 6 7 8 9 10 11 12  /* * 有序集 */ typedef struct zset { // 字典  dict *dict; // 跳跃表  zskiplist *zsl; } zset;   * zset采用跳表和哈希表共同维护，通过将skiplist和hash set的指针指向同一对象来共享数据 * 查找时，从hash set中以O(1)的时间复杂度读取数据 * 查找区间时，从skip list中以O(N)的复杂度获取区间 * 通过score对key进行定位时，skip list可以以最坏O(N)，期望O(log N)的时间复杂实现  ","date":"2016-08-10T15:10:37+08:00","permalink":"https://bg2bkk.github.io/p/redis%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/","title":"redis源码阅读"},{"content":"redis过期清除和淘汰机制   过期时间设置\n expire key seconds 该命令设置指定key超时的秒数，超过该时间后，可以将被删除 在超时之前，如果该key被修改，与之关联的超时将被移除  persist key 持久化该key，超时时间移除 set key newvalue 设置新值，会清除过期时间 del key\t显然会清除过期时间 例外情况：  lpush, zset, incr等操作，在高版本（2.1.3++）之后不会清除过期时间，毕竟修改的不是key本身 rename 也不会清除过期时间，只是改key名字        过期处理\n redis对过期key采用lazy expiration方式，在访问key的时候才判定该key是否过期 此外，每秒还会抽取volatile keys进行抽样，处理删除过期键    过期键删除策略种类\n  事件删除\n 每个键都有一个定时器，到期时触发处理事件，在事件中删除 缺点是需要为每个key维护定时器，key的量大时，cpu消耗较大    惰性删除\n 每次访问时才检查，如果没过期，正常返回，否则删除该键并返回空    定期删除\n 每隔一段时间，检查所有设置了过期时间的key，删除已过期的键    redis采用后两种结合的方式\n 读写一个key时，触发惰性删除策略 惰性删除策略不能及时处理冷数据，因此redis会定期主动淘汰一批已过期的key 内存超过maxmemory时，触发主动清理      http://blueswind8306.iteye.com/blog/2240088\n  http://www.cnblogs.com/chenpingzhao/p/5022467.html\n  ","date":"2016-08-01T13:26:07+08:00","permalink":"https://bg2bkk.github.io/p/redis%E8%BF%87%E6%9C%9F%E6%B8%85%E9%99%A4%E6%9C%BA%E5%88%B6%E5%8F%8A%E5%BA%94%E7%94%A8%E6%96%B9%E6%B3%95/","title":"redis过期清除机制及应用方法"},{"content":"免密登录配置脚本 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  #!/bin/bash passwd=\u0026#39;xxxxxxx\u0026#39; pub_key=`cat ~/.ssh/id_rsa.pub` for i in `cat $1`;do /usr/bin/expect \u0026lt;\u0026lt;-EOF set time 30 spawn ssh zhendong.hzd@$i \u0026#34;mkdir -p .ssh/;touch .ssh/authorized_keys;chmod 700 .ssh/authorized_keys;echo \\\u0026#34;$pub_key\\\u0026#34; \u0026gt;\u0026gt; .ssh/authorized_keys\u0026#34; expect { \u0026#34;*yes/no\u0026#34; { send \u0026#34;yes\\r\u0026#34;; exp_continue } \u0026#34;*password:\u0026#34; { send \u0026#34;$passwd\\r\u0026#34; } } interact expect eof EOF done   将待登录IP列表写入文件中，更改相应密码配置和用户名，然后执行\nubuntu命令行连接wifi wifi设置\n1 2 3 4 5 6 7 8 9 10  cat /etc/network/interfaces # interfaces(5) file used by ifup(8) and ifdown(8) auto lo iface lo inet loopback # 添加如下，启动时自动启动wlp2s0网卡，dhcp模式，采用wpa_conf配置 auto wlp2s0 iface wlp2s0 inet dhcp wpa_conf /etc/wpa_supplicant/wpa_supplicant.conf   wpa_supplicant.conf内容\n1 2 3 4 5  network={ ssid=\u0026#34;wills\u0026#34; psk=\u0026#34;1234567890\u0026#34; priority=1 }   连接wifi和密码，priority为优先级，数字越大级别越高\nvim和shell的配置方式 作为一个懒人，现在自然期待有一键脚本能够将我的shell和vim配置好。github上有很多repo帮助我们实现。\n知乎帮助一 知乎帮助二 vim一键配置 shell \u0026amp;\u0026amp; zsh vim一键配置二\nlinux下进程的有效用户ID和实际用户ID 见博客，getuid()\nhexdump查看文件指定位置 方法为所示，\n1  hexdump -s OFFSET -l LENGTH FILENAME   mac os下virtual box与虚拟机进行网络互通 方法见链接，需要在virtual box添加host only网卡，并在虚拟机中添加网卡。\n普通用户获取linux的root权限  方法一：sudo sh -c \u0026ldquo;su\u0026rdquo; 方法二：sudo strace su  改变默认登录的shell 使用不同linux发行版或者上不同机器时，发现shell不是我喜欢的bash，而是sh等，这个时候需要修改\n 修改登录shell  方法一：chsh -s /bin/bash 方法二：修改/etc/passwd中的shell设置    解决shell不显示路径的方法\nsar在ubuntu中的配置 1 2 3 4 5 6 7 8 9 10 11 12 13  sudo apt-get install sysstat sudo vim /etc/default/sysstat \u0026#34; change ENABLED=\u0026#34;false\u0026#34; to \u0026#34;true\u0026#34; sudo vim /etc/cron.d/sysstat \u0026#34; change \u0026#34; 5-55/10 * * * * root command -v debian-sa1 \u0026gt; /dev/null \u0026amp;\u0026amp; debian-sa1 1 1 \u0026#34; to \u0026#34; */2 * * * * root command -v debian-sa1 \u0026gt; /dev/null \u0026amp;\u0026amp; debian-sa1 1 1 \u0026#34; change the collection interval from every 10 minutes to every 2 minutes. sudo /etc/init.d/sysstat restart   全世界最愚蠢的事情就是，重复做相同的事情，却期待有不同的结果发生 Insanity: doing the same thing over and over again and expecting different results.  说实话，在写代码、调代码的时候，一但出现非预期结果，首先检查之前自己的编码和输入，确定后不应该再二次重试，毕竟相同条件下不可能产生不同结果，此时应该将思维跳脱出来，另辟蹊径为好。\nubuntu下解压zip文件出现乱码的解决办法 参考链接\n由于zip格式中并没有指定编码格式，Windows下生成的zip文件中的编码是GBK/GB2312等，因此，导致这些zip文件在Linux下解压时出现乱码问题，因为Linux下的默认编码是UTF8。\n目前网上流传一种unzip -O cp936的方法，但一些unzip是没有-O这个选项的。\n亲测好用，不好用的看链接\nredis设置和清除密码 正规项目终于要对redis设置密码了，如何加密码呢\n  配置文件中添加密码\n 配置文件中的requirepass配置指令用于配置密码 配置文件中的masterauth用于配置从机登陆主机的密码    运行中添加密码\n config set requirepass PASSWORD    运行中删除密码\n config set requirepass \u0026quot;\u0026quot;    获取密码\n config get requirepass    配置从机\n config set masterauth MASTER_PASSWORD config set requirepass SLAVE_AUTH    epoll是同步非阻塞的 epoll、select等多路服用IO，将fd加入等待时间的队列中，每隔一段时间去轮询一次，因此是同步的；优点是能够在等待任务的时间里去做别的任务；缺点是任务完成的响应延迟增大，因为每隔一段时间去轮询他们，在时间间隔内任务可能已经完成而等待处理等待了一段时间了。\n参考链接\n同步/异步指的是被调用方的通知方式，被调用方完成后，主动通知调用方，还是等待调用方发现。前者是异步，后者是同步。从这里也可以看出，异步IO通知调用方时，数据已经就绪，对于网络IO来说，异步IO已经将数据从内核复制到用户空间了。\n阻塞/非阻塞是调用方的等待方式，是一直等待在做的事件完成，还是去做别的事情，等到在做的事件完成后再接着进行处理。前者是阻塞，后者是非阻塞\n因此epoll是同步和非阻塞的。\nsed合并相邻两行 从redis中取出一个键的所有内容时，比如hgetall，得到的结果并不是排序好的，类似于这样\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  11485) \u0026#34;1470347460\u0026#34; 11486) \u0026#34;69\u0026#34; 11487) \u0026#34;1470262350\u0026#34; 11488) \u0026#34;34\u0026#34; 11489) \u0026#34;1470262170\u0026#34; 11490) \u0026#34;68\u0026#34; 11491) \u0026#34;1470242400\u0026#34; 11492) \u0026#34;21\u0026#34; 11493) \u0026#34;1470288030\u0026#34; 11494) \u0026#34;65\u0026#34; 11495) \u0026#34;1470303390\u0026#34; 11496) \u0026#34;54\u0026#34; 11497) \u0026#34;1470205320\u0026#34; 11498) \u0026#34;85\u0026#34; 11499) \u0026#34;1470318330\u0026#34; 11500) \u0026#34;92\u0026#34; 11501) \u0026#34;1470167040\u0026#34; 11502) \u0026#34;1\u0026#34; 11503) \u0026#34;1470281880\u0026#34; 11504) \u0026#34;14\u0026#34; 11505) \u0026#34;1470298140\u0026#34; 11506) \u0026#34;113\u0026#34;   该hash的key为unix时间戳，val为数值，如果想手动看分布的话，需要将相邻两行合并然后排序，在此我们借助sed\n1  sed \u0026#39;$!N;s/\\n/\\t/\u0026#39; filename   redis分析实例中所有key和单个key的内存占用情况 采用rdb工具\n1  rdb -c memory /path/to/ab-dump.rdb \u0026gt; memory.csv   sort进行多重排序 sort和uniq在文本处理，尤其是日志处理中用的较多的工具，记得当年校招时候准备面试，用到这两个命令，惊为天人，非常shock。在日常工作中，用的也非常多。\n目前有这样的需求，拿到两列数据，第一列是ip，第二列是访问计数，想看一下分布，要求ip要按文本排序，访问计数按数值排序。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  221.179.175.109\t97 221.179.175.164\t101 221.179.175.46\t8 221.179.175.164\t102 221.179.175.178\t78 221.179.175.46\t9 221.179.175.109\t98 221.179.175.178\t79 120.239.141.197\t96 221.179.175.70\t114 218.202.7.121\t70 221.179.175.178\t80 218.202.7.121\t71 221.179.175.134\t83 120.239.141.197\t97 221.179.175.46\t10 221.179.175.178\t81 221.179.175.47\t24 120.239.141.197\t98 221.179.175.70\t115 221.179.175.70\t116 120.239.141.197\t99 221.179.175.134\t84   解决方法\n1 2 3 4 5 6  sort -t \u0026#39; \u0026#39; -k1,1 -k2n,2 data 其中 -t \u0026#39; \u0026#39; 指定使用空格分列 -k1,1 指定以第一列为关键字排序 -k2n,2 指定以第二列为关键字做数据排序   也可以\n1  sort -k1 -k2n out   shell脚本批量处理文本 善用awk、grep、xargs、bash、sed等工具，可以提高生产力\n1  grep \u0026#39;config.config\u0026#39; . -r | awk -F\u0026#39;:\u0026#39; \u0026#39;{print $1}\u0026#39; | grep \u0026#39;lua$\u0026#39; | xargs sed \u0026#34;s/config.config\u0026#39;)/config.config\u0026#39;).ab/g\u0026#34; -i   shell循环\n1  for j in {a..z}; do echo $j; done   redis批量删除key 手动清理redis中的key时，很想通过 del keys* 的方式实现批量删除，而redis却没有提供这样的选项，因此需要借助外部工具\n  1、sehll 命令行\n redis-cli keys ip:* | xargs redis-cli del    2、lua脚本\n redis-cli eval \u0026ldquo;redis.call(\u0026lsquo;del\u0026rsquo;, unpack(redis.call(\u0026lsquo;keys\u0026rsquo;,\u0026lsquo;ip*')))\u0026rdquo; 0 这种方式受限于lua的unpack函数，一次删除的key不能太多    3、借助客户端\n php jedis    unix获取时间戳 1 2 3 4 5 6 7 8 9 10 11 12 13 14  date \u0026#39;+%s\u0026#39; export timestamp=`date \u0026#39;+%s\u0026#39;`; echo $timestamp # 标准时间格式转unix时间戳 date -d \u0026#34;2011-03-02 15:00\u0026#34; +%s # unix时间戳转为标准格式 date -d \u0026#39;1970-01-01 UTC 1299049200 seconds\u0026#39; # 或者 date -d \u0026#34;@1279592730\u0026#34;   链接中提到了各种各样的格式，以后写shell脚本就不担心时间戳问题了\ndocker 设置代理下载镜像 在systemd中设置\n mkdir /etc/systemd/system/docker.service.d touch /etc/systemd/system/docker.service.d/http-proxy.conf 在文件中添加：[Service]Environment=\u0026ldquo;HTTP_PROXY=http://proxy.example.com:80/\u0026quot; 重启daemon：sudo systemctl daemon-reload 查看设置状态：sudo systemctl show docker \u0026ndash;property Environment 重启docker：sudo systemctl restart docker  tested on Ubuntu 16.04\n用ps查看进程的执行时间 1  ps -eo pid,tty,user,comm,stime,etime | grep main   可以打印进程的开始时间和执行时间\nvim下以16进制查看文本文件 vim的功能实在是太强大了，可以以16进制查看文本信息：\n十六进制显示 :%!xxd 正常显示 :%!xxd -r  Linux获取系统调度时间片长度 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  #define _GNU_SOURCE #include \u0026lt;sched.h\u0026gt;#include \u0026lt;stdlib.h\u0026gt;#include \u0026lt;unistd.h\u0026gt;#include \u0026lt;stdio.h\u0026gt;#include \u0026lt;assert.h\u0026gt; int main(int argc, char *argv[]) { int ret, i; struct timespec tp; ret = sched_rr_get_interval(0, \u0026amp;tp); if(ret == -1) printf(\u0026#34;sched_rr_get_interval error.\\n\u0026#34;); printf(\u0026#34;The time is %ds:%ldns.\\n\u0026#34;, (int)tp.tv_sec, tp.tv_nsec); return 0; }   1 2  $ ./cpu_time_slice.o The time is 0s:16000000ns.   可见Ubuntu-16.04 64bit的系统进程时间片是16ms\nC语言中short、int、long内存占用 随着工作年限的增加，很多基本功反而落了下来，甚至开始怀疑short等类型的内存占用问题了呵呵。印象里一直记得int和long类型都是4字节大小啊\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  #include \u0026lt;stdio.h\u0026gt;#include \u0026lt;stdlib.h\u0026gt; struct test{ char *ch1; int i; long ch2; } aa; int main() { printf(\u0026#34;Linux-64Bit-platform\\n\u0026#34;); printf(\u0026#34;\t%lu\\n\u0026#34;, (unsigned long)sizeof(aa)); printf(\u0026#34;\tsizeof short : %d\\n\u0026#34;, sizeof(short)); printf(\u0026#34;\tsizeof int : %d\\n\u0026#34;, sizeof(int)); printf(\u0026#34;\tsizeof long : %d\\n\u0026#34;, sizeof(long)); }   1 2 3 4 5 6 7  Linux-64Bit-platform 24 sizeof short : 2 sizeof int : 4 sizeof long : 8   1 2 3 4 5 6 7  Linux-32Bit-platform 24 sizeof short : 2 sizeof int : 4 sizeof long : 4   看来，long和int大小一样已经是32位机器的老黄历了，基础知识还是应该常用常新啊\n文件操作的线程安全相关（待续） http://stackoverflow.com/questions/29981050/concurrent-writing-to-a-file\nubuntu关闭键盘和触摸板的方法 家里的猫就是喜欢趴在笔记本键盘上看你干活，我只能再买一个键盘，然后笔记本键盘留给猫大爷了。\n然而它还喜欢在键盘上跳舞，这样太影响输入了，只能想办法把笔记本键盘关掉。\n在ubuntu下，键盘鼠标触控板都属于xinput设备，可以通过以下命令查看：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  $ xinput --list ⎡ Virtual core pointer id=2\t[master pointer (3)] ⎜ ↳ Virtual core XTEST pointer id=4\t[slave pointer (2)] ⎜ ↳ SynPS/2 Synaptics TouchPad id=16\t[slave pointer (2)] ⎜ ↳ Rapoo Rapoo Gaming Keyboard id=11\t[slave pointer (2)] ⎜ ↳ RAPOO Rapoo 2.4G Wireless Device id=12\t[slave pointer (2)] ⎜ ↳ Wacom ISDv4 E6 Pen stylus id=13\t[slave pointer (2)] ⎜ ↳ Wacom ISDv4 E6 Finger touch id=14\t[slave pointer (2)] ⎜ ↳ Wacom ISDv4 E6 Pen eraser id=18\t[slave pointer (2)] ⎜ ↳ TPPS/2 IBM TrackPoint id=19\t[slave pointer (2)] ⎣ Virtual core keyboard id=3\t[master keyboard (2)] ↳ Virtual core XTEST keyboard id=5\t[slave keyboard (3)] ↳ Power Button id=6\t[slave keyboard (3)] ↳ Video Bus id=7\t[slave keyboard (3)] ↳ Sleep Button id=8\t[slave keyboard (3)] ↳ Integrated Camera id=9\t[slave keyboard (3)] ↳ Rapoo Rapoo Gaming Keyboard id=10\t[slave keyboard (3)] ↳ AT Translated Set 2 keyboard id=15\t[slave keyboard (3)] ↳ ThinkPad Extra Buttons id=17\t[slave keyboard (3)]   可以看到笔记本键盘是\n1  ↳ AT Translated Set 2 keyboard id=15\t[slave keyboard (3)]   而触控板是\n1  ⎜ ↳ SynPS/2 Synaptics TouchPad id=16\t[slave pointer (2)]   他们的id分别是 15和 16，所以采用以下命令关掉就可以\n1 2  sudo sudo xinput set-prop 15 \u0026#34;Device Enabled\u0026#34; 0 sudo sudo xinput set-prop 16 \u0026#34;Device Enabled\u0026#34; 0   附送shell脚本\n1 2 3 4 5 6 7 8 9 10 11 12 13  #!/bin/bash  keyboard=`xinput --list | grep AT | awk -F\u0026#39;=\u0026#39; \u0026#39;{print $2}\u0026#39; | awk \u0026#39;{print $1}\u0026#39;` touchpad=`xinput --list | grep Synaptics | awk -F\u0026#39;=\u0026#39; \u0026#39;{print $2}\u0026#39; | awk \u0026#39;{print $1}\u0026#39;` function doit() { echo \u0026#39;关闭 笔记本键盘\u0026#39; `sudo xinput set-prop $keyboard \u0026#34;Device Enabled\u0026#34; 0`\techo \u0026#39;关闭 笔记本触摸板\u0026#39; `sudo xinput set-prop $touchpad \u0026#34;Device Enabled\u0026#34; 0` } doit   小于1024的保留端口都有哪些 我们会遇到如下情况：\n1 2 3 4  $ sudo tcpdump -i any port 1080 tcpdump: verbose output suppressed, use -v or -vv for full protocol decode listening on any, link-type LINUX_SLL (Linux cooked), capture size 262144 bytes 15:08:42.421693 IP localhost.55092 \u0026gt; localhost.socks: Flags [.], ack 1960200857, win 342, options [nop,nop,TS val 4687328 ecr 4676064], length 0   我想监听1080端口，tcpdump为什么不乖乖显示1080，而是出现个socks呢？（可以通过***-n***参数解决）为什么1080是socks，而不是别的呢？\n这是因为低于1024的保留端口大多有自己的名字，他们由IANA分配，通常用于系统进程，而我们可以在***/etc/services***文件中找到：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39  # # From ``Assigned Numbers\u0026#39;\u0026#39;: # #\u0026gt; The Registered Ports are not controlled by the IANA and on most systems #\u0026gt; can be used by ordinary user processes or programs executed by ordinary #\u0026gt; users. # #\u0026gt; Ports are used in the TCP [45,106] to name the ends of logical #\u0026gt; connections which carry long term conversations. For the purpose of #\u0026gt; providing services to unknown callers, a service contact port is #\u0026gt; defined. This list specifies the port used by the server process as its #\u0026gt; contact port. While the IANA can not control uses of these ports it #\u0026gt; does register or list uses of these ports as a convienence to the #\u0026gt; community. # socks\t1080/tcp\t# socks proxy server socks\t1080/udp proofd\t1093/tcp proofd\t1093/udp rootd\t1094/tcp rootd\t1094/udp openvpn\t1194/tcp openvpn\t1194/udp rmiregistry\t1099/tcp\t# Java RMI Registry rmiregistry\t1099/udp kazaa\t1214/tcp kazaa\t1214/udp nessus\t1241/tcp\t# Nessus vulnerability nessus\t1241/udp\t# assessment scanner lotusnote\t1352/tcp\tlotusnotes\t# Lotus Note lotusnote\t1352/udp\tlotusnotes ms-sql-s\t1433/tcp\t# Microsoft SQL Server ms-sql-s\t1433/udp ms-sql-m\t1434/tcp\t# Microsoft SQL Monitor ms-sql-m\t1434/udp ingreslock\t1524/tcp ingreslock\t1524/udp prospero-np\t1525/tcp\t# Prospero non-privileged   git修改默认分支名 在develop分支改动太大了，导致merge 到master分支时非常被动，这个时候我想，干脆将develop分支作为分支好了。还好碰到stackoverflow的一个帖子\n git branch -m master oldmaster git branch -m develop master git push -f origin master  另一个方法是从github的项目主页上更改\n编译openssl 1.0.2g 1  ./config shared -fPIC zlib-dynamic \u0026amp;\u0026amp; make depend -j \u0026amp;\u0026amp; make -j   编译nginx/tengine: CPP模块 1  ./configure --add-module=../cpp_module --with-ld-opt=\u0026#34;-lstdc++\u0026#34;   curl -i 和 -I的区别 man page:\n1 2 3 4 5  -i, --include (HTTP) Include the HTTP-header in the output. The HTTP-header includes things like server-name, date of the document, HTTP-version and more... -I, --head (HTTP/FTP/FILE) Fetch the HTTP-header only! HTTP-servers feature the command HEAD which this uses to get nothing but the header of a document. When used on an FTP or FILE file, curl displays the file size and last modification time only.   -i选项会打印出HTTP头部的一些信息，这个选项是curl软件的选项，这些信息本来就是存在的\n-I选项会发送HEAD请求，获取信息\nlinux系统如何将父子进程一起kill掉 对于普通进程而言，kill掉父进程将会连带着把子进程kill掉；而对于daemon等类型进程而言，kill掉父进程，子进程会被daemon接管，所以如果想父子一起kill掉的话，不能直接kill父进程。\n有两种方法\n  kill \u0026ndash; -PPID\n PPID前面有***-***号，可以将父子进程kill掉    使用exec或者xargs来kill掉他们\n  dns查询中，域名是否可以有多个cname呢？ 不可以 * http://serverfault.com/questions/574072/can-we-have-multiple-cnames-for-a-single-name\ngit代理访问 git config \u0026ndash;global http.proxy 10.8.0.1:8118\nubuntu操作、挂载、格式化SD卡 玩树莓派等板子的时候，需要从host机器将os镜像烧进sd卡，然后启动。那么ubuntu如何操作呢？\nfdisk -l命令可以用来查看系统中的存储硬件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38  Disk /dev/sda: 111.8 GiB, 120034123776 bytes, 234441648 sectors Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disklabel type: gpt Disk identifier: C27256BB-CE04-48C2-96F4-8F79FAE2AE87 Device Start End Sectors Size Type /dev/sda1 2048 234440703 234438656 111.8G Linux filesystem Disk /dev/sdb: 167.7 GiB, 180045766656 bytes, 351651888 sectors Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disklabel type: dos Disk identifier: 0x42b438a2 Device Boot Start End Sectors Size Id Type /dev/sdb1 * 2048 105887743 105885696 50.5G 7 HPFS/NTFS/exFAT /dev/sdb2 105887744 187807665 81919922 39.1G 83 Linux /dev/sdb3 187807744 228767743 40960000 19.5G 7 HPFS/NTFS/exFAT /dev/sdb4 228769790 351649791 122880002 58.6G f W95 Ext\u0026#39;d (LBA) /dev/sdb5 228769792 351649791 122880000 58.6G 7 HPFS/NTFS/exFAT Disk /dev/sdc: 14.9 GiB, 16021192704 bytes, 31291392 sectors Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disklabel type: dos Disk identifier: 0x00000000 Device Boot Start End Sectors Size Id Type /dev/sdc1 8192 31291391 31283200 14.9G c W95 FAT32 (LBA)   如果sd卡（tf卡）通过usb 读卡器接入电脑，则会显示为 /dev/sdc\n如果是标准sd卡（大卡），则会显示为 /dev/mmblck0\n1 2 3 4 5 6 7 8 9 10 11  Disk /dev/mmcblk0: 14.9 GiB, 16021192704 bytes, 31291392 sectors Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disklabel type: dos Disk identifier: 0x00000000 Device Boot Start End Sectors Size Id Type /dev/mmcblk0p1 8192 31291391 31283200 14.9G c W95 FAT32 (LBA)   推荐使用USB读卡器，速度较为快一些。\nLua库文件的加载路径 Lua 提供一个名为 require 的函数来加载模块，使用也很简单，它只有一个参数，这个参数就是要指定加载的模块名，例如：\n1 2 3  require(\u0026#34;\u0026lt;模块名\u0026gt;\u0026#34;) -- 或者是 -- require \u0026#34;\u0026lt;模块名\u0026gt;\u0026#34;   然后会返回一个由模块常量或函数组成的 table，并且还会定义一个包含该 table 的全局变量。\n或者给加载的模块定义一个别名变量，方便调用：\n1 2 3  local m = require(\u0026#34;module\u0026#34;) print(m.constant) m.func3()   对于自定义的模块，模块文件不是放在哪个文件目录都行，函数 require 有它自己的文件路径加载策略，它会尝试从 Lua 文件或 C 程序库中加载模块。\nrequire 用于搜索 Lua 文件的路径是存放在全局变量 package.path 中，当 Lua 启动后，会以环境变量 LUA_PATH 的值来初始这个环境变量。如果没有找到该环境变量，则使用一个编译时定义的默认路径来初始化。\n1 2 3 4 5  Lua 5.1.5 Copyright (C) 1994-2012 Lua.org, PUC-Rio \u0026gt; print(package.path) ~/lua/?.lua;/usr/local/share/lua/5.1/?.lua;/home/huang/workspace/luactor/?.lua;./?.lua;/usr/local/share/lua/5.1/?.lua;/usr/local/share/lua/5.1/?/init.lua;/usr/local/lib/lua/5.1/?.lua;/usr/local/lib/lua/5.1/?/init.lua;   如果没有 LUA_PATH 这个环境变量，也可以自定义设置\n1 2 3 4 5 6  huang@ThinkPad-X220:~/workspace/luapkg/luasocket-2.0.2$ export LUA_PATH=\u0026#34;4;;\u0026#34; huang@ThinkPad-X220:~/workspace/luapkg/luasocket-2.0.2$ lua Lua 5.1.5 Copyright (C) 1994-2012 Lua.org, PUC-Rio \u0026gt; print(package.path) 4;./?.lua;/usr/local/share/lua/5.1/?.lua;/usr/local/share/lua/5.1/?/init.lua;/usr/local/lib/lua/5.1/?.lua;/usr/local/lib/lua/5.1/?/init.lua; \u0026gt;   可以看到，随便加的环境变量\u0026quot;4;\u0026ldquo;写在了package.path中。\n而为什么4需要两个\u0026rsquo;；\u0026lsquo;号呢：文件路径以 \u0026ldquo;;\u0026rdquo; 号分隔，最后的 2 个 \u0026ldquo;;;\u0026rdquo; 表示新加的路径后面加上原来的默认路径。\n1 2 3 4 5 6  huang@ThinkPad-X220:~/workspace/luapkg/luasocket-2.0.2$ export LUA_PATH=\u0026#34;4;\u0026#34; huang@ThinkPad-X220:~/workspace/luapkg/luasocket-2.0.2$ lua Lua 5.1.5 Copyright (C) 1994-2012 Lua.org, PUC-Rio \u0026gt; print(package.path) 4; \u0026gt;   可见如果只有一个；号，将只采用这个分号。\n如果找过目标文件，则会调用 package.loadfile 来加载模块。否则，就会去找 C 程序库。搜索的文件路径是从全局变量 package.cpath 获取，而这个变量则是通过环境变量 LUA_CPATH 来初始。搜索的策略跟上面的一样，只不过现在换成搜索的是 so 或 dll 类型的文件。如果找得到，那么 require 就会通过 package.loadlib 来加载它。\n我们也可以在lua代码中动态修改package.path变量，\n1 2 3  package.path = \u0026#34;../?.lua;\u0026#34;..package.path require \u0026#34;fun\u0026#34;   这点对于我们自己的lua project的设置来说无疑是很方便的。 参考链接\ncpp调用c函数 由于CPP在链接时与C不太一样，因此在调用C函数时，需要做一定处理。\n将C函数的声明房子 #ifdef __cplusplus 块中\n1 2 3 4 5 6 7 8 9 10 11  #ifdef __cplusplus extern \u0026#34;C\u0026#34; { #endif /*. * c functions declarations ..*/ #ifdef __cplusplus } #endif   多少人在猜你机器的密码呢 VPS在公网就是个待宰的肥肉，都想去登陆，那都谁猜我的IP了呢？\n1  sudo grep \u0026#34;Failed password for root\u0026#34; /var/log/auth.log | awk \u0026#39;{print $11}\u0026#39; | sort | uniq -c | sort -nr | more   grep的简单使用，与 或 非  或操作  1 2 3  grep -E \u0026#39;123|abc\u0026#39; filename // 找出文件（filename）中包含123或者包含abc的行 egrep \u0026#39;123|abc\u0026#39; filename // 用egrep同样可以实现 awk \u0026#39;/123|abc/\u0026#39; filename // awk 的实现方式    与操作  1  grep pattern1 files | grep pattern2 ：显示既匹配 pattern1 又匹配 pattern2 的行。    其他操作  1 2 3 4 5 6 7  grep -i pattern files ：不区分大小写地搜索。默认情况区分大小写， grep -l pattern files ：只列出匹配的文件名， grep -L pattern files ：列出不匹配的文件名， grep -w pattern files ：只匹配整个单词，而不是字符串的一部分（如匹配‘magic’，而不是‘magical’）， grep -v pattern files ：不匹配pattern grep -C number pattern files ：匹配的上下文分别显示[number]行，   iptables的简单使用 其实并不想写iptables相关的内容，因为用的不熟，但是一些常用的命令还是记一下吧\niptables的详细解释\nLinux系统中,防火墙(Firewall),网址转换(NAT),数据包(package)记录,流量统计,这些功能是由Netfilter子系统所提供的，而iptables是控制Netfilter的工具。iptables将许多复杂的规则组织成成容易控制的方式，以便管理员可以进行分组测试，或关闭、启动某组规则。  1 2 3 4  https://blog.phpgao.com/vps_iptables.html http://www.tabyouto.com/bandwagon-vps-for-shadowsocks-was-hacked.html http://my.oschina.net/yqc/blog/82111?fromerr=VxVIazGW http://www.vpser.net/security/linux-iptables.html   1 2 3 4 5 6 7 8 9  # 列出所有规则 iptables -L -n # 更新iptables规则，规则写在/etc/iptables.rules iptables-restore \u0026lt; /etc/iptables.rules # 保存iptables规则，规则写在/etc/iptables.rules iptables-save \u0026gt; /etc/iptables.rules   需要注意的是Debian/Ubuntu上iptables是不会保存规则的。\n需要按如下步骤进行，让网卡关闭是保存iptables规则，启动时加载iptables规则：\n创建/etc/network/if-post-down.d/iptables 文件，添加如下内容：\n1 2  #!/bin/bash iptables-save \u0026gt; /etc/iptables.rules   执行：chmod +x /etc/network/if-post-down.d/iptables 添加执行权限。\n创建/etc/network/if-pre-up.d/iptables 文件，添加如下内容：\n1 2  #!/bin/bash iptables-restore \u0026lt; /etc/iptables.rules   执行：chmod +x /etc/network/if-pre-up.d/iptables 添加执行权限。\niptables的一些常用规则：\n1 2  #允许ping iptables -A INPUT -p icmp -m icmp --icmp-type 8 -j ACCEPT   如果想清空的话，先执行\n/sbin/iptables -P INPUT ACCEPT  然后执行\n/sbin/iptables -F  VPS简单的ssh登陆设置 初次使用VPS，不懂得安全的重要性，直到扣款时候才心疼，这个时候，弱口令，密码登陆什么的，还是都放弃吧，只用ssh登陆，并且换一个自己的端口。参考链接\n简单来说，任何一台主机想登陆VPS的主机都需要有本身的ssh公钥私钥\n1 2  cd ~/.ssh/ ssh-keygen -t rsa -C \u0026#34;username@gmail.com\u0026#34;   然后复制~/.ssh/id_rsa.pub中的内容，就是本机的公钥。\n将公钥添加到VPS服务器的/home/username/.ssh/authorized_keys中，本机就能以username用户名登陆VPS了\n然后在/etc/ssh/sshd_config中禁用禁用 VPS 的密码登录和 root 帐号登录，将以下两项改为no\n1 2 3 4 5  PasswordAuthentication no PermitRootLogin no Port 11111   随后重启SSH服务\n1  sudo service ssh restart   vim删除空行  从网页上copy下代码后，发现很多情况下有不想要的空行，非常影响阅读，通过vim的正则可以解决  Delete all blank lines (^ is start of line; \\s* is zero or more whitespace characters; $ is end of line) 删除所有空白行(^是行的开始，\\s*是零个或者多个空白字符；$是行尾)    1  :g/^\\s*$/d   ubuntu通过命令设置系统时间 在嵌入式开发中，在pcduino或者rpi板子上安装好linux后，系统时间是UTC时间1970年，对于有些软件来说可能影响安装，所以需要命令行修改date\n1  sudo date -s \u0026#34;13 DEC 2015 20:43\u0026#34;   ubuntu终端下中文设置 在安装完ubuntu系统后，我们发现中文支持的不好，主要体现在locale的错误，解决方法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  perl: warning: Setting locale failed. perl: warning: Please check that your locale settings: LANGUAGE = (unset), LC_ALL = (unset), LC_PAPER = \u0026#34;zh_CN.UTF-8\u0026#34;, LC_ADDRESS = \u0026#34;zh_CN.UTF-8\u0026#34;, LC_MONETARY = \u0026#34;zh_CN.UTF-8\u0026#34;, LC_NUMERIC = \u0026#34;zh_CN.UTF-8\u0026#34;, LC_TELEPHONE = \u0026#34;zh_CN.UTF-8\u0026#34;, LC_IDENTIFICATION = \u0026#34;zh_CN.UTF-8\u0026#34;, LC_MEASUREMENT = \u0026#34;zh_CN.UTF-8\u0026#34;, LC_TIME = \u0026#34;zh_CN.UTF-8\u0026#34;, LC_NAME = \u0026#34;zh_CN.UTF-8\u0026#34;, LANG = \u0026#34;en_US.UTF-8\u0026#34; are supported and installed on your system. perl: warning: Falling back to the standard locale (\u0026#34;C\u0026#34;).   这是因为中文包没有安装好的缘故，如下命令就可以解决：\n1 2 3 4 5 6  添加简体中文支持 sudo apt-get -y install language-pack-zh-hans language-pack-zh-hans-base 添加繁体中文支持 sudo apt-get -y install language-pack-zh-hant language-pack-zh-hant-base   如果还不行，先观察下locale的配置\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  huang@localhost:~$ locale locale: Cannot set LC_CTYPE to default locale: No such file or directory locale: Cannot set LC_MESSAGES to default locale: No such file or directory locale: Cannot set LC_ALL to default locale: No such file or directory LANG=en_US.UTF-8 LANGUAGE= LC_CTYPE=\u0026#34;en_US.UTF-8\u0026#34; LC_NUMERIC=zh_CN.UTF-8 LC_TIME=zh_CN.UTF-8 LC_COLLATE=\u0026#34;en_US.UTF-8\u0026#34; LC_MONETARY=zh_CN.UTF-8 LC_MESSAGES=\u0026#34;en_US.UTF-8\u0026#34; LC_PAPER=zh_CN.UTF-8 LC_NAME=zh_CN.UTF-8 LC_ADDRESS=zh_CN.UTF-8 LC_TELEPHONE=zh_CN.UTF-8 LC_MEASUREMENT=zh_CN.UTF-8 LC_IDENTIFICATION=zh_CN.UTF-8 LC_ALL=   再重新配置下语言包\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  huang@localhost:~$ sudo locale-gen \u0026#34;en_US.UTF-8\u0026#34; Generating locales... en_US.UTF-8... done Generation complete. huang@localhost:~$ sudo pip install shadowsocks^C huang@localhost:~$ sudo locale-gen \u0026#34;zh_CN.UTF-8\u0026#34; Generating locales... zh_CN.UTF-8... done Generation complete. huang@localhost:~$ sudo dpkg-reconfigure locales Generating locales... en_US.UTF-8... done zh_CN.UTF-8... up-to-date zh_HK.UTF-8... done zh_SG.UTF-8... done zh_TW.UTF-8... done Generation complete.   一般就都能解决\nLinux终端下的颜色设置输出 Linux终端下，如果有一个彩色的终端，可以明显提升人的阅读兴趣，通过printf的简单设置即可实现彩色输出\n1 2 3 4  \\033[显示方式;前景色;背景色m 显示方式、前景色、背景色至少一个存在即可。 格式：\\033[显示方式;前景色;背景色m   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  前景色 背景色 颜色 30 40 黑色 31 41 红色 32 42 绿色 33 43 黃色 34 44 蓝色 35 45 紫红色 36 46 青蓝色 37 47 白色 显示方式 意义 0 终端默认设置 1 高亮显示 4 使用下划线 5 闪烁 7 反白显示 8 不可见   1 2 3 4 5  \\033[1;31;40m \u0026lt;!--1-高亮显示 31-前景色红色 40-背景色黑色--\u0026gt; \\033[0m \u0026lt;!--采用终端默认设置，即取消颜色设置--\u0026gt; printf(\u0026#34;\\033[1;31;40m\u0026#34;); printf(\u0026#34;\\033[0m\u0026#34;);   tsar监控系统负载和nginx运行情况 tsar是阿里巴巴发布的一款能够实时监控系统状态的命令行工具，并且支持第三方模块扩展，其中比较注明的是nginx模块。使用tsar时，可以将系统负载和nginx运行情况同步同时打出，可以用来定位系统瓶颈，所以广受好评。\ntsar -li1 是其最经典的用法，可以将一般我们感兴趣的监控项每秒更新一次并输出\n1 2 3 4  Time ---cpu-- ---mem-- ---tcp-- -----traffic---- --sda--- ---load- Time util util retran bytin bytout util load1 25/03/16-19:03:30 0.08 10.22 0.00 1.4K 1.2K 0.00 0.33 25/03/16-19:03:31 0.08 10.21 0.00 424.00 468.00 0.00 0.33   如果想使能nginx模块，需要对其进行配置\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  1. mkdir /etc/tsar/conf.d 2. touch /etc/tsar/conf.d/nginx.conf 3. 写入如下内容并保存 mod_nginx on ####add it to tsar default output output_stdio_mod mod_nginx ####add it to center db #output_db_mod mod_nginx ####add it to nagios send ####set nagios threshold for alert #output_nagios_mod mod_nginx #threshold nginx.value1;N;N;N;N; #threshold nginx.value2;N;N;N;N; #threshold nginx.value3;N;N;N;N; 表示使能nginx模块，并使用stdio输出 4. tsar -li1 Time ---cpu-- ---mem-- ---tcp-- -----traffic---- --sda--- ---load- ------------------nginx----------------- Time util util retran bytin bytout util load1 qps rt sslqps spdyps sslhst 25/03/16-19:06:19 0.08 11.40 7.14 302.00 546.00 0.00 0.02 1.00 0.00 0.00 0.00 0.00   wrk在CentOS系统上的编译方法 wrk作为一款可以内嵌lua脚本的，支持多线程的压测工具，受到了广泛欢迎。在高版本CentOS 7上，直接在wrk目录下执行make，可以首先编译deps/luajit，得到deps/luajit/libluajit.a，然而在低版本上，CentOS 6.5系统中，会报一些莫名奇妙的错误。\n解决方法是，查看wrk的Makefile，发现wrk依赖于luajit，那么首先进入deps/luajit编译它，并且是静态编译\n1 2 3 4 5 6 7  cd wrk cd deps/luajit make -j24 BUILDMODE=static cd ../.. make -j24   rpmbuild环境的快速初始化 需要将代码打包为CentOS的RPM包时，可以先自己在本地新建一个环境\n1 2 3 4  1. mkdir -p ~/rpmbuild/{SOURCES,BUILD,BUILDROOT,RPMS,SRPMS,SPECS} 2. 将代打包的代码压缩包 software.tar.gz 放入SOURCES文件夹 3. 将 software.spec 放入SPECS文件夹 4. rpmbuild -ba path/to/software.spec 即可   git记住密码，不用每次都输密码才登入 git有两种方式，一种是ssh方式，配置公钥私钥，对于新手而言还是比较麻烦的；另一种是http方式，这里有一个办法可以让git记住密码，避免每次都需要输入密码\n1 2 3 4 5 6 7  1. touch ~/.git-credentials 2. 将 https://{username}:{password}@github.com 写入该文件 3. git config --global credential.helper store 就可以使得git记住密码了 4. 此时查看 ~/.gitconfig，发现多了一项 [credential] helper = store   centos系统上某些软件，比如gcc、python等版本过低的解决方案 在CentOS Server上，经常会遇到某些软件依赖版本过低的问题，比如CentOS 6.5的python是2.7版本的，gcc是4.2版本的，那么我们如何获得一个干净的、与原版本无冲突的运行环境呢。CentOS系提供了一个叫SCL的工具，可以帮我们实现目的\n1 2 3 4 5 6  $ sudo wget http://people.centos.org/tru/devtools-1.1/devtools-1.1.repo -P /etc/yum.repos.d $ sudo sh -c \u0026#39;echo \u0026#34;enabled=1\u0026#34; \u0026gt;\u0026gt; /etc/yum.repos.d/devtools-1.1.repo\u0026#39; $ sudo yum install devtoolset-1.1 $ scl enable devtoolset-1.1 bash $ gcc --version # 通过devtoolset工具可以暂时提高gcc版本，而不更改之前服务器的配置，这个很有效果，高版本的gcc会智能保留symbol。   1 2 3 4 5  # CentOS 6.5 sudo yum install centos-release-SCL sudo yum install python27 scl enable python27 bash python --version   ubuntu系统上某些软件，比如gcc等版本过高的解决方案 与CentOS相反，debian系发行版的软件版本都很高，Ubuntu 16.04的gcc 版本已经到了5.2，然而编译一些早期linux内核的话，需要gcc-4.7左右的版本，这时候我们怎么办呢，有两个方法：\n 通过apt安装低版本gcc  sudo apt-get install gcc-4.7 在编译linux 内核时， make CC=gcc-4.7 即可   update-alternatives可以帮忙更改符号链接，指向不同版本的gcc  参考链接1 参考链接2 附赠    python的matplotlib库实现绘制图标  sudo apt-get install python-matplotlib  参考链接 example\npython使用requests库发送http请求 参考链接\npython解析命令行参数：argparse 参考链接\ngit比较两次commit的差异 通过比较两次commit的代码差异，能够快速理解此次commit的目的，理解作者意图\n git log  查看commit历史    1 2 3 4 5 6 7 8 9 10 11  commit 2279c3f4a8a42e696a0f34e6e9b6289487da92c1 Author: bg2bkk \u0026lt;bg2bkk@gmail.com\u0026gt; Date: Sun Mar 13 09:12:26 2016 +0800 add SO_REUSEADDR和SO_REUSEPORT.md commit 2b9d85f8427c5ca9e4f9c128c22acd280eb94405 Author: bg2bkk \u0026lt;bg2bkk@gmail.com\u0026gt; Date: Sat Mar 12 01:16:00 2016 +0800 add 采用二级指针实现单链表操作 单链表翻转 删除单链表结点    git diff commit 2279c3f4a8a42e696a0f34e6e9b6289487da92c1 2b9d85f8427c5ca9e4f9c128c22acd280eb94405  git返回强制返回某次提交  git log git reset 5f4769a98985b5acfea45462df27830e51a75145 \u0026ndash;hard  可见commit号很重要    iptables允许端口被外网访问 防火墙设置，配置1985端口可以被外网访问\n sudo iptables -A INPUT -m state \u0026ndash;state NEW -m tcp -p tcp \u0026ndash;dport 1985 -j ACCEPT  tcpdump过滤指定标志的packet 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  # tcp包里有个flags字段表示包的类型，tcpdump可以根据该字段抓取相应类型的包： # tcp[13] 就是 TCP flags (URG,ACK,PSH,RST,SYN,FIN) # Unskilled 32 # Attackers 16 # Pester 8 # Real 4 # Security 2 # Folks 1 #抓取fin包： tcpdump -ni any port 9001 and \u0026#39;tcp[13] \u0026amp; 1 != 0 \u0026#39; -s0 -w fin.cap -vvv #抓取syn+fin包： tcpdump -ni any port 9001 and \u0026#39;tcp[13] \u0026amp; 3 != 0 \u0026#39; -s0 -w syn_fin.cap -vvv #抓取rst包： tcpdump -ni any port 9001 and \u0026#39;tcp[13] \u0026amp; 4 != 0 \u0026#39; -s0 -w rst.cap -vvv   参考链接\n查看进程的内存占用情况 用Ternary Search Tree代替Trie Tree后，我想知道我的进程内存占用有多大区别。\n  ps -e -o \u0026lsquo;pid,comm,args,pcpu,rsz,vsz,stime,user,uid\u0026rsquo; | grep MyDict\n rsz是实际占用内存，单位是KB    pmap -d pid\n  ","date":"2016-07-24T16:36:33+08:00","permalink":"https://bg2bkk.github.io/p/effective-tips-in-daily-work/","title":"effective tips in daily work"},{"content":"nrf51822的dfu与别的芯片的空中升级几乎没有差别，以ESP8266为例，本次启动是从启动点bank0启动，空中升级的过程是，从远程网络服务器获取固件并写在bank1中，校验成功后设置下次启动点为bank1，重启后升级成功；nrf51822有点不同的是，空中升级通过ble获取固件并写入flash的bank1后，校验成功会擦除bank0，将bank1内容复制到bank0中，然后重启。\n我的芯片是nrf51822 QFAA，16KB Ram，256KB Flash，使用SDK10。nrf51822启动时，bootloader检查是否进入dfu流程中。bootloader采用 SDK_10_PATH/examples/dfu/bootloader/pca10028/dual_bank_ble_s110，该例程启动时读取button4状态，如果被按下，说明需要进入dfu状态，在讯连的板子上没有button4，所以改用button0。\n  Keil MDK实现空中升级\n  如上链接所示的过程写的比较详细\n 准备工作  softdevice: SDK_10_PATH/components/softdevice/s110/hex/s110_nrf51_8.0.0_softdevice.hex bootloader: SDK_10_PATH/examples/dfu/bootloader/pca10028/dual_bank_ble_s110 ble application: SDK_10_PATH/examples/ble_peripheral/ble_app_uart nrf-Connect，主要使用hex2bin.exe和怎样制作DFU初始化包 Keil MDK4/5 Master Control Panel，采用最新版3.10.0.14  制作升级包        制作bootloader，采用dual_bank_ble_s110\n dual_bank_ble_s110的flash和ram布局  nrf51822 QFAC 32KB Ram 256 KB Flash  flash  start 0x3C000 length 0x3C00   ram  ram1  start 0x20002C00 length 0x5380   ram2  start 0x20007F80 length 0x80 NoInit       nrf51822 QFAA 16KB Ram 256 KB Flash  flash  start 0x3C000 length 0x3C00   ram  ram1  start 0x20002C00 length 0x1380   ram2  start 0x20001F80 length 0x80 NoInit         烧写bootloader  首先烧写　softdevice s110，采用nrfgo studio写入s110.hex  SDK_10_PATH/components/softdevice/s110/hex/s110_nrf51_8.0.0_softdevice.hex   烧写bootloader 重启，可以在手机的nrf Connect或者nrf Beacon看到DfuTarg，说明bootloader写成功；由于目前只有bootloader没有app，所以bootloader默认进入DFU状态      开发应用程序和升级包\n 应用程序可以在ble_peripheral中找，我习惯用ble_app_uart ble_app_uart的flash和ram布局  nrf51822 QFAC 32KB Ram 256 KB Flash  flash  start 0x18000 length 0x28000   ram  start 0x20002000 length 0x4000     nrf51822 QFAA 16KB Ram 256 KB Flash  flash  start 0x18000 length 0x28000   ram  start 0x20002000 length 0x2000       生成应用程序bin文件  MDK编译生成hex文件，伴有axf文件 生成bin文件的两种方式  keil mdk fromelf.exe  PATH:  C:\\Keil\\ARM\\ARMCC\\bin\\fromelf.exe cmd:  fromelf.exe --bin --output outfile.bin infile.axf   Android-nRF-Connect的hex2bin方式   git clone https://github.com/NordicSemiconductor/Android-nRF-Connect  path/Android-nRF-Connect/init packet handling/hex2bin.exe _build/nrf51422_xxac_s110.hex 就可以生成bin文件   推荐方式为后者，并借助keil的设置  在 option-\u0026gt;User-\u0026gt;Run User Programs After Buidl/Rebuild 的 run #1 中 填写 \u0026quot;D:\\workspace\\android\\Android-nRF-Connect-master\\init packet handling\\hex2bin.exe\u0026quot; _build/nrf51422_xxac_s110.hex 每次编译后，生成hex之后会自动调用hex2bin工具生成bin文件       制作升级包  安装Master Control Panel，我采用最新版3.10.0.14 工具：  C:\\Program Files (x86)\\Nordic Semiconductor\\Master Control Panel\\3.10.0.14\\nrf\\nrfutil.exe 命令：  nrfutil.exe dfu genpkg --application nrf51422_xxac_s110.bin --application-version 0xFFFFFFFF --dev-revision 0xFFFF --dev-type 0xFFFF --sd-req 100 nrf51422_xxac_s110.zip  参数讲解   --application-version version : the version of the application image, for example, 0xff  --dev-revision version : the revision of the device that should accept the image, for example, 1  --dev-type type : the type of the device that should accept the image, for example, 1  --sd-req sd_list : a comma-separated list of FWID values of SoftDevices that are valid to be used with the new image, for example, 0x4f,0x5a       空中升级  将zip文件传到手机 打开nrf Beacon，在dfu tab下select file，选择zip文件 点击select device选择DfuTarg 点击upload开始上传更新包 传输完成后，nrf51822重启，进入ble_app_uart应用中   手动方式  按住button0然后重新启动nrf51822，进入dfu模式 重复空中升级的手机操作        [Linux下使用armgcc和nrf工具实现DFU升级]\n 准备工作  softdevice: SDK_10_PATH/components/softdevice/s130/hex/s130_nrf51_8.0.0_softdevice.hex  采用s130，而非Keil中用的s110   bootloader: SDK_10_PATH/examples/dfu/bootloader/pca10028/dual_bank_ble_s130 ble application: SDK_10_PATH/examples/ble_peripheral/ble_app_uart nRF5x-Command-Line-Tool nrfutil 0.5.2  nrfutil master分支介绍sdk11和sdk11之前的版本用nrfutil-0.5.2，之后的sdk用nrfutil高版本，目前是2.0.0版本。     制作bootloader  SDK_10_PATH/examples/dfu/bootloader/pca10028/dual_bank_ble_s130/armgcc 由于nrf51822 QFAA蛋疼的16KB Ram，所以内存和flash布局要做相应修改，修改 SDK_10_PATH/examples/dfu/bootloader/dfu_gcc_nrf51.ld的相应布局      1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  MEMORY { /** Flash start address for the bootloader. This setting will also be stored in UICR to allow the * MBR to init the bootloader when starting the system. This value must correspond to * BOOTLOADER_REGION_START found in dfu_types.h. The system is prevented from starting up if * those values do not match. The check is performed in main.c, see * APP_ERROR_CHECK_BOOL(*((uint32_t *)NRF_UICR_BOOT_START_ADDRESS) == BOOTLOADER_REGION_START); */ FLASH (rx) : ORIGIN = 0x3C000, LENGTH = 0x3C00 /** RAM Region for bootloader. This setting is suitable when used with s110, s120, s130, s310. */ RAM (rwx) : ORIGIN = 0x20002C00, LENGTH = 0x1380 /** Location of non initialized RAM. Non initialized RAM is used for exchanging bond information * from application to bootloader when using buttonluss DFU OTA. */ NOINIT (rwx) : ORIGIN = 0x20001F80, LENGTH = 0x80 /** Location of bootloader setting in at the last flash page. */ BOOTLOADER_SETTINGS (rw) : ORIGIN = 0x0003FC00, LENGTH = 0x0400 /** Location in UICR where bootloader start address is stored. */ UICR_BOOTLOADER (r) : ORIGIN = 0x10001014, LENGTH = 0x04 }       1 2 3 4 5 6 7 8 9 10 11  flash: nrf51422_xxac @echo Flashing: $(OUTPUT_BINARY_DIRECTORY)/$\u0026lt;.hex nrfjprog --program $(OUTPUT_BINARY_DIRECTORY)/$\u0026lt;.hex -f nrf51 --sectorerase nrfjprog --reset ## Flash softdevice flash_softdevice: @echo Flashing: s130_nrf51_1.0.0_softdevice.hex nrfjprog --program ../../../../../../components/softdevice/s130/hex/s130_nrf51_1.0.0_softdevice.hex -f nrf51 --chiperase nrfjprog --reset       以上就是根据nordic的sdk10提供的官方bootloader例程和ble_app_uart应用程序实现的空中升级，只是一个最简单的实现，还需要多学习和总结\n  在应用程序中添加dfu支持\n 官方文档  方法 应用程序切换到dfu 网友供稿      如何提高ble通信速率\n csdn    ","date":"2016-07-20T15:31:44+08:00","permalink":"https://bg2bkk.github.io/p/ble_nrf51822_dfu_%E7%A9%BA%E4%B8%AD%E5%8D%87%E7%BA%A7/","title":"ble_nrf51822_dfu_空中升级"},{"content":"  nrf51822 sdk document\n  flash和ram布局\n 在armgcc文件夹里的ld文件，应用程序的ld需要严格按照51822的内存布局来， 我用的是256KB Flash和16KB的Ram，  无协议栈  flash  start 0x00000 length 0x40000 / 256KB   ram  start 0x20000000 length 0x4000 / 16KB     有协议栈  flash  start 0x18000  协议栈一般放在0x0位置，s110是80KB，即0x14000，所以应用程序的start比0x14000大就可以   length 0x28000  start+length=0x40000，注意不能越界     ram  start 0x20002000 length 0x2000 16KB的话协议栈和应用程序各占8KB，比较寒酸       如果你发现无协议栈的程序无法启动，那么你需要修改查看flash和ram的布局 如果你发现有协议栈的程序无法启动，那么你还需要关注协议栈和应用程序是否和谐相处  如果还无法启动或者不正常运行，那么你的程序可能出现了运行错误比如访问越界内存，但是单片机的话由于没有core dump所以机器崩溃但你并不知道。      Jlink\n JLink的Linux版非常方便，感觉比st-link好用一些 如何在一台电脑上搞多个JLink，还需要再学习 JLink在Ubuntu上进行带协议栈的调试还需要学习，带协议栈真是个蛋疼的事情    nRF5x-Command-Line-Tool\n nrfjprog烧写芯片工具，应该是基于Jlink的 nrfjprog \u0026ndash;eraseall 清空芯片 nrfjprog \u0026ndash;program xyz.hex -f nrf51 \u0026ndash;chiperase 烧写程序 nrfjprog -r 重启    Segger RTT使用\n 在sdk的external/segger_rtt文件夹中，记得include和添加c文件 编译方式：  armgcc: Makefile中记得使能CFLAGS += -DNRF_LOG_USES_RTT=1 Keil MDK: option中添加 -DNRF_LOG_USES_RTT   使用方式：  Keil MDK: 在新版的JLink软件(大于6.0版本)中的J-Link RTT Viewer armgcc:  JLinkRTTClient 打开连接 JLinkRTTLogger 连接nrf51822，并将log写入文件中     代码如下    1 2 3 4 5 6 7 8 9 10 11  #include \u0026#34;SEGGER_RTT.h\u0026#34;#include \u0026#34;SEGGER_RTT_Conf.h\u0026#34; main() { NRF_LOG_INIT(); SEGGER_RTT_Init(); // 两种方式 \tSEGGER_RTT_printf(0, \u0026#34;\\r\\nello,rtt\\r\\n\u0026#34;); NRF_LOG_PRINTF(\u0026#34;ADC example\\r\\n\u0026#34;); }     例程要对应sdk的版本\n 每个sdk里有很多例程，都是可以直接用keil、iar和armgcc编译的，后者就是我用的ubuntu 目前我采用的是sdk10，由于sdk10和sdk11在twi，即I2C的驱动上有差别，sdk11不能一次写超过256B字节，导致我的12864的oled不能正常工作，所以采用sdk10 但是我发现sdk11更加成熟些，目前只能暂时这样，解决方法要么是改造sdk11的twi驱动，要么是用GPIO模拟I2C控制oled，要么是等待sdk13发布    uart\n nrf51822的uart驱动使用起来比较有意思  一般我们采用115200波特率，所以需要修改 一般我们不用流控，所以将APP_UART_FLOW_CONTROL_ENABLED改为APP_UART_FLOW_CONTROL_DISABLED printf的话，Keil的microlib勾选上来；armgcc的话可以直接开搞。      1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  uint32_t err_code; const app_uart_comm_params_t comm_params = { RX_PIN_NUMBER, TX_PIN_NUMBER, RTS_PIN_NUMBER, CTS_PIN_NUMBER, APP_UART_FLOW_CONTROL_DISABLED, false, UART_BAUDRATE_BAUDRATE_Baud115200 }; APP_UART_FIFO_INIT(\u0026amp;comm_params, UART_RX_BUF_SIZE, UART_TX_BUF_SIZE, uart_error_handle, APP_IRQ_PRIORITY_LOW, err_code); APP_ERROR_CHECK(err_code);     twi / I2C\n ssd1306_128x64_oled  ssd1306是比较常用的oled驱动芯片了，各种例程很多，还便宜 可以用I2C和SPI驱动，后者比前者多2根线，所以用I2C了；实际上很多oled都可以通过改led电阻来更改驱动方式 ssd1306的话最好能够将u8g的lib移植一下，这个目前还没有做   nrf有两个twi，需要在例程中config文件夹里的头文件中将设备使能，置为1    adc\n 选对管脚    \t* 一般来说内部稳定的1.2V是比较好的选择，我选择ADC_CONFIG_REFSEL_VBG * 选对输入比例 * 可选择： * #define ADC_CONFIG_INPSEL_AnalogInputNoPrescaling (0x00UL) * 直接将待检测电压输入 * #define ADC_CONFIG_INPSEL_AnalogInputTwoThirdsPrescaling (0x01UL) * 测量带检测电压的1/2 * #define ADC_CONFIG_INPSEL_AnalogInputOneThirdPrescaling (0x02UL) * 测量带检测电压的1/3 * #define ADC_CONFIG_INPSEL_SupplyTwoThirdsPrescaling (0x05UL) * #define ADC_CONFIG_INPSEL_SupplyOneThirdPrescaling (0x06UL) * 测量电压不能大于参考电压，因此采用1.2V作为参考电压时，只使用测量电压的1/3比较安全 * adc转换的结果在adc中断里取 * [ble利用adc实现电量检测服务](http://blog.chinaunix.net/uid-28852942-id-5711152.html)   疑难杂症  armgcc: region RAM overflowed with stack  原因是sd+app的ram布局超过了芯片整体的ram大小 其实设置app start=0x20002800 length=0x1800 是刚够0x4000即16KB的，应该不会有这个问题；所以在注释掉\u0026lt;SDK_PATH\u0026gt;/components/toolchain/gcc/nrf5x_common.ld的最后一句ASSERT(__StackLimit \u0026gt;= __HeapLimit, \u0026ldquo;region RAM overflowed with stack\u0026rdquo;)并编译、烧写是可以正常工作的 内存超过布局是因为还留有一定ram给heap内存了，但是如果没有malloc等动态内存分配函数的话，是用不到heap内存的，所以将HEAP_SIZE设置为0或者512，可以编译通过  \u0026lt;SDK_PATH\u0026gt;/components/toolchain/gcc/gcc_startup_nrf51.s  .equ Heap_Size, 2048\t改为 512     另一个方法更优雅一点  在Makefile中添加ASMFLAGS += -D__HEAP_SIZE=0 如果是keil的话，Target \u0026raquo; C/C++ \u0026raquo; Preproccesor Symbols 添加 __HEAP_SIZE = 0   参考链接  课外阅读1 课外阅读2 region ram overflow after upgrading with Segger RTT        1 2 3 4 5  Linking target: nrf51422_xxac_s130.out /home/huang/workspace/nrf51822/gcc-arm-none-eabi-4_9-2015q3/bin/../lib/gcc/arm-none-eabi/4.9.3/../../../../arm-none-eabi/bin/ld: region RAM overflowed with stack collect2: error: ld returned 1 exit status Makefile:174: recipe for target \u0026#39;nrf51422_xxac_s130\u0026#39; failed make: *** [nrf51422_xxac_s130] Error 1     dfu\n 如何根据官方例程进行DFU升级，可以参考我的博客 nrf51822 dfu 升级    nordic tutorials of bluetooth low energy\n  advertising\n advertising address  gap address type  Public Address  公共地址 在IEEE 注册 设备地址终身不变   Random Static Address  可变静态地址 在设备启动时动态设置 设备断电前地址不变 默认设置   Private Resolvable Address  这种地址由identity resolving key(IRK)和一个随机数生成 可以更改，甚至可以在一个连接的生命周期内更改，从而避免被位置设备标定和跟踪 设备只能被拥有其下发IRK的设备解析，允许他们识别自己   Private Non-Resolvable Address  不常用       advertising type  non-connectable  ibeacon   connectable   advertising data  限制31bytes 可以在scan response data中再加31bytes，这样在被扫描的时候可以总共发送62bytes的负载数据      service\n the Generic Attribute Profile, GATT  he GATT Profile specifies the structure in which profile data is exchanged. This structure defines basic elements such as services and characteristics, used in a profile.  GATT指定了描述数据传输的结构体，这个结构体定义描述了基本元素：services服务和characteristics特征。 通俗来讲，GATT是一组描述使用BLE进行数据的绑定、展现和传输的规则     Services  A service is a collection of data and associated behaviors to accomplish a particular function or feature. [\u0026hellip;] A service definition may contain […] mandatory characteristics and optional characteristics.  服务，The Bluetooth Core Specification 定义为，一个服务是数据及数据的关联操作的集合，用于实现特定功能。一个service包括一个必须要有的characteristics和几个可选的characteritics。 换句话说，一个service是信息的集合，比如传感器的值。Bluetooth SIG预先定义了一些服务，比如battery service，比如Heart Rate service，你也可以自定义服务。     Characteristics  A characteristic is a value used in a service along with properties and configuration information about how the value is accessed and information about how the value is displayed or represented.  特性，官方定义是在一个服务里，所包含的属性值和配置信息，用于确定数据值如何被访问，如何呈现。 换句话说，特征决定了值和信息如何被呈现和访问。 Security parameters，units和其他相关元数据也封装在特征中     三者的关系相当于是，在房间里有柜子，柜子里有抽屉。GATT是房间，services是柜子，而特征就是存东西的抽屉。 Universally Unique ID, UUID  UUID是我们在BLE中经常看到的一个缩写，这是一个独一无二的数字，用来表示一个service、特征或者描述符。通过传输这些ID，peripheral设备可以向centeral设备通知自己提供的服务。 有两类UUID  16-bit UUID  比如预先定义的Heart rate service是0x180D，Heart Rate Measurement characteristic是0x2A37. 16-bit UUID是出于节省内存和能量来设计的，你只能用来表示已经定义好的这些UUID   128-bit UUID  128-bit UUID可以表示自定义的UUID，一般来说可以自定义UUID作为base UUID，比如4A98xxxx-1CC4-E7C1-C757-F1267DD021E8，中间的x表示你可以将service和特征的UUID填充进去 nRFgo Studio可以生成UUID 该类随机生成的UUID只有3e~-39的概率是一样的，所以如果是随机生成的，一般不会冲突          ble connection parameters\n Connection Interval Slave latency Connection supervision timeout    changing Gatt Characteristic Properties\n    ","date":"2016-07-15T03:12:18+08:00","permalink":"https://bg2bkk.github.io/p/ble-%E5%92%8C-nrf51822-%E5%BC%80%E5%8F%91/","title":"BLE 和 NRF51822 开发"},{"content":"  智能门锁\n 推送服务器instapush 智能门锁内含推送服务器端php代码    blynk.cc\n First drag-n-drop IoT app builder for Arduino, Raspberry Pi, ESP8266, SparkFun boards, and others    marsTechHan的天气检测\n  esp8266开发板的对比\n  mqtt简介\n  nodemcu的wifi配置经\n src topic    esp8266 user guide\n  服务器和智能硬件的互相通信方案\n google \u0026lsquo;server push message to nodemcu\u0026rsquo;    物联网的协议和标准\n  websocket官网\n  mqtt\n  esp8266的smartconfig\n 示例    例子\n  sming hub\n  Rock solid esp8266 wifi mqtt, restful client for arduino\n  8266 mcu\n  esp8266的GPIO\n esp8266模块有17管脚，记做GPIO0 ~ GPIO16 启动时，所有IO口都是输入模式，GPIO0~GPIO15可以配置为INPUT、OUTPUT和INPUT_PULLUP，GPIO16可以配置为INPUT、OUTPUT和INPUT_PULLDOWN_16，GPIO16是一个比较特殊的管脚，可用于睡眠唤醒 小模块，比如esp-01只会留出GPIO0和GPIO2；除了esp-01，其他模块也还留了GPIO15供使用；用户可以通过这些IO来控制模块的使用方式  GPIO0和GPIO2共同用于决定启动方式（加上拉电阻）,GPIO0-GPIO2值为H-H时，从spi flash启动，为L-H时，从串口UART启动；而当GPIO15为高时，模块从SD卡启动   GPIO6到GPIO11用于esp8266读写flash存储，所以一般不要用他们；写flash的方式，如果是Dual IO，用2根数据线，总共4根线实现读写flash，如果是Quad IO，用4根数据线，总共6根线读写flash；因此一般来说还是不要用GPIO6到GPIO11之间的管脚了。esp8266有17个管脚，其中6个用于spi flash,如果想使用HSPI，还得借助于GPIO12到GPIO15； GPIO1和GPIO3分别是UART0的Tx和Rx GPIO4、GPIO5、GPIO12、GPIO13、GPIO14可以用作普通IO口 GPIO15和GPIO13可以复用为UART0的管脚，用于读取其他设备数据；当SPI flash采用DIO方式时，GPIO9和GPIO10可以作为普通IO口使用；GPIO2可以作为UART1的输出口，一般不怎么用；其他复用信息可以参考 对于nodemcu而言，它对IO口还有一种编号方式，nodemcu使用Dx，比如D0来标记IO口，这和esp8266的GPIO不一致，具体见表格    ","date":"2016-07-13T17:03:29+08:00","permalink":"https://bg2bkk.github.io/p/nodemcu_smart_home/","title":"nodemcu_smart_home"},{"content":" sudo apt-get install postgresql pip install psycopg2 su postgres pgcli create database testdb alter user postgres password huang;  ","date":"2016-07-08T00:37:41+08:00","permalink":"https://bg2bkk.github.io/p/postgresql%E5%88%9D%E6%AD%A5%E4%B8%8A%E6%89%8B/","title":"postgresql初步上手"},{"content":"  eclipse下载\n neon http://ftp.jaist.ac.jp/pub/eclipse/technology/epp/downloads/release/neon/R/eclipse-jee-neon-R-linux-gtk-x86_64.tar.gz system workbench:    stlink 驱动\n http://erika.tuxfamily.org/wiki/index.php?title=Tutorial:_STM32_-_Integrated_Debugging_in_Eclipse_using_GNU_toolchain\u0026oldid=5474 http://www.st.com/content/st_com/en/products/embedded-software/development-tool-software/stsw-link004.html# Linux: https://github.com/texane/stlink  sudo apt-get install autoreconf sudo apt-get install libusb-1.0-0 libusb-1.0-0-dev make \u0026amp;\u0026amp; make -j \u0026amp;\u0026amp; make install sudo ./st-util  之前还需要做udev.rules，现在发现不需要     用法：http://erika.tuxfamily.org/wiki/index.php?title=Tutorial:STM32-_Integrated_Debugging_in_Eclipse_using_GNU_toolchain\u0026amp;oldid=5474    arm gcc compiler\n sudo apt-get install gcc-arm-none-eabi    插件和eclipse环境配置：\n  eclipse cdt 插件\n https://eclipse.org/cdt/downloads.php    http://gnuarmeclipse.sourceforge.net/updates\n gnu arm eclipse plugins的几种安装方法 http://gnuarmeclipse.github.io/plugins/install/ http://gnuarmeclipse.github.io/eclipse/workspace/preferences/ http://gnuarmeclipse.github.io/plugins/packs-manager/    ac6 system workbench: http://www.ac6-tools.com/Eclipse-updates/org.openstm32.system-workbench.site/\n 有了它就可以ac6 debugger了，但是没办法，neon不支持 http://www.emcu.it/STM32/What_should_I_use_to_develop_on_STM32/stm32f0_linux_dvlpt.pdf      如何使用eclipse新建工程\n 可以安装以上两个插件后，从eclipse新建ac6工程，下载相应库即可，ac6保证这个好使； 可以从cube新建工程sw4stm32类型的工程，然后引入SW4STM32工程    如何调试工程\n  debugger: AC6\t普通的\n 使用ac6调试, http://www.xlgps.com/article/387805.html    debugger: hardware debugger configuration\n http://stm32discovery.nano-age.co.uk/open-source-development-with-the-stm32-discovery/getting-hardware-debuging-working-with-eclipse-and-code-sourcey neon还不支持ac6 debugger，所以只能用后者 http://www.openstm32.org/forumthread3023    create debugging configuration\n http://www.openstm32.org/Creating+debug+configuration 开始debug      st-flash 烧录工具 https://www.youtube.com/watch?v=HKX12hJApZM\n  openocd https://www.youtube.com/watch?v=ZeUQXjTg-8c\n ./configure \u0026ndash;enable-verbose \u0026ndash;enable-verbose-jtag-io \u0026ndash;enable-parport \u0026ndash;enable-jlink \u0026ndash;enable-ulink \u0026ndash;enable-stlink \u0026ndash;enable-ti-icdi make -j \u0026amp;\u0026amp; sudo make install openocd -f tcl/board/stm32f4discovery.cfg    openocd是debug server，3333端口\n  eclipse需要debug configuration\n  eclipse的设置\n 代码自动提示：http://blog.csdn.net/u012750578/article/details/16811227    elua\n  1 2 3  openocd -f ../../openocd-0.9.0/tcl/board/stm32f429discovery.cfg -c \u0026#34;init\u0026#34; -c \u0026#34;reset halt\u0026#34; -c \u0026#34;sleep 100\u0026#34; -c \u0026#34;wait_halt 2\u0026#34; -c \u0026#34;echo \\\u0026#34;--- Writing elua_lua_stm32f4discovery.bin\\\u0026#34;\u0026#34; -c \u0026#34;flash write_image erase elua_lua_stm32f4discovery.bin 0x08000000\u0026#34; -c \u0026#34;sleep 100\u0026#34; -c \u0026#34;echo \\\u0026#34;--- Verifying\\\u0026#34;\u0026#34; -c \u0026#34;verify_image elua_lua_stm32f4discovery.bin 0x08000000\u0026#34; -c \u0026#34;sleep 100\u0026#34; -c \u0026#34;echo \\\u0026#34;--- Done\\\u0026#34;\u0026#34; -c \u0026#34;resume\u0026#34; -c \u0026#34;shutdown\u0026#34; st-flash --reset write elua_lua_stm32f4discovery.bin 0x8000000   ","date":"2016-07-06T12:51:05+08:00","permalink":"https://bg2bkk.github.io/p/stm32_eclipse_openocd_stlink/","title":"stm32_eclipse_openocd_stlink"},{"content":" 现代C++类型系统  ","date":"2016-06-11T12:27:29+08:00","permalink":"https://bg2bkk.github.io/p/modern_c-_%E7%8E%B0%E4%BB%A3c-/","title":"modern_c++_现代C++"},{"content":" 我自己摸索出来的模型 https://blog.golang.org/pipelines 上个链接里的内容非常的golang，我们在讲这段代码非常golang的时候，我们说的是协程、channel以及二者的并发实践；我们在讲某段lua代码非常的lua时候，我们说的是coroutine和metatable；我们在讲某段c代码非常的有c味道的时候，往往说的是指针、多级指针和void灵活指向的类型；我们在讲某段cpp代码非常的c++的时候，我们说的是它的封装、类库和内存模型  ","date":"2016-06-08T11:32:32+08:00","permalink":"https://bg2bkk.github.io/p/golang_concurrency_patterns/","title":"golang_concurrency_patterns"},{"content":" http://www.lintcode.com/zh-cn/problem/compare-strings/ http://taop.marchtea.com/02.0.html http://taop.marchtea.com/01.02.html  ","date":"2016-06-05T22:47:08+08:00","permalink":"https://bg2bkk.github.io/p/compare_strings_%E6%AF%94%E8%BE%83%E5%AD%97%E7%AC%A6%E4%B8%B2/","title":"compare_strings_比较字符串"},{"content":"写go并发代码有点疲劳，那就A个题吧。我觉得LintCode上的题目都很不错，有难有易，循序渐进的，随手选一道题来做吧。\n选择了链表插入排序，写起来不那么容易，但是也有调试的快感，其实对于难题，我们需要做到的是心思缜密、抽丝剥茧一步步实现；对于中等题目，我们需要抓住本质，一击制敌；在编码过程中，心里有时刻有代码执行时间复杂度和空间占用的底，逐渐养成这个习惯；编码过程中同样重要的还有编码风格，如果能够简洁明了的表达程序逻辑，就追求简洁，如果变量较多，需要在变量命名的时候注意甄别，对于写出的代码，尽量追求逻辑清晰风格良好，这是一个程序员的基本素质。\n 用插入排序对链表排序\n 思路：插入排序的特点是，待排序的节点前面所有节点都是已排序的，同时记录已排序部分的末尾，也就是待排序节点的prev节点，所以每次拿带排序节点依次从头比较，直到比较到自己头上；在比较过程中，如果没有合适的位置，最终比较到自己头上，说明待排序节点可以直接补在已排序节点的后面；如果有合适的位置，就直接break，然后待排序节点从链表取出，prev节点的next指向待排序节点的next，保存当前break处的节点，待排序节点占据该节点位置，并将待排序节点的next指向break处节点，完成插入。\n完整代码地址\n codelist  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43  /** * Definition of ListNode * class ListNode { * public: * int val; * ListNode *next; * ListNode(int val) { * this-\u0026gt;val = val; * this-\u0026gt;next = NULL; * } * } */ class Solution { public: ListNode *insertionSortList(ListNode *head) { // write your code here \tif(!head || !head-\u0026gt;next) return head; ListNode *sortedHead = head; ListNode *prev = head; ListNode *node = prev-\u0026gt;next; while(node){ ListNode **p = \u0026amp;sortedHead; while(*p!=node){ if((*p)-\u0026gt;val \u0026gt; node-\u0026gt;val){ break; } p = \u0026amp;((*p)-\u0026gt;next); } if(*p == node){ prev = node; node = node-\u0026gt;next; } else { ListNode *next = *p; *p = node; prev-\u0026gt;next = node-\u0026gt;next; (*p)-\u0026gt;next = next; node = prev-\u0026gt;next; } } return sortedHead; } };   ","date":"2016-06-05T22:27:39+08:00","permalink":"https://bg2bkk.github.io/p/insertionsortlist_%E9%93%BE%E8%A1%A8%E6%8F%92%E5%85%A5%E6%8E%92%E5%BA%8F/","title":"insertionSortList_链表插入排序"},{"content":" http://purecpp.org/?p=108  ","date":"2016-06-02T10:08:04+08:00","permalink":"https://bg2bkk.github.io/p/cpp_callable_object_%E5%8F%AF%E8%B0%83%E7%94%A8%E5%AF%B9%E8%B1%A1/","title":"cpp_callable_object_可调用对象"},{"content":" metatable and metamethod  ","date":"2016-05-31T16:22:49+08:00","permalink":"https://bg2bkk.github.io/p/%E8%AE%A9%E4%BD%A0%E7%9A%84lua%E4%BB%A3%E7%A0%81%E6%9B%B4%E5%8A%A0%E7%9A%84lua/","title":"让你的lua代码更加的lua"},{"content":"面试的时候，面试官问我哈希算法，我表示奇怪，因为，哈希算法，不就那么几个嘛，我们要理解这么多吗？这是一个我完全没有想到的领域啊\n","date":"2016-05-31T15:54:21+08:00","permalink":"https://bg2bkk.github.io/p/hash%E7%9B%B8%E5%85%B3%E7%9A%84%E4%B8%80%E4%BA%9B%E7%9F%A5%E8%AF%86/","title":"hash相关的一些知识"},{"content":"说实话我对很多面试题是发怵的，很多题真的觉得好难；有时候自我安慰工作中用不到，太难的算法只是用来锻炼思维和编码能力；然而另一些时候发现由于缺乏相应训练和知识储备，面对工作时由于算法和数据结构能力的缺失导致解决问题时候颇感棘手；所以说，面对算法或者算法相关的面试题，是真能考出程序员的水平的。\n算法作为面试题的重点时，其实考的并不特别难，一来为了对人才有一定区分度，而不是故意筛人，二来面试时间限制太难的算法不能保证完成。理想情况下我们最好能结合实际工作进行算法实践。\n我们需要多想多写多练习，从简单的开始，往难的进发。\n说句不好听的，面试题可谓是千篇一律吧。\n知乎上SimonS列出的算法题比较经典\n1 2 3 4 5 6 7 8 9 10 11  针对本科和硕士应届生的算法面试题： 1、假设淘宝一天有5亿条成交数据，求出销量最高的100个商品并给出算法的时间复杂度。 2、给一列无序数组，求出中位数并给出算法的时间复杂度。 3、输入一个整型数组，求出子数组和的最大值，并给出算法的时间复杂度。 4、给出10W条人和人之间的朋友关系，求出这些朋友关系中有多少个朋友圈（如A-B、B-C、D-E、E-F，这4对关系中存在两个朋友圈），并给出算法的时间复杂度。 ...    1、假设淘宝一天有5亿条成交数据，求出销量最高的100个商品并给出算法的时间复杂度。   思路：对这5亿条数据按照商品id进行哈希，并对哈希值当后几位相同时写到同一文件中，这样相同商品就会写在同一文件中，然后可以对每个文件再细分，从容的进行统计。统计每个商品id的成交量后，如果不能一次load进所有内存，这个时候可以采用堆排序的方式维护小顶堆取出top K；如果能load进内存的话，采用其他排序比如快排就可以取出top K的商品了。对交易记录进行哈希分类的时间复杂度是O(N)，采用小顶堆取出top K个元素的时间复杂度是O(Nlogk)，也就是O(N)\n  2、给一列无序数组，求出中位数并给出算法的时间复杂度。   思路：仅仅取出中位数的话，如果对整个数组排序，会显得得不偿失；采用快排中用到的partition方法，选择数组第一个值为哨兵，比它大的数组元素放在数组右边，比他小的放在数组左边；分开后，如果此时该元素的下标index是N/2的话，则它就是中位数，否则如果它的下标小于 N/2，说明中位数在它的右边，那么以该元素为左边界，以原数组右边界为右边界，寻找第N/2 - index大的元素；如果它的下标大于N/2的话，采用相似方法。这种方法的时间复杂度是O(NlgN)，实际上和快排的区别在于去掉了merge操作和不关心部分的排序这两项工作\n  3、输入一个整型数组，求出子数组和的最大值，并给出算法的时间复杂度。   思路：典型的动态规划问题，但是作为算法比较薄弱的我，选择先从本办法入手\n  4、给出10W条人和人之间的朋友关系，求出这些朋友关系中有多少个朋友圈（如A-B、B-C、D-E、E-F，这4对关系中存在两个朋友圈），并给出算法的时间复杂度。   思路：无向图\n ","date":"2016-05-31T15:22:18+08:00","permalink":"https://bg2bkk.github.io/p/%E5%85%B3%E4%BA%8E%E9%9D%A2%E8%AF%95%E9%A2%98%E7%9A%84%E4%B8%80%E4%BA%9B%E6%88%91%E7%9A%84%E6%80%9D%E8%80%83/","title":"关于面试题的一些我的思考"},{"content":"  Linux内核参数注释\n TCP参数注释及调优 man tcp    内核为tcp维护的四个定时器\n 重传定时器  用于重传没有收到确认的报文；在发送报文时启动重传定时器，如果在定时器时间内收到确认，则撤销定时器；若在收到确认前已经超时，则重传报文并复位定时器。   坚持定时器  当接收方的接收通告窗口是0时，会向发送方发送零窗口报文段；稍后接收方窗口不为0时，会向发送方发送窗口更新报文（非0报文段）；如果发送方没有收到这个报文，则一直会认为接收方还是窗口为0所以继续等待；而接收方此时并不知道这个报文丢失，所以处于等待发送状态；通信双方陷入了死锁状态 因此TCP为每个连接设置坚持定时器，当发送方收到零长窗口的包时，会启动该定时器；当该定时器到期，发送方会发送探测报文段（只有一个字节，有序号，但是该序号永远不需要确认，也会被忽略掉），探测报文提醒接收端，问问是不是还是零长窗口 坚持计时器的初始时长是重传时间；第一次探测报文发出，如果没有收到接收端的窗口更新响应，则在坚持计时器超时后，复位该计时器，计时时间加倍，然后发送新的探测报文，重复这个过程；直到定时器时长超过60s为止，开始每60s重复一次。   保活定时器  保活定时器是TCP的keepalive设置；如果客户端故障，链路上没有数据，而服务端不能一直等待，所以需要保活定时器。服务端每次收到对端报文，都会重置保活定时器，默认是7200s，之后再每隔75s重复发送探测报文，连续10次没有回应的话就放弃这个连接。   2MSL定时器  第一种情况：被动关闭方发出FIN包并将状态从CLOSE_WAIT转换到LAST_ACK后，主动关闭方从FIN_WAIT2转到TIME_WAIT状态，并回复ACK；这个ACK到达接收方最大需要一个MSL时间，接收方收到ACK后，可以进入CLOSED状态；而如果接收方没有收到ACK，则会认为发送方可能没有收到刚才发的FIN包，所以会从新发送FIN包，这个FIN包到达主动关闭方需要一个MSL时间；因此，如果主动关闭方能等待2个MSL时间，可以在应付被动关闭方再次发送过来的FIN包并回复ACK，保证二者都能进入CLOSED状态 第二种情况：由于等待了2个MSL时间，之前双方发送的报文都会消失不见，避免下一个采用同样地址和端口的新连接遇到这些不速之客；否则如果等待时间短，新连接可以很快使用这个端口和地址，遇到之前的FIN包什么的，造成误解。      tcp的超时重连机制\n tcp_syn_retries     Number of times initial SYNs for an active TCP connection attempt will be retransmitted. Should not be higher than 127. Default value is 6, which corresponds to 63seconds till the last retransmission with the current initial RTO of 1second. With this the final timeout for an active TCP connection attempt will happen after 127seconds.\n 对于一个活跃的TCP连接来说，SYN报文的重传次数。这个次数应该小于127，默认是6次，初始RTO是1s，这意味着在63s后最后一次重传，所以在第127s的时候这个tcp连接会超时o\n我们将会在1s、2s、4s、8s、16s、32s、64s进行重传\n [tcp的报文超时重传机制](rto and retransmission)  google \u0026lsquo;tcp 超时处理\u0026rsquo; computing tcp\u0026rsquo;s retransimission timer 内核有两个重要的超时重传选项    1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  tcp_retries1 - INTEGER This value influences the time, after which TCP decides, that something is wrong due to unacknowledged RTO retransmissions, and reports this suspicion to the network layer. See tcp_retries2 for more details. RFC 1122 recommends at least 3 retransmissions, which is the default. tcp_retries2 - INTEGER This value influences the timeout of an alive TCP connection, when RTO retransmissions remain unacknowledged. Given a value of N, a hypothetical TCP connection following exponential backoff with an initial RTO of TCP_RTO_MIN would retransmit N times before killing the connection at the (N+1)th RTO. The default value of 15 yields a hypothetical timeout of 924.6 seconds and is a lower bound for the effective timeout. TCP will effectively time out at the first RTO which exceeds the hypothetical timeout. RFC 1122 recommends at least 100 seconds for the timeout, which corresponds to a value of at least 8.    tcp_retries1  在发生超时，tcp没有收到报文ack的情况下，会进行重传；重传次数取决于该选项，默认是3次；初次重传时间间隔是0.2s，每次重传的时间间隔加倍，0.2、0.4、0.8、1.6、3.2s 超过这个时间后，则认为发生了超时，向网络层报告这个怀疑，底层的IP和ARP开始接管，去寻找所要连接的对端机器   tcp_retries2  当RTO超时重传，仍然没有被回复确认包时。给定一个值N，一个假想的TCP连接会随着初始RTO时间进行指数增长补偿，重传N次，在第N+1次时连接被干掉。 默认值是15次，即924.6s，这是一个有效超时的下限；TCP将在超出这个时间后的第一个RTO中超时； RFC1122建议至少这个值是100s，就是说重传8次 关于RTO的计算，参考RFC和以下链接：  RTO和RTO在linux上的实现 RTO的计算方法一 RTO的计算方法二 RTO的修改方法  rfc1323 格式较好的地址     聊一聊重传次数  值得一看，目前我对下文还有疑问，并且认为超时时间只和retries2有关。   min_rto设置可以通过ip route设置    1 2 3  如果RTT较大，比如RTO初始值计算得到的是1000ms 那么根本不需要重传15次，重传总间隔就会超过924600ms。 比如我测试的一个RTT=400ms的情况，当tcp_retries2=10时，仅重传了3次就放弃了TCP流   \t* RTO_MIN是动态的一个值 \u0026lt;!-- * 超时后，对端发送RST包，终止连接；connect返回结果是Connection time out 110 --\u0026gt; * [导致TCP重传的情况](http://www.voidcn.com/blog/gogokongyin/article/p-5803363.html) * 报文中途被丢弃，或者ttl到期 * 报文的ACK在中途丢失 * 接收端异常，并不发送ACK给发送端 * 判断一个报文是重传报文 * 序列号突然下降。由于是累计确认的，某个数据包丢失的话，后面的数据包都不会被确认接收；所以序列号下降很有可能是被重传的报文 * 如果某一时刻出现两个序列号、长度等相同的包，则其中一个包肯定是重传的   TCP连接占用内存大小  tcp_rmem min mid max 单个TCP连接的读内存占用，系统限制；单位是byte，大小是几KB到十几MB tcp_wmem min mid max 单个TCP连接的写内存占用 tcp_mem min mid max 系统中tcp整体内存使用，单位是4k或者8k大小的页    SO_SNDBUF和SO_RCVBUF可以基于setsockopt来限制单个tcp的读写缓存，但是会受限于上述的限制；高于或者低于限制时，会被替换\n读写缓存用于缓存对端的TCP报文，读缓存用于缓存两种报文：一种是无序的落在接收滑动窗口中的TCP报文，等待有序报文；另一种是有序报文，但是没有来得及被应用程序读取的TCP报文；写缓存也一样\n读写缓存不是固定的，是在使用中根据使用情况分配的；如果TCP连接非常清闲，读写缓存的大小会降到0；而如果TCP连接非常繁忙，以读缓存为例，如果缓存报文超过缓存大小，则新来报文将被丢弃；持续一段时间后，将向对端发送接收窗口为0的报文\n  TCP长连接\n  SO_KEEPALIVE套接口选项\n SO_KEEPALIVE保持连接检测对方主机是否崩溃，如果2小时内该socket在任一方向都没有数据交换，TCP自动发送给对方一个存活探测分节（keepalive probe） 存活探测分节是一个对方必须响应的TCP分节，返回有三种情况：  对方接收一切正常：以期望的ACK响应 对方已崩溃并已重新启动：以RST响应，socket错误为ECONNRESET，socket被关闭 对方无任何响应：开始根据tcp_keepalive_time设置的重传次数开始重传，相隔75s一次，默认9次,11分钟多之后放弃。socket错误是ETIMEOUT，socket被关闭。   因此如果我们使用系统的保活探测机制，可能在2小时之后才能感知到tcp连接不存在。（方法是设置SO_KEEPALIVE为1） 所以可以通过setsockopt来设置这个保活机制，TCP_KEEPIDLE、TCP_KEEPINTVL和TCP_KEEPCNT，可以让时间小一点。 默认设置  net.ipv4.tcp_keepalive_intvl = 75\nnet.ipv4.tcp_keepalive_probes = 9\nnet.ipv4.tcp_keepalive_time = 7200\n    传输层协议 TCP/UDP\n  TCP连接的保活和异常检测\n TCP通讯时对侧主机崩溃或者网络异常的退出    如果链路空闲，此时如果是系统的保活机制，空闲7200s后开始发送探测报文，每隔75s发送一次，共持续9次；那么我们可能需要在2小时之后才能发现这个tcp连接断开，这是不可想象的\n此时tcp的其他机制可以起作用：[tcp超时重传机制](rto and retransmission)。tcp_retries2参数和TCP_RTO_MIN共同确定的超时时间，如果tcp_retries2是15的话，这个时间是924.6s；如果设置为8，则是100s左右；设置为5的话，46.5s左右就能检测出超时了。 因此在本地网络正常，对侧网络断开或者对侧主机崩溃时，发出探测包，此时本地socket正常，所以写操作没有问题；如果该报文在tcp_retries2设置的超时时间后没有回应，则判断超时，可以关闭socket了。\n* [TCP保活报文](http://www.netis.com/flows/2012/11/01/tcpkeepalive/) * 保活探测报文是将最近TCP报文的序号减1，并设置1个byte，payload为00的数据报文 * 保活回复报文将是对其的回应   深入理解socket网络异常   客户端连接了服务端未开放未监听的端口\n 这种情况下服务端会对收到的SYN回应一个RST（RFC793）；客户端收到RST后终止连接，进入CLOSED状态；connect返回ECONNREFUSED 111错误，错误信息：connect refused    客户端与服务端之间网络不通\n connect返回主机不可达  如果给出的是一个不可访问的地址，比如不存在的本地网络地址，或者DNS解析失败时，会返回这个错误。在Linux上，错误码是EHOSTUNREACH 113，错误信息：No route to host   connect返回连接超时  连接超时，客户端的SYN包消失，或者没有收到ACK，就会超时重传SYN；重传间隔时间是1s、2s、4s、8s、16s、32s，默认为6次，第6次SYN会经过64s后超时；也就是说127s后，connect返回ETIMEDOUT      通信过程中会遇到哪些问题呢：\n  通信双方之间网络断开，双方也不互相发送数据\n 双方都对网络断开无感知，在没有SO_KEEPALIVE的情况下，双方都会保持ESTABLISHED    网络断开，一方给另一方发送数据\n 首先接收方是对网络断开无感知的；理论上讲发送方在重传一定次数后，报超时错误；而实际上，可能发送方会显示发送成功，但接收方一定没有收到数据，原因可能是：  写在本机的TCP写缓存中；要么缓存写满后不能再往缓存中写数据，向客户端报错，当然这种情况比较少见；更多情况是写缓存中有一定数据后，启动发送，多次重传后报超时错误 缓存在本机网络的某个NAT的缓存中，由NAT回复了ACK包   因此这里需要说的是，并不是TCP显示发送成功，对方就一定能收到；这个时候只是内核或者本机所处网络的NAT收到了应用程序的数据 TCP可以保证的是可靠、有序的传输，这个意思是TCP保证收到有序数据包时可以保证可靠传输，而不是发送成功数据包时可靠传输    网络断开，一方等待另一方发送数据\n 等待的接收方是不能感知到网络已断开的，如果采用阻塞型的read系统调用等，会一直阻塞下去；当有SO_KEEPALIVE设置时，可以依赖系统的keepalive机制；应用程序可以设置超时时间来确保read不要被永久阻塞    TCP协议栈在各平台的实现不尽相同，在Linux下，Ctrl+C结束程序，协议栈会发送close，而Windows会发送RST段；如果没有调用close而结束，Linux会发送FIN包，而Win会发送RST包\n  crash的一端发送FIN包，相当于调用close，\n 未崩溃的一方继续 接收 数据  Linux上，当对端crash后，相当于调用close，会发送FIN包；那么在这个tcp连接上读取数据的接收方，read系统调用会立刻返回失败   未崩溃的一方继续 接收 数据  对方crash的时刻，tcp连接不会立刻感知；第一次write该tcp连接，可以写成功；而当这次数据包发送到对端时，由于应用程序crash，不论有没有重启，对端都会发送RST包；再次调用write会返回-1，错误码是EPIPE 32，错误信息是Broken Pipe；应用程序会收到SIGPIPE信号，崩溃，没有coredump文件产生（可以通过忽略SIGPIPE避免这个问题）。      crash的一端发送RST包\n 未崩溃的一方继续 接收 数据  调用recv会返回-1，错误码ECONNRESET，错误信息 Connection reset by peer   未崩溃的一方继续 发送 数据  调用send会返回-1，错误码ECONNRESET，错误信息 Connection reset by peer      crash的一端没有发送RST或者FIN包\n 调用recv的话会一直阻塞 调用send的话会尝试重传直到超时    可见对端崩溃时，本端如何感知，取决于对端是否发送RST包\n    RFC 793\n  RST包的产生\n 向不存在的端口发起连接，对方回复RST 一些延迟的包，比如旧的SYN包的副本，导致连接无法正常建立 程序异常终止，有的系统会发送RST 设置了SO_LINGER选项支持异常关闭，并调用close，会发送RST包 已经关闭的端口收到了数据，反馈回一个RST包  这就是对端crash后，第一次本端向crash方发送数据是可以写成功的，但是当数据到达crash方后，crash已经是关闭了的，所以会回复RST，这个时候tcp就会出错，Broken Pipe      RST包的处理方式\n Linux-2.6.18源码：      1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  /* When we get a reset we do this. */ static void tcp_reset(struct sock *sk) { /* We want the right error as BSD sees it (and indeed as we do). */ switch (sk-\u0026gt;sk_state) { case TCP_SYN_SENT: sk-\u0026gt;sk_err = ECONNREFUSED; break; case TCP_CLOSE_WAIT: sk-\u0026gt;sk_err = EPIPE; break; case TCP_CLOSE: return; default: sk-\u0026gt;sk_err = ECONNRESET; } if (!sock_flag(sk, SOCK_DEAD)) sk-\u0026gt;sk_error_report(sk); tcp_done(sk); }   * 当本端这个tcp连接处于TCP_SYN_SENT状态，也就是说本地主动发起连接，缺不幸收到了RST包，这个时候会向应用程序报告ECONNREFUSED连接被拒绝错误 * 当本地这个tcp处于TCP_CLOSE_WAIT状态，就是说本地从ESTA状态收到对方的FIN包后转为CLOSE_WAIT状态时，对端已经关闭了；如果这个时候本地仍然继续向对端发送数据，对端会返回一个RST包，这就导致程序进入这个case分支，因此向上层应用程序报EPIPE错误 * 默认清空下错误码都是ECONNRESET，connection reset by peer了。    TCP连接中的一些常见的“常数”\n mss 1460  以太网的MTU是1500bytes，而IP头是20bytes，TCP头部是20bytes，所以很多时候mss是1460bytes，这个比较常见   win 5792  在tcp初始化后，接收窗口大小会被设置成4个mss大小，在linux3.0之后是10个mss大小； 以4个mss大小为例，由于有的时候tcp的头部中option字段可能会带有时间戳，头部额外占用12字节，所以初始窗口大小是 4 * (1460 - 12) = 5792大小      broken pipe相关的问题 *\n  linux内核工程导论：TCP\n  TCP的write/read系统调用和send/recv的区别\n  ","date":"2016-05-30T13:58:17+08:00","permalink":"https://bg2bkk.github.io/p/effective-tips-about-tcp-ip-on-linux/","title":"effective tips about tcp ip on Linux"},{"content":" http://www.cnblogs.com/coser/archive/2011/11/27/2265134.html http://my.oschina.net/u/90679/blog/188750  ","date":"2016-05-27T13:46:13+08:00","permalink":"https://bg2bkk.github.io/p/consistent_hash_%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C%E7%AE%97%E6%B3%95%E7%9A%84%E5%AE%9E%E7%8E%B0/","title":"consistent_hash_一致性哈希算法的实现"},{"content":"  B-tree\n B-Tree含有n个节点的话，其高度为lgN，可以在O(lgN)时间内实现插入和删除等操作 一个内节点x如果含有n个关键字，则x将含有n+1个子女 一颗m阶的B-tree  每个节点最多含有m个孩子 除根节点和叶节点外，每个节点最少含有[ceil(m/2)]个孩子 根节点最少有2个孩子，除非该树只有根节点 所有叶子节点都在同一层，叶子节点不包含任何关键字信息，这点与红黑树的nil的语义相同 非叶子节点的信息：a、b、c      RB-tree\n http://www.cnblogs.com/CarpenterLee/p/5503882.html http://www.cnblogs.com/CarpenterLee/p/5525688.html    lsm-tree\n 中文 leveldb    ","date":"2016-05-27T11:39:18+08:00","permalink":"https://bg2bkk.github.io/p/data_structure%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/","title":"data_structure数据结构"},{"content":" http://blog.csdn.net/dlutbrucezhang/article/details/9074891 man cpu_zero  ","date":"2016-05-27T10:46:46+08:00","permalink":"https://bg2bkk.github.io/p/cpu%E4%B8%8E%E8%BF%9B%E7%A8%8B%E8%B0%83%E5%BA%A6/","title":"CPU与进程调度"},{"content":"最近突然看协程和并发编程比较多，遇到这样一道题\n 题目：子线程循环 10 次，接着主线程循环 100 次，接着又回到子线程循环 10 次，接着再回到主线程又循环 100 次，如此循环50次，试写出代码。\n 参考文档里的代码采用C++11编写，而我，很不幸的，看不懂。\n我想我的cpp已经退化到看不见了吧，然后c++11我更加看不懂了，甚至连cpp较为官方的文档都开始采用c++11了。\n虽然我不会c++11，但是我会lua、c、golang、python、shell，我要报复性的把这个题做了。\nC++11 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  #include\u0026lt;iostream\u0026gt;#include\u0026lt;thread\u0026gt;#include\u0026lt;mutex\u0026gt;#include\u0026lt;condition_variable\u0026gt;using namespace std; mutex m; condition_variable cond; int flag=10; void fun(int num){ for(int i=0;i\u0026lt;2;i++){ unique_lock\u0026lt;mutex\u0026gt; lk(m);//A unique lock is an object that manages a mutex object with unique ownership in both states: locked and unlocked.  while(flag!=num) cond.wait(lk);//在调用wait时会执行lk.unlock()  for(int j=0;j\u0026lt;num;j++) cout\u0026lt;\u0026lt;j\u0026lt;\u0026lt;\u0026#34; \u0026#34;; cout\u0026lt;\u0026lt;endl; flag=(num==10)?100:10; cond.notify_one();//被阻塞的线程唤醒后lk.lock()恢复在调用wait前的状态  } } int main(){ thread child(fun,10); fun(100); child.join(); return 0; }   Lua lua的协程使得主从两个thread之间并没有竞争关系，所以很顺畅的就可以把代码写出来，逻辑也十分简单\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40  local thread = coroutine.create(function() for cnt = 1, 5 do local tmp = {} for i = 1, 10 do table.insert(tmp, i) end print(\u0026#39;child: \u0026#39;, table.concat(tmp, \u0026#39; \u0026#39;)) coroutine.yield() local tmp = {} for i = 1, 10 do table.insert(tmp, i) end print(\u0026#39;child: \u0026#39;, table.concat(tmp, \u0026#39; \u0026#39;)) coroutine.yield() end end) for i=1, 5 do coroutine.resume(thread) local tmp = {} for i = 1, 100 do table.insert(tmp, i) end print(\u0026#39;main: \u0026#39;, table.concat(tmp, \u0026#39; \u0026#39;)) print(\u0026#39;------------------------------------\u0026#39;) coroutine.resume(thread) local tmp = {} for i = 1, 100 do table.insert(tmp, i) end print(\u0026#39;main: \u0026#39;, table.concat(tmp, \u0026#39; \u0026#39;)) print(\u0026#39;====================================\u0026#39;) end   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  child: 1 2 3 4 5 6 7 8 9 10 main: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 ------------------------------------ child: 1 2 3 4 5 6 7 8 9 10 main: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 ==================================== child: 1 2 3 4 5 6 7 8 9 10 main: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 ------------------------------------ child: 1 2 3 4 5 6 7 8 9 10 main: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 ==================================== child: 1 2 3 4 5 6 7 8 9 10 main: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 ------------------------------------ child: 1 2 3 4 5 6 7 8 9 10 main: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 ==================================== child: 1 2 3 4 5 6 7 8 9 10 main: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 ------------------------------------ child: 1 2 3 4 5 6 7 8 9 10 main: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 ==================================== child: 1 2 3 4 5 6 7 8 9 10 main: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 ------------------------------------ child: 1 2 3 4 5 6 7 8 9 10 main: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 ====================================   c  volatile: 使用volatile类型的全局变量和sleep函数实现阻塞和互斥  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53  #include \u0026lt;pthread.h\u0026gt;#include \u0026lt;string.h\u0026gt;#include \u0026lt;stdio.h\u0026gt;#include \u0026lt;stdlib.h\u0026gt;#include \u0026lt;unistd.h\u0026gt;#include \u0026lt;errno.h\u0026gt;#include \u0026lt;ctype.h\u0026gt; volatile int cond = 0; void func(int n) { int i = 0, j = 0; for(j=0; j\u0026lt;5; j++){ while(cond != 0) sleep(1); printf(\u0026#34;\\n----------------------------------\\n\u0026#34;); printf(\u0026#34;child: \u0026#34;); for(i=0; i \u0026lt; 10; i++ ) printf(\u0026#34;%d\\t\u0026#34;, i); printf(\u0026#34;\\n\u0026#34;); cond = 1; } } int main() { pthread_t tid; int s = pthread_create(\u0026amp;tid, NULL, func, 10); if(s != 0){ printf(\u0026#34;pthread_create error for %s\u0026#34;, strerror(errno)); exit(1); } int i = 0, j = 0; for(j=0; j \u0026lt; 5; j++){ while(cond != 1) sleep(1); printf(\u0026#34;master: \u0026#34;); for(i=0; i \u0026lt; 100; i++ ) printf(\u0026#34;%d\\t\u0026#34;, i); printf(\u0026#34;\\n\u0026#34;); printf(\u0026#34;==================================\\n\u0026#34;); cond = 0; } s = pthread_join(tid, NULL); if(s != 0){ printf(\u0026#34;pthread_join error for %s\u0026#34;, strerror(errno)); exit(1); } }     signal: 使用信号，用于进程互相通知对方\n  semop: 使用System V　进行线程同步，控制并发访问\n  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89  #include \u0026lt;pthread.h\u0026gt;#include \u0026lt;string.h\u0026gt;#include \u0026lt;stdio.h\u0026gt;#include \u0026lt;stdlib.h\u0026gt;#include \u0026lt;unistd.h\u0026gt;#include \u0026lt;errno.h\u0026gt;#include \u0026lt;ctype.h\u0026gt;#include \u0026lt;signal.h\u0026gt; #include \u0026lt;sys/types.h\u0026gt;#include \u0026lt;sys/ipc.h\u0026gt;#include \u0026lt;sys/sem.h\u0026gt; volatile int cond = 0; int semid; struct sembuf sem[2]; void func(int n) { //\tprintf(\u0026#34;ppid = %d, getpid = %d\\n\u0026#34;, getppid(), getpid());  int i = 0, j = 0; for(j=0; j\u0026lt;5; j++){ sem[1].sem_num = 1; sem[1].sem_op = -1; sem[1].sem_flg = 0; semop(semid, \u0026amp;sem[1], 1); printf(\u0026#34;\\n----------------------------------\\n\u0026#34;); printf(\u0026#34;child: \u0026#34;); for(i=0; i \u0026lt; 10; i++ ) printf(\u0026#34;%d\\t\u0026#34;, i); printf(\u0026#34;\\n\u0026#34;); sem[0].sem_num = 0; sem[0].sem_op = 1; sem[0].sem_flg = 0; semop(semid, \u0026amp;sem[0], 1); } } int main() { semid = semget(IPC_PRIVATE, 2, 0666| IPC_CREAT); if(semid \u0026lt; 0){ printf(\u0026#34;semget error for %s\u0026#34;, strerror(errno)); exit(1); } pthread_t tid; int s = pthread_create(\u0026amp;tid, NULL, func, getpid()); if(s != 0){ printf(\u0026#34;pthread_create error for %s\u0026#34;, strerror(errno)); exit(1); } int i = 0, j = 0; for(j=0; j \u0026lt; 5; j++){ sem[0].sem_num = 0; sem[0].sem_op = -1; sem[0].sem_flg = 0; sem[1].sem_num = 1; sem[1].sem_op = 1; sem[1].sem_flg = 0; semop(semid, \u0026amp;sem[1], 1); semop(semid, \u0026amp;sem[0], 1); printf(\u0026#34;master: \u0026#34;); for(i=0; i \u0026lt; 100; i++ ) printf(\u0026#34;%d\\t\u0026#34;, i); printf(\u0026#34;\\n\u0026#34;); printf(\u0026#34;==================================\\n\u0026#34;); sem[1].sem_num = 1; sem[1].sem_op = 1; sem[1].sem_flg = 0; } s = pthread_join(tid, NULL); if(s != 0){ printf(\u0026#34;pthread_join error for %s\u0026#34;, strerror(errno)); exit(1); } }   python  python yield  golang  goroutine之间可以通过channel进行多任务同步  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42  package main import \u0026#34;fmt\u0026#34; var c1 chan int var c2 chan int func task(loop int, times int) { for i := 0; i \u0026lt; loop; i++ { \u0026lt;-c1 fmt.Println(\u0026#34;------------------------------\u0026#34;) fmt.Print(\u0026#34;child: \u0026#34;) for j := 0; j \u0026lt; times; j++ { fmt.Printf(\u0026#34;%d\\t\u0026#34;, j) } fmt.Println() c2 \u0026lt;- 1 } } func main() { times := 100 loop := 5 c1 = make(chan int, 1024) c2 = make(chan int, 1024) go task(loop, 10) for i := 0; i \u0026lt; loop; i++ { c1 \u0026lt;- 1 \u0026lt;-c2 fmt.Print(\u0026#34;master: \u0026#34;) for j := 0; j \u0026lt; times; j++ { fmt.Printf(\u0026#34;%d\\t\u0026#34;, j) } fmt.Println() fmt.Println(\u0026#34;==============================\u0026#34;) } }    其实golang的chan作为阻塞读取的协程通信组件，有一个也就能实现谁先谁后的同步了；毕竟，不光 val \u0026lt;- chan 这种读操作会堵塞，chan \u0026lt;- val这种写操作也会被堵塞  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39  package main import \u0026#34;fmt\u0026#34; var c1 chan int func task(loop int, times int) { for i := 0; i \u0026lt; loop; i++ { fmt.Println(\u0026#34;------------------------------\u0026#34;) fmt.Print(\u0026#34;child: \u0026#34;) for j := 0; j \u0026lt; times; j++ { fmt.Printf(\u0026#34;%d\\t\u0026#34;, j) } fmt.Println() c1 \u0026lt;- 1 } } func main() { times := 100 loop := 5 c1 = make(chan int) go task(loop, 10) for i := 0; i \u0026lt; loop; i++ { \u0026lt;-c1 fmt.Print(\u0026#34;master: \u0026#34;) for j := 0; j \u0026lt; times; j++ { fmt.Printf(\u0026#34;%d\\t\u0026#34;, j) } fmt.Println() fmt.Println(\u0026#34;==============================\u0026#34;) } }   shell  token bucket  ","date":"2016-05-26T01:39:59+08:00","permalink":"https://bg2bkk.github.io/p/%E4%B8%80%E9%81%93%E5%A4%9A%E7%BA%BF%E7%A8%8B%E9%9D%A2%E8%AF%95%E9%A2%98/","title":"一道多线程面试题"},{"content":" https://www.gitbook.com/book/chenxiaowei/cpp_concurrency_in_action/details http://blog.csdn.net/column/details/ccia.html https://github.com/bsmr-c-cpp/Cpp-Concurrency-in-Action  ","date":"2016-05-26T01:24:43+08:00","permalink":"https://bg2bkk.github.io/p/cpp_concurrency_in_action/","title":"cpp_concurrency_in_action"},{"content":" http://en.cppreference.com/w/cpp/thread/condition_variable http://blog.csdn.net/liuxuejiang158blog/article/details/21977009  ","date":"2016-05-26T01:19:05+08:00","permalink":"https://bg2bkk.github.io/p/cpp_condtion_variable/","title":"cpp_condtion_variable"},{"content":"  http://dataguild.org/?p=6817\n  https://github.com/emqtt/emqttd\n  http://my.oschina.net/scholer/blog/296402\n  https://github.com/mqtt/mqtt.github.io/wiki/servers\n mosquitto http://blog.csdn.net/xukai871105/article/details/39252653    websocket mqtt\n websocket mqtt js    mqtt协议\n  mqtt c lib\n  eclipse mqtt server\n  公共mqtt服务\n  mqtt软件\n mqtt库client mqtt server 方案    mosquitto 用法\n mosquitto -d mosquitto_sub -d -h 192.168.2.163 -p 1883 -t /bg2bkk mosquitto_pub -d -h 192.168.2.163 -p 1883 -t /bg2bkk -m huang 配置文件释义 mqtt消息顺序和服务质量    ","date":"2016-05-25T23:55:24+08:00","permalink":"https://bg2bkk.github.io/p/mqtt-pratices-and-issues/","title":"mqtt pratices and issues"},{"content":"Chapter 16: Object-Oriented Programming   http://www.lua.org/pil/16.1.html\n  http://lua-users.org/wiki/SimpleLuaClasses\n  http://lua-users.org/wiki/LuaClassesWithMetatable\n  为什么要__index = itself\n http://lua-users.org/lists/lua-l/2013-04/msg00617.html    http://lua-users.org/wiki/ObjectOrientedProgramming\n  ","date":"2016-05-25T15:01:41+08:00","permalink":"https://bg2bkk.github.io/p/review_pil_%E9%87%8D%E8%AF%BBprogramming-in-lua/","title":"review_PIL_重读\u003cprogramming in lua\u003e"},{"content":"IP 合法性校验  http://www.cnblogs.com/txw1958/archive/2011/10/13/ip_address_regular_expression.html http://c.biancheng.net/cpp/html/1437.html http://stackoverflow.com/questions/106179/regular-expression-to-match-dns-hostname-or-ip-address  正则表达式  https://github.com/astaxie/build-web-application-with-golang/blob/master/zh/07.3.md https://github.com/polaris1119/The-Golang-Standard-Library-by-Example/blob/master/chapter02/02.1.md  ","date":"2016-05-20T18:41:29+08:00","permalink":"https://bg2bkk.github.io/p/ip-address-%E5%90%88%E6%B3%95%E6%80%A7%E5%92%8C%E6%AD%A3%E5%88%99%E6%A3%80%E6%9F%A5%E6%96%B9%E6%B3%95/","title":"IP Address 合法性和正则检查方法"},{"content":"zookeeper  http://www.cnblogs.com/yuyijq/p/3391945.html  ","date":"2016-05-19T11:26:46+08:00","permalink":"https://bg2bkk.github.io/p/zookeeper-etcd-and-consul/","title":"zookeeper etcd and consul"},{"content":"HTTP   HTTP/0.9\n  HTTP/1.0\n 引入POST方法，允许client发送表单 引入Header头部，能够返回错误码、以及文字或图片等其他格式 头部的Connection: keep-alive可以保持长连接    HTTP/1.1\n 增加HOST字段，然后GET 后面只需要跟相对路径即可，由HOST字段分辨访问主机的哪个域；之前是不能有多个域的，因为多个域指向同一IP会造成混淆 引入Range头，可以只下载一部分内容 默认长链接 keepalive    HTTP/2:\n 革命性的更新，压缩头部，stream和frame等机制    HTTP request 请求\n 请求行 eg. GET www.cnblogs.com HTTP/1.1 HTTP头部 eg. Content-Type: text/html; charset=utf-8 内容\t只在post请求存在    HTTP respond 响应\n 状态行 eg. HTTP/1.1 200 OK HTTP头部  响应头 response header 通用头 general header eg. Date ETAG Connection: Keep-Alive      1  通用头即可以包含在HTTP请求中，也可以包含在HTTP响应中。通用头的作用是描述HTTP协议本身。比如描述HTTP是否持久连接的Connection头，HTTP发送日期的Date头，描述HTTP所在TCP连接时间的Keep-Alive头，用于缓存控制的Cache-Control头等。   \t* 实体头 entity header eg. Content-Type: Content-Length  1  实体头是那些描述HTTP信息的头。既可以出现在HTTP POST方法的请求中，也可以出现在HTTP响应中。比如图5和图6中的Content-Type和Content-length都是描述实体的类型和大小的头都属于实体头。其它还有用于描述实体的Content-Language,Content-MD5,Content-Encoding以及控制实体缓存的Expires和Last-Modifies头等。   * 响应数据 * 浏览器靠响应头部的Content-Type来确定如何处理收到的信息，类型由IANA分配，包括[8大类媒体类型](http://www.iana.org/assignments/media-types/media-types.xhtml)   HTTP头部  请求头 request header    1  请求头是那些由客户端发往服务端以便帮助服务端更好的满足客户端请求的头。请求头只能出现在HTTP请求中。比如告诉服务器只接收某种响应内容的Accept头，发送Cookies的Cookie头，显示请求主机域的HOST头，用于缓存的If-Match，If-Match-Since,If-None-Match头，用于只取HTTP响应信息中部分信息的Range头，用于附属HTML相关请求引用的Referer头等。   * 响应头 response header  1  HTTP响应头是那些描述HTTP响应本身的头，这里面并不包含描述HTTP响应中第三部分也就是HTTP信息的头（这部分由实体头负责）。比如说定时刷新的Refresh头，当遇到503错误时自动重试的Retry-After头，显示服务器信息的Server头，设置COOKIE的Set-Cookie头，告诉客户端可以部分请求的Accept-Ranges头等。   一次http请求的过程 http请求头部keepalive content-encoding transfer-encoding content-length transfer-length Range字段\n HTTP的幂等性  幂等性  比较 POST GET PUT DELETE等方法，指出各自的幂等性   电商中的幂等性    ","date":"2016-05-18T20:26:09+08:00","permalink":"https://bg2bkk.github.io/p/http%E5%8D%8F%E8%AE%AE%E5%AD%A6%E4%B9%A0%E8%BF%87%E7%A8%8B/","title":"HTTP协议学习过程"},{"content":"  kvm使用\n 创建磁盘：qemu-img create -f qcow2 server_01.img 10G 启动虚拟机：qemu-system-x86_64 -m 512 -enable-kvm server_01.img -cdrom ./mini.iso    克隆虚拟机\n  http://blog.csdn.net/csfreebird/article/details/8878808\n  http://www.ilanni.com/?p=6173\n  ","date":"2016-05-18T18:42:22+08:00","permalink":"https://bg2bkk.github.io/p/kvm-qemu-virtual-machine%E5%AE%9E%E8%B7%B5/","title":"kvm qemu Virtual Machine实践"},{"content":"近几天一直在看协程的事情，在getcontext和makecontext的时候，发现还和信号有一定的关系；虽然线程切换或者协程切换肯定会涉及到信号，但是我还是想知道，会有多深的关系呢？\n 进程切换过程详解 http://blog.chinaunix.net/uid-30126070-id-5058253.html  ","date":"2016-05-18T17:33:16+08:00","permalink":"https://bg2bkk.github.io/p/%E8%BF%9B%E7%A8%8B%E5%88%87%E6%8D%A2%E4%B8%8E%E4%BF%A1%E5%8F%B7%E7%9A%84%E5%85%B3%E7%B3%BB/","title":"进程切换与信号的关系"},{"content":" reuseport tfo的golang实现(github)  上一行项目的作者bradley falzon    ","date":"2016-05-18T17:25:33+08:00","permalink":"https://bg2bkk.github.io/p/golang%E4%B8%AD%E7%9A%84%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/","title":"golang中的网络编程"},{"content":"  类型判断性能消耗\n  go test关于benchmark的使用\n http://www.01happy.com/golang-unit-testing/    golang性能分析 gperf\n http://studygolang.com/articles/1155 https://blog.golang.org/profiling-go-programs http://www.cnblogs.com/yjf512/archive/2012/12/27/2835331.html https://segmentfault.com/a/1190000000670041 https://segmentfault.com/a/1190000000501635 http://wiki.jikexueyuan.com/project/the-way-to-go/13.10.html    ","date":"2016-05-18T17:24:33+08:00","permalink":"https://bg2bkk.github.io/p/golang%E4%B8%AD%E7%9A%84%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E5%92%8C%E4%BC%98%E5%8C%96/","title":"golang中的性能分析和优化"},{"content":"  http://www.cnblogs.com/luosongchao/p/3680312.html\n  http://blog.csdn.net/xhhjin/article/details/7579145\n  http://laoar.net/blogs/250/\n  https://en.wikipedia.org/wiki/Call_stack#Unwinding\n  x86函数是如何调用的\n  ","date":"2016-05-18T16:02:19+08:00","permalink":"https://bg2bkk.github.io/p/linux%E7%9A%84%E7%BA%BF%E7%A8%8B%E6%A0%88/","title":"linux的线程栈"},{"content":"SA_RESTART 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51  // from http://www.win.tue.nl/~aeb/linux/lk/lk-4.html#ss4.5 #include \u0026lt;stdio.h\u0026gt;#include \u0026lt;errno.h\u0026gt;#include \u0026lt;stdlib.h\u0026gt;#include \u0026lt;unistd.h\u0026gt;#include \u0026lt;signal.h\u0026gt; int got_interrupt; void intrup(int dummy) { got_interrupt = 1; char *msg = \u0026#34;got signal\\n\u0026#34;; write(1, msg, strlen(msg)); } void die(char *s) { printf(\u0026#34;%s\\n\u0026#34;, s); exit(1); } int main() { struct sigaction sa; int n; char c; sa.sa_handler = intrup; sigemptyset(\u0026amp;sa.sa_mask); sa.sa_flags = 0; if (sigaction(SIGINT, \u0026amp;sa, NULL)) die(\u0026#34;sigaction-SIGINT\u0026#34;); sa.sa_flags = SA_RESTART; if (sigaction(SIGQUIT, \u0026amp;sa, NULL)) die(\u0026#34;sigaction-SIGQUIT\u0026#34;); got_interrupt = 0; n = read(0, \u0026amp;c, 1); if (n == -1 \u0026amp;\u0026amp; errno == EINTR) printf(\u0026#34;\u0026gt;\u0026gt;\u0026gt; read call was interrupted\\n\u0026#34;); else if (got_interrupt) printf(\u0026#34;\u0026gt;\u0026gt;\u0026gt; read call was restarted\\n\u0026#34;); printf(\u0026#34;Read character: %c\\n\u0026#34;, c); return 0; } ```bash $ ./sa_restart.o ^cgot signal\t-- 这里按下Crtl+C，发送SIGINT信号 \u0026gt;\u0026gt;\u0026gt; read call was interrupted read character:   TODO LIST  O_CLOEXEC EPOLLEXCLUSIVE  $ ./sa_restart.o ^cgot signal\n   read call was interrupted read character:\n   ","date":"2016-05-18T15:56:47+08:00","permalink":"https://bg2bkk.github.io/p/signal%E4%BF%A1%E5%8F%B7%E7%BC%96%E7%A8%8B%E6%97%B6%E7%9A%84sa_restart%E7%94%A8%E6%B3%95/","title":"signal信号编程时的SA_RESTART用法"},{"content":" widoraa  https://github.com/widora/openwrt_widora   coolpy t-firefly  ","date":"2016-05-13T17:28:57+08:00","permalink":"https://bg2bkk.github.io/p/internet-on-things/","title":"Internet on things"},{"content":"  http://www.cricode.com/2999.html\n  nginx负载均衡\n  一致性哈希 consistent hashing  http://www.codeproject.com/Articles/56138/Consistent-hashing http://blog.huanghao.me/?p=14 http://blog.csdn.net/sparkliang/article/details/5279393  ","date":"2016-05-11T17:57:31+08:00","permalink":"https://bg2bkk.github.io/p/nginx-%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90/","title":"nginx 源码剖析"},{"content":"  []\n  http://www.cppblog.com/peakflys/archive/2012/07/25/184855.html\n  ","date":"2016-05-11T14:58:27+08:00","permalink":"https://bg2bkk.github.io/p/cpp_hashmap/","title":"cpp_hashmap"},{"content":" cpp java tutorial  ","date":"2016-05-11T14:40:00+08:00","permalink":"https://bg2bkk.github.io/p/leetcode_146_lru_cache/","title":"leetcode_146_LRU_Cache"},{"content":" http://www.cnblogs.com/grandyang/p/4084408.html http://blog.csdn.net/kenden23/article/details/18696083 http://blog.csdn.net/fightforyourdream/article/details/12900751  ","date":"2016-05-11T11:47:34+08:00","permalink":"https://bg2bkk.github.io/p/leetcode_150_valid_number/","title":"leetcode_150_valid_number"},{"content":"  String to Integer (atoi)   https://leetcode.com/problems/string-to-integer-atoi/ 何海涛代码    1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108  // StringToInt.cpp : Defines the entry point for the console application. // // 《剑指Offer——名企面试官精讲典型编程题》代码 // 著作权所有者：何海涛 #include \u0026lt;stdio.h\u0026gt;#include \u0026lt;stdlib.h\u0026gt;#include \u0026lt;string.h\u0026gt;#include \u0026lt;iostream\u0026gt;using namespace std; long long StrToIntCore(const char* str, bool minus); enum Status {kValid = 0, kInvalid}; int g_nStatus = kValid; int status = kValid; int StrToInt(const char* str) { g_nStatus = kInvalid; long long num = 0; if(str != NULL \u0026amp;\u0026amp; *str != \u0026#39;\\0\u0026#39;) { bool minus = false; if(*str == \u0026#39;+\u0026#39;) str ++; else if(*str == \u0026#39;-\u0026#39;) { str ++; minus = true; } if(*str != \u0026#39;\\0\u0026#39;) { num = StrToIntCore(str, minus); } } return (int)num; } // 要求atoi，integer为32位整数，范围是 -2147483648(0x80000000) ~ 2147483647(0x7fffffff) // 由于要判断是否溢出，所以采用long long类型来实现加减，范围是 -9223372036854775808 ~ 9223372036854775807 // 最后返回值时，采用(int)num来将long long强制转换为int，由于num范围就是int类型这么大，所以不会出错  // 判断是否溢出时 num \u0026gt; 0x7fffffff 可以直接判断，毕竟num可以很大  // 判断输入str的有效性  long long StrToIntCore(const char* digit, bool minus) { long long num = 0; while(*digit != \u0026#39;\\0\u0026#39;) { if(*digit \u0026gt;= \u0026#39;0\u0026#39; \u0026amp;\u0026amp; *digit \u0026lt;= \u0026#39;9\u0026#39;) { int flag = minus ? -1 : 1; num = num * 10 + flag * (*digit - \u0026#39;0\u0026#39;); if((!minus \u0026amp;\u0026amp; num \u0026gt; 0x7FFFFFFF) || (minus \u0026amp;\u0026amp; num \u0026lt; (signed int)0x80000000)) { num = 0; break; } digit++; } else { num = 0; break; } } if(*digit == \u0026#39;\\0\u0026#39;) { g_nStatus = kValid; } return num; } // ====================测试代码====================  void Test(char* string) { int result = StrToInt(string); if(result == 0 \u0026amp;\u0026amp; g_nStatus == kInvalid) printf(\u0026#34;the input %s is invalid.\\n\u0026#34;, string); else printf(\u0026#34;number for %s is: %d.\\n\u0026#34;, string, result); } int main(int argc, char * argv[]) { // Test(NULL);  Test(\u0026#34;\u0026#34;); Test(\u0026#34;123\u0026#34;); Test(\u0026#34;+123\u0026#34;); Test(\u0026#34;-123\u0026#34;); Test(\u0026#34;1a33\u0026#34;); Test(\u0026#34;+0\u0026#34;); Test(\u0026#34;-0\u0026#34;); //有效的最大正整数, 0x7FFFFFFF  Test(\u0026#34;+2147483647\u0026#34;); Test(\u0026#34;-2147483647\u0026#34;); Test(\u0026#34;+2147483648\u0026#34;); //有效的最小负整数, 0x80000000  Test(\u0026#34;-2147483648\u0026#34;); Test(\u0026#34;+2147483649\u0026#34;); Test(\u0026#34;-2147483649\u0026#34;); Test(\u0026#34;+\u0026#34;); Test(\u0026#34;-\u0026#34;); return 0; }   * 我的狗尾续貂之作  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53  long long str2int(string str){ const char *s = str.c_str(); if(!s || *s == \u0026#39;\\0\u0026#39;){ return 0; } bool minus = false; long long num = 0; if(*s == \u0026#39;+\u0026#39;){ minus = false; s++; } else if ( *s == \u0026#39;-\u0026#39;) { minus = true; s++; } while(*s == \u0026#39;0\u0026#39;) s++; while(*s != \u0026#39;\\0\u0026#39;){ if( *s \u0026gt;= \u0026#39;0\u0026#39; \u0026amp;\u0026amp; *s \u0026lt;= \u0026#39;9\u0026#39;){ int digit = *s - \u0026#39;0\u0026#39;; int flag = minus ? -1 : 1; num = num * 10 + flag * digit; if( (!minus \u0026amp;\u0026amp;num \u0026gt; 0x7fffffff) || (minus \u0026amp;\u0026amp; num \u0026lt; (signed int)0x80000000)){ num = 0; status = kInvalid; break; } else { s++; } } else { status = kInvalid; num = 0; break; } } if(*s == \u0026#39;\\0\u0026#39;) { status = kValid; } return num; } void Test(string str) { long long result = str2int(str); if(result == 0 \u0026amp;\u0026amp; status == kInvalid) printf(\u0026#34;the input %s is invalid.\\n\u0026#34;, str.c_str()); else printf(\u0026#34;number for %s is: %d.\\n\u0026#34;, str.c_str(), result); }   * leetcode accept 代码  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38  class Solution { public: int myAtoi(string str) { const char *s = str.c_str(); if(!s || *s == \u0026#39;\\0\u0026#39;){ return 0; } while(*s == \u0026#39; \u0026#39;) s++; bool minus = false; long long num = 0; if(*s == \u0026#39;+\u0026#39;){ minus = false; s++; } else if ( *s == \u0026#39;-\u0026#39;) { minus = true; s++; } while(*s != \u0026#39;\\0\u0026#39;){ if( *s \u0026gt;= \u0026#39;0\u0026#39; \u0026amp;\u0026amp; *s \u0026lt;= \u0026#39;9\u0026#39;){ if(*s == \u0026#39;0\u0026#39; \u0026amp;\u0026amp; num == 0) { s++; continue;} int digit = *s - \u0026#39;0\u0026#39;; int flag = minus ? -1 : 1; num = num * 10 + flag * digit; if (!minus \u0026amp;\u0026amp;num \u0026gt; 0x7fffffff) { return INT_MAX; } else if (minus \u0026amp;\u0026amp; num \u0026lt; (signed int)0x80000000){ return INT_MIN; } s++; } else { break; } } return (int)num; } };   ","date":"2016-05-11T11:36:47+08:00","permalink":"https://bg2bkk.github.io/p/leetcode%E8%A7%A3%E9%A2%98%E8%BF%87%E7%A8%8B%E4%B8%AD%E7%9A%84%E6%80%9D%E8%80%83/","title":"leetcode解题过程中的思考"},{"content":"  String to Integer (atoi)   https://leetcode.com/problems/string-to-integer-atoi/ 何海涛代码    1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108  // StringToInt.cpp : Defines the entry point for the console application. // // 《剑指Offer——名企面试官精讲典型编程题》代码 // 著作权所有者：何海涛 #include \u0026lt;stdio.h\u0026gt;#include \u0026lt;stdlib.h\u0026gt;#include \u0026lt;string.h\u0026gt;#include \u0026lt;iostream\u0026gt;using namespace std; long long StrToIntCore(const char* str, bool minus); enum Status {kValid = 0, kInvalid}; int g_nStatus = kValid; int status = kValid; int StrToInt(const char* str) { g_nStatus = kInvalid; long long num = 0; if(str != NULL \u0026amp;\u0026amp; *str != \u0026#39;\\0\u0026#39;) { bool minus = false; if(*str == \u0026#39;+\u0026#39;) str ++; else if(*str == \u0026#39;-\u0026#39;) { str ++; minus = true; } if(*str != \u0026#39;\\0\u0026#39;) { num = StrToIntCore(str, minus); } } return (int)num; } // 要求atoi，integer为32位整数，范围是 -2147483648(0x80000000) ~ 2147483647(0x7fffffff) // 由于要判断是否溢出，所以采用long long类型来实现加减，范围是 -9223372036854775808 ~ 9223372036854775807 // 最后返回值时，采用(int)num来将long long强制转换为int，由于num范围就是int类型这么大，所以不会出错  // 判断是否溢出时 num \u0026gt; 0x7fffffff 可以直接判断，毕竟num可以很大  // 判断输入str的有效性  long long StrToIntCore(const char* digit, bool minus) { long long num = 0; while(*digit != \u0026#39;\\0\u0026#39;) { if(*digit \u0026gt;= \u0026#39;0\u0026#39; \u0026amp;\u0026amp; *digit \u0026lt;= \u0026#39;9\u0026#39;) { int flag = minus ? -1 : 1; num = num * 10 + flag * (*digit - \u0026#39;0\u0026#39;); if((!minus \u0026amp;\u0026amp; num \u0026gt; 0x7FFFFFFF) || (minus \u0026amp;\u0026amp; num \u0026lt; (signed int)0x80000000)) { num = 0; break; } digit++; } else { num = 0; break; } } if(*digit == \u0026#39;\\0\u0026#39;) { g_nStatus = kValid; } return num; } // ====================测试代码====================  void Test(char* string) { int result = StrToInt(string); if(result == 0 \u0026amp;\u0026amp; g_nStatus == kInvalid) printf(\u0026#34;the input %s is invalid.\\n\u0026#34;, string); else printf(\u0026#34;number for %s is: %d.\\n\u0026#34;, string, result); } int main(int argc, char * argv[]) { // Test(NULL);  Test(\u0026#34;\u0026#34;); Test(\u0026#34;123\u0026#34;); Test(\u0026#34;+123\u0026#34;); Test(\u0026#34;-123\u0026#34;); Test(\u0026#34;1a33\u0026#34;); Test(\u0026#34;+0\u0026#34;); Test(\u0026#34;-0\u0026#34;); //有效的最大正整数, 0x7FFFFFFF  Test(\u0026#34;+2147483647\u0026#34;); Test(\u0026#34;-2147483647\u0026#34;); Test(\u0026#34;+2147483648\u0026#34;); //有效的最小负整数, 0x80000000  Test(\u0026#34;-2147483648\u0026#34;); Test(\u0026#34;+2147483649\u0026#34;); Test(\u0026#34;-2147483649\u0026#34;); Test(\u0026#34;+\u0026#34;); Test(\u0026#34;-\u0026#34;); return 0; }   * 我的狗尾续貂之作  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53  long long str2int(string str){ const char *s = str.c_str(); if(!s || *s == \u0026#39;\\0\u0026#39;){ return 0; } bool minus = false; long long num = 0; if(*s == \u0026#39;+\u0026#39;){ minus = false; s++; } else if ( *s == \u0026#39;-\u0026#39;) { minus = true; s++; } while(*s == \u0026#39;0\u0026#39;) s++; while(*s != \u0026#39;\\0\u0026#39;){ if( *s \u0026gt;= \u0026#39;0\u0026#39; \u0026amp;\u0026amp; *s \u0026lt;= \u0026#39;9\u0026#39;){ int digit = *s - \u0026#39;0\u0026#39;; int flag = minus ? -1 : 1; num = num * 10 + flag * digit; if( (!minus \u0026amp;\u0026amp;num \u0026gt; 0x7fffffff) || (minus \u0026amp;\u0026amp; num \u0026lt; (signed int)0x80000000)){ num = 0; status = kInvalid; break; } else { s++; } } else { status = kInvalid; num = 0; break; } } if(*s == \u0026#39;\\0\u0026#39;) { status = kValid; } return num; } void Test(string str) { long long result = str2int(str); if(result == 0 \u0026amp;\u0026amp; status == kInvalid) printf(\u0026#34;the input %s is invalid.\\n\u0026#34;, str.c_str()); else printf(\u0026#34;number for %s is: %d.\\n\u0026#34;, str.c_str(), result); }   * leetcode accept 代码  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38  class Solution { public: int myAtoi(string str) { const char *s = str.c_str(); if(!s || *s == \u0026#39;\\0\u0026#39;){ return 0; } while(*s == \u0026#39; \u0026#39;) s++; bool minus = false; long long num = 0; if(*s == \u0026#39;+\u0026#39;){ minus = false; s++; } else if ( *s == \u0026#39;-\u0026#39;) { minus = true; s++; } while(*s != \u0026#39;\\0\u0026#39;){ if( *s \u0026gt;= \u0026#39;0\u0026#39; \u0026amp;\u0026amp; *s \u0026lt;= \u0026#39;9\u0026#39;){ if(*s == \u0026#39;0\u0026#39; \u0026amp;\u0026amp; num == 0) { s++; continue;} int digit = *s - \u0026#39;0\u0026#39;; int flag = minus ? -1 : 1; num = num * 10 + flag * digit; if (!minus \u0026amp;\u0026amp;num \u0026gt; 0x7fffffff) { return INT_MAX; } else if (minus \u0026amp;\u0026amp; num \u0026lt; (signed int)0x80000000){ return INT_MIN; } s++; } else { break; } } return (int)num; } };   ","date":"2016-05-11T11:36:47+08:00","permalink":"https://bg2bkk.github.io/p/leetcode%E8%A7%A3%E9%A2%98%E8%BF%87%E7%A8%8B%E4%B8%AD%E7%9A%84%E6%80%9D%E8%80%83/","title":"leetcode解题过程中的思考"},{"content":"结论 1. SO_REUSEPORT用于多个socket监听同一个TCP链接 2. SO_REUSEADDR可用于多个进程bind同一端口，但需要TCP连接的四元组不一样。 3. SO_REUSEPORT比SO_REUSEADDR更加扩展，但是也带来了隐患，需要额外注意 4. SO_REUSEADDR的最大作用是，当服务因故障重启时，不用等待需要绑定的端口从TIME_WAIT状态变更到CLOSED状态，就可以直接绑定该端口  引言 nginx 1.9.1引入了 SO_REUSEPORT选项，在高版本（linux kernel 3.9以上）系统上可用。该选项允许多个socket监听同一个IP:PORT组合，\n SO_REUSEPORT可以简化服务器编程 prefork模式：master预先分配进程池，每一个client连接用一个进程处理  省资源，不用每次都fork，然后再回收 可控制，预先分配的进程池大小是固定的   SO_REUSEPORT使得多进程时不用使master再做管理工作，比如管理子进程，设置信号等等，设置不需要一个master进程，只需要子进程监听同一个端口就行。操作系统做了大部分工作。  这里还有个好处是，C写的server模块，python写的server模块，它们可以共存监听同一个端口，灵活性更好    听听linux kernle维护者怎么说  允许多个进程绑定host上的同一端口 只需要第一个绑定端口的进程指定SO_REUSEPORT选项，后继者都可以绑定该端口，所以需要担心的是端口劫持，不希望恶意程序能accept该端口的连接。 方法是后继者要与第一次绑定端口的进程的USER ID一样，比如用root和普通用户启动程序绑定同一个端口，会报address already in use SO_REUSEPORT的负载均衡性能更好   TCP和UDP都可以用  UDP场景中，在DNS server的应用比较有意义，可以负载均衡的处理dns请求 作者指出，SO_REUSEADDR虽然也能让UDP连接绑定同一端口，但是SO_REUSEPORT可以防止劫持，并能将请求均衡的分配给监听的线程    传统多线程的工作模式的缺点    传统的多线程server都是有一个listener线程绑定端口并接受所有的请求，然后传递给其他线程，而这个listener往往会成为瓶颈    master绑定端口，每个slave轮流accept从该端口获取连接（nginx）   缺点是有可能导致每个slave不能平均的处理连接，unblanced；有的slave处理的过多，有的slave处理的过少，导致cpu资源不能充分利用 SO_REUSEPORT的实现可以使请求平均的分配给堵塞在accept上的各个进程    SO_REUSEPORT的应用举例  server.py  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  import socket import os SO_REUSEPORT = 15 s = socket.socket(socket.AF_INET, socket.SOCK_STREAM) s.setsockopt(socket.SOL_SOCKET, SO_REUSEPORT, 1) s.bind((\u0026#39;\u0026#39;, 10000)) s.listen(1) while True: conn, addr = s.accept() print(\u0026#39;Connected to {}\u0026#39;.format(os.getpid())) data = conn.recv(1024) conn.send(data) conn.close()   启动两个进程，都绑定10000端口；使用nc作为client\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  $ python server.py\u0026amp; [1] 12649 $ python server.py\u0026amp; [2] 12650 $ echo data | nc localhost 10000 Connected to 12649 data $ echo data | nc localhost 10000 Connected to 12650 data $ echo data | nc localhost 10000 Connected to 12649 data $ echo data | nc localhost 10000 Connected to 12650 data   再启动一个新的进程显然也是可以的\n1 2 3 4 5 6 7 8  $ python server.py\u0026amp; [3] 14021 $ echo data | nc localhost 10000 Connected to 12650 data $ echo data | nc localhost 10000 Connected to 14021 data     SO_REUSEPORT在golang中的实践\n  SO_REUSEADDR的使用场景\n 在某tcp连接处于 TIME_WAIT状态时，它所占用的port不能被立刻使用 例如server端服务挂掉后需要重启，重启时发现需要bind的端口处于TIME_WAIT状态，不能立刻使用，错误码为EADDRINUSE，glibc将这个错误码渲染为 \u0026ldquo;Address already in use\u0026rdquo; TIME_WAIT状态持续时间为2MSL，一个MSL通常是30s到2min，所以该状态时长为1min到4min；这是不可忍受的 SO_REUSEADDR可以使得进程能够绑定处于TIME_WAIT状态的端口，在服务重启的时候很有用 SO_REUSEADDR同样可以使得进程能够绑定处于ESTABLISHED状态的连接 无论如何，SO_REUSEADDR不允许相同ip和port的四元组存在    SO_REUSEPORT 和 SO_REUSEADDR 对比（待续）  前者可以防止端口被恶意进程劫持 前者可以使请求平均分配给各个进程  参考链接  lwn: the SO_REUSEPORT socket option topic on so_reuseaddr and so_reuseport on stackoverflow  ","date":"2016-05-09T16:55:42+08:00","permalink":"https://bg2bkk.github.io/p/so_reuseaddr%E5%92%8Cso_reuseport/","title":"SO_REUSEADDR和SO_REUSEPORT"},{"content":"引言  三次握手的过程中，当用户首次访问server时，发送syn包，server根据用户IP生成cookie，并与syn+ack一同发回client；client再次访问server时，在syn包携带TCP cookie；如果server校验合法，则在用户回复ack前就可以直接发送数据；否则按照正常三次握手进行。\n  TFO提高性能的关键是省去了热请求的三次握手，这在充斥着小对象的移动应用场景中能够极大提升性能。\n Google研究发现TCP 二次握手是页面延迟时间的重要部分，所以提出TFO\nTFO的fast open标志体现在TCP报文的头部的OPTION字段\nTCP Fast Open的标准文档是rfc7413\nTFO与2.6.34内核合并到主线，lwn通告地址\nTFO的使用目前还是有些复杂的，从linux的network文档来看：\nTFO的配置说明：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  tcp_fastopen - INTEGER Enable TCP Fast Open feature (draft-ietf-tcpm-fastopen) to send data in the opening SYN packet. To use this feature, the client application must use sendmsg() or sendto() with MSG_FASTOPEN flag rather than connect() to perform a TCP handshake automatically. The values (bitmap) are 1: Enables sending data in the opening SYN on the client w/ MSG_FASTOPEN. 2: Enables TCP Fast Open on the server side, i.e., allowing data in a SYN packet to be accepted and passed to the application before 3-way hand shake finishes. 4: Send data in the opening SYN regardless of cookie availability and without a cookie option. 0x100: Accept SYN data w/o validating the cookie. 0x200: Accept data-in-SYN w/o any cookie option present. 0x400/0x800: Enable Fast Open on all listeners regardless of the TCP_FASTOPEN socket option. The two different flags designate two different ways of setting max_qlen without the TCP_FASTOPEN socket option. Default: 1 Note that the client \u0026amp; server side Fast Open flags (1 and 2 respectively) must be also enabled before the rest of flags can take effect. See include/net/tcp.h and the code for more details.   为了启用 tcp fast open功能\n- client需要使用sendmsg或者sento系统调用，加上MSG_FASTOPEN flag，来连接server端，代替connect系统调用。 - 对server端不做要求。  linux系统（高版本内核）默认tcp_fastopen为1：\n1 2 3  $ sysctl -a | grep fastopen net.ipv4.tcp_fastopen = 1   测试代码： server.c\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43  // reference: http://blog.csdn.net/hanhuili/article/details/8540227  #include \u0026lt;string.h\u0026gt; #include \u0026lt;sys/types.h\u0026gt; /* See NOTES */#include \u0026lt;sys/socket.h\u0026gt;#include \u0026lt;netinet/in.h\u0026gt;int main(){ int portno = 6666; socklen_t clilen; char buffer[256]; struct sockaddr_in serv_addr, cli_addr; int cfd; int sfd = socket(AF_INET, SOCK_STREAM, 0); // Create socket  bzero((char *) \u0026amp;serv_addr, sizeof(serv_addr)); serv_addr.sin_family = AF_INET; serv_addr.sin_addr.s_addr = INADDR_ANY; serv_addr.sin_port = htons(portno); bind(sfd, \u0026amp;serv_addr,sizeof(serv_addr)); // Bind to well known address  int qlen = 5; // Value to be chosen by application  int err = setsockopt(sfd, IPPROTO_TCP/*SOL_TCP*/, 23/*TCP_FASTOPEN*/, \u0026amp;qlen, sizeof(qlen)); listen(sfd,1); // Mark socket to receive connections  while(1){ cfd = accept(sfd, NULL, 0); // Accept connection on new socket  while(1){ int len = read(cfd,buffer,256); if(len) printf(\u0026#34;tcp fast open: %s\\n\u0026#34;,buffer); else break; // read and write data on connected socket cfd \t} memset(buffer, 0, 256); close(cfd); } }   测试代码：client.c\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34  #include \u0026lt;sys/socket.h\u0026gt;#include \u0026lt;netinet/in.h\u0026gt;#include \u0026lt;netdb.h\u0026gt; #include \u0026lt;errno.h\u0026gt;int main(){ struct sockaddr_in serv_addr; struct hostent *server; char *data = \u0026#34;Hello, tcp fast open\u0026#34;; int data_len = strlen(data); int sfd = socket(AF_INET, SOCK_STREAM, 0); server = gethostbyname(\u0026#34;localhost\u0026#34;); bzero((char *) \u0026amp;serv_addr, sizeof(serv_addr)); serv_addr.sin_family = AF_INET; bcopy((char *)server-\u0026gt;h_addr, (char *)\u0026amp;serv_addr.sin_addr.s_addr, server-\u0026gt;h_length); serv_addr.sin_port = htons(6666); // /usr/src/linux-headers-4.4.0-22/include/linux/socket.h:#define MSG_FASTOPEN\t0x20000000\t/* Send data in TCP SYN */  // int len = sendto(sfd, data, data_len, 0x20000000/*MSG_FASTOPEN*/,  int len = sendto(sfd, data, data_len, MSG_FASTOPEN/*MSG_FASTOPEN*/, (struct sockaddr *) \u0026amp;serv_addr, sizeof(serv_addr)); if(errno != 0){ printf(\u0026#34;error: %s\\n\u0026#34;, strerror(errno)); } close(sfd); }   通信过程：tcpdump\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61  $ sudo tcpdump -i any port 6666 -X # 第一次 ./client.o 00:29:34.820187 IP localhost.51388 \u0026gt; localhost.6666: Flags [S], seq 755101042, win 43690, options [mss 65495,sackOK,TS val 17053 ecr 0,nop,wscale 7,unknown-34,nop,nop], length 0 0x0000: 4500 0040 afef 4000 4006 8cc6 7f00 0001 E..@..@.@....... 0x0010: 7f00 0001 c8bc 1a0a 2d01 ed72 0000 0000 ........-..r.... 0x0020: b002 aaaa fe34 0000 0204 ffd7 0402 080a .....4.......... 0x0030: 0000 429d 0000 0000 0103 0307 2202 0101 ..B.........\u0026#34;... 00:29:34.820284 IP localhost.6666 \u0026gt; localhost.51388: Flags [S.], seq 3725111481, ack 755101043, win 43690, options [mss 65495,sackOK,TS val 17053 ecr 17053,nop,wscale 7], length 0 0x0000: 4500 003c 0000 4000 4006 3cba 7f00 0001 E..\u0026lt;..@.@.\u0026lt;..... 0x0010: 7f00 0001 1a0a c8bc de08 b0b9 2d01 ed73 ............-..s 0x0020: a012 aaaa fe30 0000 0204 ffd7 0402 080a .....0.......... 0x0030: 0000 429d 0000 429d 0103 0307 ..B...B..... 00:29:34.820372 IP localhost.51388 \u0026gt; localhost.6666: Flags [P.], seq 1:21, ack 1, win 342, options [nop,nop,TS val 17053 ecr 17053], length 20 0x0000: 4500 0048 aff0 4000 4006 8cbd 7f00 0001 E..H..@.@....... 0x0010: 7f00 0001 c8bc 1a0a 2d01 ed73 de08 b0ba ........-..s.... 0x0020: 8018 0156 fe3c 0000 0101 080a 0000 429d ...V.\u0026lt;........B. 0x0030: 0000 429d 4865 6c6c 6f2c 2074 6370 2066 ..B.Hello,.tcp.f 0x0040: 6173 7420 6f70 656e ast.open 00:29:34.820433 IP localhost.6666 \u0026gt; localhost.51388: Flags [.], ack 21, win 342, options [nop,nop,TS val 17053 ecr 17053], length 0 0x0000: 4500 0034 f227 4000 4006 4a9a 7f00 0001 E..4.\u0026#39;@.@.J..... 0x0010: 7f00 0001 1a0a c8bc de08 b0ba 2d01 ed87 ............-... 0x0020: 8010 0156 fe28 0000 0101 080a 0000 429d ...V.(........B. 0x0030: 0000 429d ..B. 00:29:34.859246 IP localhost.6666 \u0026gt; localhost.51388: Flags [.], ack 22, win 342, options [nop,nop,TS val 17063 ecr 17053], length 0 0x0000: 4500 0034 f228 4000 4006 4a99 7f00 0001 E..4.(@.@.J..... 0x0010: 7f00 0001 1a0a c8bc de08 b0ba 2d01 ed88 ............-... 0x0020: 8010 0156 fe28 0000 0101 080a 0000 42a7 ...V.(........B. 0x0030: 0000 429d ..B. # 第二次 ./client.o 00:29:39.271936 IP localhost.51398 \u0026gt; localhost.6666: Flags [S], seq 2362540136, win 43690, options [mss 65495,sackOK,TS val 18166 ecr 0,nop,wscale 7,exp-tfo cookiereq], length 0 0x0000: 4500 0040 c69e 4000 4006 7617 7f00 0001 E..@..@.@.v..... 0x0010: 7f00 0001 c8c6 1a0a 8cd1 8068 0000 0000 ...........h.... 0x0020: b002 aaaa fe34 0000 0204 ffd7 0402 080a .....4.......... 0x0030: 0000 46f6 0000 0000 0103 0307 fe04 f989 ..F............. 00:29:39.271986 IP localhost.6666 \u0026gt; localhost.51398: Flags [S.], seq 3703577773, ack 2362540137, win 43690, options [mss 65495,sackOK,TS val 18166 ecr 18166,nop,wscale 7], length 0 0x0000: 4500 003c 0000 4000 4006 3cba 7f00 0001 E..\u0026lt;..@.@.\u0026lt;..... 0x0010: 7f00 0001 1a0a c8c6 dcc0 1cad 8cd1 8069 ...............i 0x0020: a012 aaaa fe30 0000 0204 ffd7 0402 080a .....0.......... 0x0030: 0000 46f6 0000 46f6 0103 0307 ..F...F..... 00:29:39.272038 IP localhost.51398 \u0026gt; localhost.6666: Flags [P.], seq 1:21, ack 1, win 342, options [nop,nop,TS val 18166 ecr 18166], length 20 0x0000: 4500 0048 c69f 4000 4006 760e 7f00 0001 E..H..@.@.v..... 0x0010: 7f00 0001 c8c6 1a0a 8cd1 8069 dcc0 1cae ...........i.... 0x0020: 8018 0156 fe3c 0000 0101 080a 0000 46f6 ...V.\u0026lt;........F. 0x0030: 0000 46f6 4865 6c6c 6f2c 2074 6370 2066 ..F.Hello,.tcp.f 0x0040: 6173 7420 6f70 656e ast.open 00:29:39.272072 IP localhost.6666 \u0026gt; localhost.51398: Flags [.], ack 21, win 342, options [nop,nop,TS val 18166 ecr 18166], length 0 0x0000: 4500 0034 5a58 4000 4006 e269 7f00 0001 E..4ZX@.@..i.... 0x0010: 7f00 0001 1a0a c8c6 dcc0 1cae 8cd1 807d ...............} 0x0020: 8010 0156 fe28 0000 0101 080a 0000 46f6 ...V.(........F. 0x0030: 0000 46f6 ..F. 00:29:39.311280 IP localhost.6666 \u0026gt; localhost.51398: Flags [.], ack 22, win 342, options [nop,nop,TS val 18176 ecr 18166], length 0 0x0000: 4500 0034 5a59 4000 4006 e268 7f00 0001 E..4ZY@.@..h.... 0x0010: 7f00 0001 1a0a c8c6 dcc0 1cae 8cd1 807e ...............~ 0x0020: 8010 0156 fe28 0000 0101 080a 0000 4700 ...V.(........G. 0x0030: 0000 46f6 ..F.   奇怪的是，在代码中启用tcp_fastopen的结果和不启用，并没有区别。那这是什么原因呢？\n通过搜索，发现在介绍tcp fast open优化shadowsocks时，设置net.ipv4.tcp_fastopen为3，虽然奇怪，但是可以试试：\n1 2 3  $ sysctl -a | grep fastopen net.ipv4.tcp_fastopen = 3   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62  # 第一次，server返回cookie unknown-34 0x38af51c10bf41ca4 00:36:36.667932 IP localhost.52220 \u0026gt; localhost.6666: Flags [S], seq 3662514892, win 43690, options [mss 65495,sackOK,TS val 122515 ecr 0,nop,wscale 7,unknown-34,nop,nop], length 0 0x0000: 4500 0040 545f 4000 4006 e856 7f00 0001 E..@T_@.@..V.... 0x0010: 7f00 0001 cbfc 1a0a da4d 8acc 0000 0000 .........M...... 0x0020: b002 aaaa fe34 0000 0204 ffd7 0402 080a .....4.......... 0x0030: 0001 de93 0000 0000 0103 0307 2202 0101 ............\u0026#34;... 00:36:36.667990 IP localhost.6666 \u0026gt; localhost.52220: Flags [S.], seq 3186866007, ack 3662514893, win 43690, options [mss 65495,sackOK,TS val 122515 ecr 122515,nop,wscale 7,unknown-34 0x38af51c10bf41ca4,nop,nop], length 0 0x0000: 4500 0048 0000 4000 4006 3cae 7f00 0001 E..H..@.@.\u0026lt;..... 0x0010: 7f00 0001 1a0a cbfc bdf3 b757 da4d 8acd ...........W.M.. 0x0020: d012 aaaa fe3c 0000 0204 ffd7 0402 080a .....\u0026lt;.......... 0x0030: 0001 de93 0001 de93 0103 0307 220a 38af ............\u0026#34;.8. 0x0040: 51c1 0bf4 1ca4 0101 Q....... 00:36:36.668050 IP localhost.52220 \u0026gt; localhost.6666: Flags [P.], seq 1:21, ack 1, win 342, options [nop,nop,TS val 122515 ecr 122515], length 20 0x0000: 4500 0048 5460 4000 4006 e84d 7f00 0001 E..HT`@.@..M.... 0x0010: 7f00 0001 cbfc 1a0a da4d 8acd bdf3 b758 .........M.....X 0x0020: 8018 0156 fe3c 0000 0101 080a 0001 de93 ...V.\u0026lt;.......... 0x0030: 0001 de93 4865 6c6c 6f2c 2074 6370 2066 ....Hello,.tcp.f 0x0040: 6173 7420 6f70 656e ast.open 00:36:36.668109 IP localhost.6666 \u0026gt; localhost.52220: Flags [.], ack 21, win 342, options [nop,nop,TS val 122515 ecr 122515], length 0 0x0000: 4500 0034 69cb 4000 4006 d2f6 7f00 0001 E..4i.@.@....... 0x0010: 7f00 0001 1a0a cbfc bdf3 b758 da4d 8ae1 ...........X.M.. 0x0020: 8010 0156 fe28 0000 0101 080a 0001 de93 ...V.(.......... 0x0030: 0001 de93 .... 00:36:36.707264 IP localhost.6666 \u0026gt; localhost.52220: Flags [.], ack 22, win 342, options [nop,nop,TS val 122525 ecr 122515], length 0 0x0000: 4500 0034 69cc 4000 4006 d2f5 7f00 0001 E..4i.@.@....... 0x0010: 7f00 0001 1a0a cbfc bdf3 b758 da4d 8ae2 ...........X.M.. 0x0020: 8010 0156 fe28 0000 0101 080a 0001 de9d ...V.(.......... 0x0030: 0001 de93 .... # 第二次，client发送请求时，将cookie写在syn包中，同时带上发送的数据；server端校验后(kernel和tcp/ip协议栈做校验)后返回成功，如此在3次握手中节省了一次rtt时间 00:36:38.744954 IP localhost.52226 \u0026gt; localhost.6666: Flags [S], seq 1820632025:1820632045, win 43690, options [mss 65495,sackOK,TS val 123034 ecr 0,nop,wscale 7,unknown-34 0x38af51c10bf41ca4,nop,nop], length 20 0x0000: 4500 005c 4343 4000 4006 f956 7f00 0001 E..\\CC@.@..V.... 0x0010: 7f00 0001 cc02 1a0a 6c84 a3d9 0000 0000 ........l....... 0x0020: d002 aaaa fe50 0000 0204 ffd7 0402 080a .....P.......... 0x0030: 0001 e09a 0000 0000 0103 0307 220a 38af ............\u0026#34;.8. 0x0040: 51c1 0bf4 1ca4 0101 4865 6c6c 6f2c 2074 Q.......Hello,.t 0x0050: 6370 2066 6173 7420 6f70 656e cp.fast.open 00:36:38.745022 IP localhost.6666 \u0026gt; localhost.52226: Flags [S.], seq 3848342665, ack 1820632046, win 43690, options [mss 65495,sackOK,TS val 123034 ecr 123034,nop,wscale 7], length 0 0x0000: 4500 003c 0000 4000 4006 3cba 7f00 0001 E..\u0026lt;..@.@.\u0026lt;..... 0x0010: 7f00 0001 1a0a cc02 e561 0c89 6c84 a3ee .........a..l... 0x0020: a012 aaaa fe30 0000 0204 ffd7 0402 080a .....0.......... 0x0030: 0001 e09a 0001 e09a 0103 0307 ............ 00:36:38.745072 IP localhost.52226 \u0026gt; localhost.6666: Flags [.], ack 1, win 342, options [nop,nop,TS val 123034 ecr 123034], length 0 0x0000: 4500 0034 4344 4000 4006 f97d 7f00 0001 E..4CD@.@..}.... 0x0010: 7f00 0001 cc02 1a0a 6c84 a3ee e561 0c8a ........l....a.. 0x0020: 8010 0156 fe28 0000 0101 080a 0001 e09a ...V.(.......... 0x0030: 0001 e09a .... 00:36:38.745127 IP localhost.52226 \u0026gt; localhost.6666: Flags [F.], seq 1, ack 1, win 342, options [nop,nop,TS val 123034 ecr 123034], length 0 0x0000: 4500 0034 4345 4000 4006 f97c 7f00 0001 E..4CE@.@..|.... 0x0010: 7f00 0001 cc02 1a0a 6c84 a3ee e561 0c8a ........l....a.. 0x0020: 8011 0156 fe28 0000 0101 080a 0001 e09a ...V.(.......... 0x0030: 0001 e09a .... 00:36:38.747232 IP localhost.6666 \u0026gt; localhost.52226: Flags [.], ack 2, win 342, options [nop,nop,TS val 123035 ecr 123034], length 0 0x0000: 4500 0034 ec10 4000 4006 50b1 7f00 0001 E..4..@.@.P..... 0x0010: 7f00 0001 1a0a cc02 e561 0c8a 6c84 a3ef .........a..l... 0x0020: 8010 0156 fe28 0000 0101 080a 0001 e09b ...V.(.......... 0x0030: 0001 e09a ....    上述通信过程中  第一次，server返回cookie unknown-34 0x38af51c10bf41ca4 第二次，client发送请求时，将cookie写在syn包中，同时带上发送的数据；server端校验后(kernel和tcp/ip协议栈做校验)后返回成功，如此在3次握手中节省了一次rtt时间   也就是说，在net.ipv4.tcp_fastopen设置为3时，tcp fastopen特性使能  关于如何使能TFO，在前文中的TFO的配置说明中，我们可以看到，\n1 2 3 4 5 6 7 8 9 10  The values (bitmap) are 1: Enables sending data in the opening SYN on the client w/ MSG_FASTOPEN. 使能client端的TFO特性 2: Enables TCP Fast Open on the server side, i.e., allowing data in a SYN packet to be accepted and passed to the application before 3-way hand shake finishes. 使能server端的TFO特性 4: Send data in the opening SYN regardless of cookie availability and without a cookie option.   并且这个标志是位操作，如果我在本机做实验，将本机作为sever端和client端的话，需要两个位都使能，所以应该将该值设置为3.\n同时我们可以看到，tcp fast open是非常向后兼容的，升级成本不高，需要高于3.7+版本内核，但总体来说值得采用。\nnginx 1.5.18（2013年）开始支持tcp fast open\nTODO LIST  TFO在移动端场景中的性能体现：android+nginx tcp fast open 在内核中的实现  参考链接  TFO\u0026mdash;google tcp fast open protocol wikipedia TFO简介 tfo的golang实现(github) 上一行项目的作者bradley falzon google关于tfo的论文  ","date":"2016-05-09T15:53:34+08:00","permalink":"https://bg2bkk.github.io/p/tcp_fast_open%E7%9A%84%E6%A6%82%E5%BF%B5-%E4%BD%9C%E7%94%A8%E4%BB%A5%E5%8F%8A%E5%AE%9E%E7%8E%B0/","title":"tcp_fast_open的概念 作用以及实现"},{"content":"  os\n  bufio\n  ioutil\n  bytes\n  io操作对比\n  references\n  io.Reader\n  ","date":"2016-05-09T14:34:50+08:00","permalink":"https://bg2bkk.github.io/p/golang%E4%B8%AD%E7%9A%84io%E6%93%8D%E4%BD%9C%E5%AF%B9%E6%AF%94/","title":"golang中的io操作对比"},{"content":"time_wait相关   tcp_tw_reuse\n 允许重用    tcp_tw_recycle\n 允许快速回收    net.ipv4.tcp_max_tw_buckets\n 系统可以保持timewait状态socket连接的最大数量。桶需要小一点，强迫系统回收端口    1 2 3 4 5 6  Maximal number of timewait sockets held by system simultaneously. If this number is exceeded time-wait socket is immediately destroyed and warning is printed. This limit exists only to prevent simple DoS attacks, you _must_ not lower the limit artificially, but rather increase it (probably, after increasing installed memory), if network conditions require more than default value.     net.ipv4.tcp_timestamps 和 net.ipv4.tcp_tw_recycle\n 对于客户端处于NAT环境下时，多个客户端通过一个出口发出请求，对服务端而言这些请求的来源IP是一样的；如果设置timestamps，TCP缓存每个主机（IP）最近的时间戳，如果后续请求时间戳小雨缓存的时间戳的话，将视为无效，该请求的数据包会被丢弃；多个客户端发出的请求数据包的到达是无序的，所以有可能导致请求被丢弃，得不到服务端的响应。所以这个时候我们需要关闭timestamp机制，而如果tcp_tw_recycle开启的话，这种机制将被激活，唯一的解决办法就是关闭tcp_tw_recycle。 tcp_tw_recycle的作用是快速回收端口，目的是让主机有端口可用；我们通过设置tcp_max_tw_buckets，将其限制到小与65536的值，比如50000，那么系统在分配超过50000端口后将尝试回收端口，效果和tcp_tw_recycle是一样的，所以设置tcp_max_tw_buckets也能实现目的。但是该值不能设置太小，因为一旦超过这个值，timewait状态的socket将被销毁，只输出警告。    linux doc\n  reference\n huoding linux内核调优参数对比和解释 sysconf和limits.conf原理    tcp fast open 相关 so_reuse_addr 和 so_reuse_port相关 ","date":"2016-05-06T16:03:46+08:00","permalink":"https://bg2bkk.github.io/p/tcpip-linux%E7%BD%91%E7%BB%9C%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/","title":"TCPIP\u0026 Linux网络性能调优"},{"content":"C语言中的宏 在看代码的过程中我看到了 ## 和 # 两个符号，前一个我知道，后一个就不清楚了。在文档中我才知道C语言有这么多的宏，##表示连接符concat，而#EXP表示将代码中的表达式EXP转为字符串，这样写在错误日志中我们就知道是那句代码导致错误的了。\nC语言中的宏以及用法还有很多，上述文档总结的非常好，除了##和#外，还有\u0026hellip;、宏展开时多次求值问题都有讲解，值得一读一试。\n这篇文章也不错，他们都源自于gnu的官方文档\nOmniGraffle  OmniGraffle简书 UX基础 - OmniGraffle新手指南  markdown * [markdown边角料](http://blog.csdn.net/phunxm/article/details/49565427)  kernel  kernel工程导论  内存管理  http://blog.jobbole.com/103993/ http://blog.jobbole.com/88673/  前端开发   如何使textarea的大小随着其内容增加而变化呢？\n  解决方法\n 1、http://audi.tw/Blog/Javascript/javascript.textarea.autogrow.asp 2、http://www.cnblogs.com/xmmcn/archive/2012/12/18/2822968.html 3、jquery 插件: https://bobscript.com/archives/419/    awk  http://blog.sina.com.cn/s/blog_4a033b090100xo2b.html http://blog.csdn.net/junjieguo/article/details/7525794  postgre  修改表结构，postgre_wiki 插入数据、postgre_wiki 清楚pg_xlog  python  python魔术方法  指南 入门    [http协议] http协议301和302的区别\n http://www.cnblogs.com/caiyuanzai/archive/2012/04/24/2469013.html http://blog.csdn.net/qmhball/article/details/7838989  linux socket编程样例   http://alas.matf.bg.ac.rs/manuals/lspe/snode=106.html\n  进程间传递fd\n  linux apue编程  epoll是同步非阻塞的  epoll、select等多路服用IO，将fd加入等待时间的队列中，每隔一段时间去轮询一次，因此是同步的；优点是能够在等待任务的时间里去做别的任务；缺点是任务完成的响应延迟增大，因为每隔一段时间去轮询他们，在时间间隔内任务可能已经完成而等待处理等待了一段时间了。\n参考链接\n同步/异步指的是被调用方的通知方式，被调用方完成后，主动通知调用方，还是等待调用方发现。前者是异步，后者是同步。从这里也可以看出，异步IO通知调用方时，数据已经就绪，对于网络IO来说，异步IO已经将数据从内核复制到用户空间了。\n阻塞/非阻塞是调用方的等待方式，是一直等待在做的事件完成，还是去做别的事情，等到在做的事件完成后再接着进行处理。前者是阻塞，后者是非阻塞\n因此epoll是同步和非阻塞的。\n性能分析  有用的systemtap脚本  分布式存储  知识体系  B-Tree    分布式ID生成  ID  方案一： 常规数据库的auto increment服务  改进：可以将ID划均分给若干数据库，每个数据库自增的起点不一样，可以保证各库生成ID不同  缺点是非强一致性     方案二： 单点批量生成；ID生成服务每次从数据库预定一定容量的ID，然后派发；可以成倍降低数据库压力；  缺点：单点服务、可能造成空洞； 改进：找备胎，一旦主ID服务挂掉，备胎立刻备上；通过vip+keepalived实现   方案三：uuid 方案四：当前毫秒数；缺点是每个毫秒容量有限，也可能重复 方案五：将64bit数字作为ID，分别包含字段：毫秒数、业务线、机房、机器、以及毫秒内序列号；根据业务来规划容量；毫秒数可以保证ID是趋势自增的   ID  分布式锁  http://www.cnblogs.com/zhengyun_ustc/archive/2012/11/17/topic2.html http://www.jeffkit.info/2011/07/1000/  一致性哈希 consistent hashing  http://www.codeproject.com/Articles/56138/Consistent-hashing http://blog.huanghao.me/?p=14 http://blog.csdn.net/sparkliang/article/details/5279393  2PC、3PC和Paxos算法  coolshell  并发编程   volatile\n  并发编程\n  聊聊并发\n  nginx配置文件   rewrite:\n http://www.xiehaichao.com/articles/428.html http://seanlook.com/2015/05/17/nginx-location-rewrite/    nginx配置使用用户自定义错误页面\n  Lua的学习、使用和源码精读 lua的元表   http://lua-users.org/wiki/MetamethodsTutorial\n 元表用来扩展lua对象的功能，元表的含义在于生来就有，lua对象本身会带有这个表，所以称为元表 metatable也是普通的lua table，包含一系列元方法metamethods，每个元方法有对应的events触发；比如算术运算符、__index 等操作 __index    http://lua-users.org/wiki/MetatableEvents\n  控制类型继承；当访问myTable[key]，而table中没有key域时，如果元表有__index项：\n 如果__index是函数，则调用该函数 如果__index是table，返回这个table中key域的值；如果__index是table并且该table没有key域，但是该table有__index，则继续查找(calls fallback function or fallback table) 使用rawget(myTable, key)可以跳过metatable    __index是一个应用广泛并用处很大的元方法metamethod\n 如果想获取table中的元素key，而key在table中没有找到，该方法可以定义为函数或者一个table，来寻找key。  如果__index是函数，该函数的第一个参数是没有找到key的这个table，第二个参数是key； 如果__index是table，那么将在该table中寻找key，如果没有找到，可以继续从这个table的__index寻找，因此你可以通过__index进行一整个链条的查找。      __metatable\n 用于隐藏metatable，当调用getmetatable(myTable)时，如果该域不为空，则返回这个域的值，而不是metatable    sample code\n    Lua面向对象  http://dabing1022.github.io/2014/03/18/multiple-inheritance-understand-lua/  Lua源码精读  Lua的全局和状态，以及初始化  Lua的全局和状态  在调用lua_newstate 初始化Lua虚拟机时，会创建一个全局状态和一个线程（或称为调用栈），这个全局状态在整个虚拟机中是唯一的，供其他线程共享。一个Lua虚拟机中可以包括多个线程，这些线程共享一个全局状态，线程之间也可以调用lua_xmove函数来交换数据。   LuaVM 初始化 lua_State    Lua与C的交互 * [深入理解Lua与C用于数据交互的栈](http://blog.csdn.net/maximuszhou/article/details/21331819) * 为啥要通过 栈 来通信呢？ * Lua是动态类型语言，在Lua语言中没有类型定义的语法，每个值都携带了它自身的类型信息，而C语言是静态类型语言 * Lua使用垃圾收集，可以自动管理内存，而C语言要求程序自己释放分配的内存，需应用程序自身管理内存 * 压栈的影响 * C将值压入栈中后，Lua将会生成相应类型的结构，存储和管理这个值 * Lua不会持有指向VM外部的指针，指向的都是自己的结构和栈上的结构 * 比如压入字符串，Lua生成Lua_TTSTRING类型的对象，C可以随意释放这个字符串   http://if-yu.info/lua-notes.html  list和nil * https://techsingular.org/2012/12/22/programming-in-lua%EF%BC%88%E5%9B%9B%EF%BC%89%EF%BC%8D-nil-%E5%92%8C-list/ * nil不但不是无的意思，反而在list中起到占位和有的意思。  lua的first class  可以被赋值给变量； 可以作为参数； 可以作为返回值； 可以作为数据结构的构成部分。( 注意 nil 并不完全符合这个要求，但是可以通过某个 field 的缺失来表示 nil。)  Lua的GC * lua的[gc](https://techsingular.org/2013/10/27/lua-%E7%9A%84%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/)  lua的table * https://facepunch.com/showthread.php?t=1306348   I don\u0026rsquo;t believe this is correct. It was my understanding that Lua tables are implemented as a two-part data structure whereby dense non-negative integer keys are stored as a simple array and are therefore indexed by a simple pointer addition and dereference, which is O(1). All other keys (non-integer, negative and sparse integer) are stored in a hashmap as a chained scatter table which stores key-values pairs as a flat array indexed by the hash of the key. Collisions are resolved by storing pointers to the next element with the same hash alongside this (essentially a linked list of colliding elements). At worst case, where all elements collide, the complexity of this implementation is O(n), however it is expected that on average the number of collisions per element is 1 and the maximum is 2; this means that the average complexity is O(1).\n  The implementation of Lua tables is such that, even with a huge number of elements, lookup is as quick as possible.\n lua函数使用   setmetatable\n https://www.lua.org/manual/5.2/manual.html setmetatable(table, metatable)  将metatable设置为table的元表，（在Lua中只能设置table的元表，其他类型的对象不行，除非使用C）。如果metatable为nil，则参数cable的元表被清除；如果该table的__metatable不为空，则抛出异常   该函数返回table    collectgarbage(\u0026ldquo;count\u0026rdquo;)\n 垃圾回收函数    lua yield 和 resume\n http://www.lua.org/manual/5.2/manual.html#pdf-coroutine.resume    1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  -- http://my.oschina.net/wangxuanyihaha/blog/186401 function foo(a) print(\u0026#34;foo\u0026#34;, a) return coroutine.yield(2 * a) end co = coroutine.create(function ( a, b ) print(\u0026#34;co-body\u0026#34;, a, b) local r = foo(a + 1) print(\u0026#34;co-body\u0026#34;, r) local r, s = coroutine.yield(a + b, a - b) print(\u0026#34;co-body\u0026#34;, r, s) return b, \u0026#34;end\u0026#34; end) print(\u0026#34;main\u0026#34;, coroutine.resume(co, 1, 10)) print(\u0026#34;main\u0026#34;, coroutine.resume(co, \u0026#34;m\u0026#34;))\t-- resume的参数 \u0026#39;m\u0026#39; 是在调用yield传入的，所以本次是在第5行 return m print(\u0026#34;main\u0026#34;, coroutine.resume(co, \u0026#34;x\u0026#34;, \u0026#34;y\u0026#34;)) print(\u0026#34;main\u0026#34;, coroutine.resume(co, \u0026#34;x\u0026#34;, \u0026#34;y\u0026#34;))   1 2 3 4 5 6 7 8  co-body\t1\t10 foo\t2 main\ttrue\t4 co-body\tm main\ttrue\t11\t-9 co-body\tx\ty main\ttrue\t10\tend main\tfalse\tcannot resume dead coroutine   lua编码的陷阱 * [字符串拼接导致垃圾产生](http://tech.uc.cn/?p=1131)  golang golang的并发、协程和channel  golang并发编程初探  1 2 3 4 5 6  for i := 0; i \u0026lt; 10; i++ { go func() { arr[i] = i + i*i chs[i] \u0026lt;- arr[i] }() }   类似于如上形式的for循环中启动go协程，在for循环结束时协程才会开执行，所以每个协程用到的i都是最大值10\n可以将i加入到协程的参数中，如下：\n1 2 3 4 5 6 7 8  for i := 0; i \u0026lt; 10; i++ { chs[i] = make(chan int) go func(i) { arr[i] = i + i*i chs[i] \u0026lt;- arr[i] }(i) }   可以用局部变量保存i值\n1 2 3 4 5 6 7 8  for i := 0; i \u0026lt; 10; i++ { i := i chs[i] = make(chan int) go func() { arr[i] = i + i*i chs[i] \u0026lt;- arr[i] }() }     golang的底层数据结构\n  golang多协程channel同步\n sync.WaitGroup defer recover    golang闭包与协程使用\n  golang设计模式 * [单例模式](http://marcio.io/2015/07/singleton-pattern-in-go/) * [golang map reduce](https://gist.github.com/mcastilho)  golang接口 * https://github.com/astaxie/build-web-application-with-golang/blob/master/zh/02.6.md * http://xiaorui.cc/2016/03/11/%E5%85%B3%E4%BA%8Egolang-struct-interface%E7%9A%84%E7%90%86%E8%A7%A3%E4%BD%BF%E7%94%A8/ * http://blog.csdn.net/zhangzhebjut/article/details/24974315    UML图\n 实现关系、泛化关系、关联关系、聚合关系 http://design-patterns.readthedocs.io/zh_CN/latest/read_uml.html    设计模式\n http://tengj.top/2016/04/04/sjms3abstractfactory/    ","date":"2016-05-06T11:39:48+08:00","permalink":"https://bg2bkk.github.io/p/effective-tips-in-daily-learning/","title":"effective tips in daily learning"},{"content":"  https://zh.wikipedia.org/wiki/X86%E8%B0%83%E7%94%A8%E7%BA%A6%E5%AE%9A\n  ABI\n 调用约定\tcalling conventions 类型表示\ttype representation 名称修饰\tname mangling    cdecl( C declaration ): X86架构下：\n 函数实参在线程栈上从右到左依次入栈 函数结果保存在寄存器 EAX/AX/AL 中 浮点型结果保存在 寄存器 ST0 中 编译后的函数名 以 _ 为前缀 调用者负责从线程栈中弹出实参（清栈） 8 bits 或者 16 bits的整形实参提升为32bits 受函数调用影响的寄存器：EAX, ECX, EDX, ST0 - ST7, ES, GS 不受函数调用影响的寄存器：EBX, EBP, ESP, EDI, ESI, CS, DS    ","date":"2016-05-03T16:39:34+08:00","permalink":"https://bg2bkk.github.io/p/x86%E8%B0%83%E7%94%A8%E7%BA%A6%E5%AE%9A/","title":"X86调用约定"},{"content":"黄振栋简历 联系方式  Email：bg2bkk # gmail.com 微博：@bg2bkk  个人信息  男/1990 硕士/哈工大深圳研究生院计算机系 工作年限：14个月 英语水平：CET-6 技术博客：http://bg2bkk.github.io Github：http://github.com/bg2bkk  教育背景 - 2012.09 ~ 2015.01 哈尔滨工业大学 计算机 硕士 - 2008.09 ~ 2012.06 哈尔滨工程大学 计算机 学士   技能清单  c/ lua/ python/ golang/ shell/ vhdl nginx/ ngx_lua/ redis linux kernel/ performance profiling 算法、数据结构和设计模式 linux系统编程、多线程编程、网络编程 embedded system \u0026amp;\u0026amp; IOT: ble/mqtt/elua microprocessor: stm32 51 avr FPGA   自我评价  热爱计算机，热爱编程，热爱程序员这个工作   工作经历 - 2015.01 ~ NOW\t新浪微博\t系统开发工程师 - 2013.09 ~ 2014.05\t极光推送\t后台开发实习生  项目经历 新浪微博 系统开发工程师 （ 2015年1月 ~ 2016年8月 ）  微博防抓站系统   手机微博七层动态调度系统dygateway    手机微博 HTTP DNS 服务端开发  极光推送(jpush.cn) 后台开发实习生（ 2013年9月 ~ 2014年5月 ）  大规模用户模拟系统   项目 演讲和讲义  ABTestingGateway：手机微博七层动态调度系统中关于灰度发布和动态分流的子项目，780+ stars。 2015年OSC源创会运维专场：基于动态策略的灰度发布系统   兴趣点   兴趣广泛，从Linux服务端开发到安卓开发，从单片机开发到FPGA开发，从kernel源码到lua源码，我都有兴趣:)\n  对所使用的软件或服务，愿意并有能力进行深入理解，从设计思路到源码实现着手\n TCP/ DNS/ HTTP Linux/ Nginx/ Redis/ Lua/    对动态追踪和性能优化尤其有兴趣\n linux/nginx的配置参数调优 通过perf或者systemtap分析性能瓶颈    Linux kernel\n tcp/ip stack epoll memory management     个人项目   smarthome\n 基于ESP8266单片机的家庭环境参数监测模块，目前支持温度、湿度、PM2.5等参数 通过wifi上传监测参数和心跳到远程server 通过mqtt进行远程推送和远程控制 server端采用nginx+nodejs+redis实现 使用nginx的rtmp模块实现实时视频监控 TODO LIST  opencv抓取关键帧上报 android app简易开发 使用dart 甲醛传感器监测室内甲醛气体      MyDict\n 一个离线词典 原作者采用trie树对离线词库生成索引，我采用三向单词查找树(Ternary search tries TSTs)实现 数据结构解决实际问题，体现程序员的价值    NFA_By_Python\n 《计算理论》专业课作业，内容是将使用NFA解析正则表达式，并将其可视化。 python分析正则表达式，自动生成dot代码，通过graphviz画图并生成pdf 这恐怕是我离计算机科学最近的一次了:) 其实想想，计算理论还是非常有趣的，而我也无比热爱这门科学    img_process_vhdl\n 纯VHDL写的通用图像处理框架，在FPGA进行图像卷积运算，进而可以实现滤波、开闭等操作 考虑到github上好像逻辑工程师不多，我就不写README了。 以后再也不碰FPGA了，VHDL这种逻辑语言其实没必要人肉来写    ","date":"2016-04-22T11:25:56+08:00","permalink":"https://bg2bkk.github.io/p/resume/","title":"resume"},{"content":" DNS消息格式 EDNS详解 rfc6891 edns_client_subnet draft 小米的ends实践  1  6. respond时也需要增加一个Additional RRs区域，直接把请求的Additional内容发过去就可以(如果支持source netmask，将请求中的source netmask复制到scope netmask中，OpenDNS要求必须支持scope netmask)   * 意思是非OpenDNS就可以不支持scope netmask吗？目前新浪的仍然不支持    miekg/dns: golang lib\n  dig with edns\n https://www.gsic.uva.es/~jnisigl/dig-edns-client-subnet.html http://xmodulo.com/geographic-location-ip-address-command-line.html 在线查询：curl ipinfo.io/23.66.166.151    DNS报文格式\n IP packet  IP Header 20 bytes IP Data: UDP  UDP Header 8 bytes UDP Data: DNS  DNS Header 12 bytes DNS Data: RR  RR: Question[] RR: Answer[] RR: Authority[] RR: Additional[] RR  QName QType QClass RDLENGTH RDATA   RR OPT  QName null QType OPT=41 QClass = UDP payload 2bytes TTL = Extended-RCODE 1byte: extend + VERSION 1byte: 0 + Z 2bytes: 0 RDLen\tlen of data(OPT) OPT  Option-Code 2bytes: EDNS0_SUBNET Option-Length 2bytes Option-Data  Family 1byte: IPV4(1) Source Netmask 1byte: 32 Scope Netmask 1byte: 0 Client Subnet 4bytes: 65.135.152.203                  我们总是在追一些时髦的技术，而不顾基础还不牢靠\n  我们总是看见新的框架，然而框架本质上仍然是那些东西，mvc，cs\n  ","date":"2016-04-13T11:37:24+08:00","permalink":"https://bg2bkk.github.io/p/dns-with-golang/","title":"DNS with golang"},{"content":"  stlink\n https://github.com/texane/stlink 用于下载调试 将windows keil编译出的elf、bin等文件烧进stm32，正常工作 todo: stflash    https://github.com/rowol/stm32_discovery_arm_gcc\n gcc to make stm32 gcc makefile    stm32cubemx\n 用于生成代码 生成代码后报 Gtk-Message: Failed to load module \u0026ldquo;overlay-scrollbar\u0026rdquo;  原因：The Message lines mean you are missing the overlay-scrollbar-gtk2 and unity-gtk2-module packages. 解决办法：http://askubuntu.com/questions/453124/gtk-message-and-warnings-in-ubuntu-14-04 apt-get install overlay-scrollbar-gtk2      ","date":"2016-04-12T10:20:13+08:00","permalink":"https://bg2bkk.github.io/p/developing-stm32-on-linux/","title":"Developing stm32 on Linux"},{"content":"  What Your Computer Does While You Wait 关于现代CPU和OS有详解\n  读薄csapp\n  深入探索并发编程\n  刘浩mit 6.824 代码\n  packagecloud: guide to linux system call ltrace strace\n  linux 网络栈 IO栈\n  一位很棒的小朋友\n  赖明星数据库\n  netfilter\n  项仲的博客，cgroup和linux调度器等\n  intel 什么是代码现代化\n  https://github.com/martinezjavier/ldd3\n ldd3在kernel-2.6.32、kernel-2.6.35和kernel-2.6.37调试通过，可供学习。 我使用ubuntu-10.04，kernle-2.6.32测试    https://github.com/duxing2007/ldd3-examples-3.x\n ldd3在kernel-4.2.0-27、ubuntu-14.04测试，调试通过，可供学习    https://github.com/cmus/cmus\n 命令行式的音乐播放器，依赖的解码库较多    wangle\n facebook的RPC框架 所依赖的一些异步库，比如folly github主页看起来非常清爽，代码质量十分之高，而且不是那种为了kpi而造轮子的，每个项目都有用处，高层项目构建于基础项目 facebook主页可以多看看    https://github.com/cyfdecyf/spinlock\n 自旋锁专业研究    vdsotest\n vdso研究学习    google\n googletest gperftool    c gui lib\n https://github.com/vurtun/nuklear https://github.com/andlabs/libui    redis-lua bloom filter\n https://github.com/erikdubbelboer/redis-lua-scaling-bloom-filter redis实现的布隆过滤器    ","date":"2016-04-12T10:19:38+08:00","permalink":"https://bg2bkk.github.io/p/github-%E4%B8%8A%E9%82%A3%E4%BA%9B%E4%BB%A4%E6%88%91%E6%84%9F%E5%88%B0%E6%83%8A%E8%89%B3%E5%8F%88%E5%AE%9E%E7%94%A8%E7%9A%84%E9%A1%B9%E7%9B%AE/","title":"github 上那些令我感到惊艳又实用的项目"},{"content":"  买VPS，vultr的设备，使用起来还是蛮简单的。信用卡一张，注册并扣费0.1美元会送50美元，两个月内用完。我开始部署了一个日本的最便宜的5美元一月的vps，使用起来还不错，youtube 480P没问题；但是我通过这送的50美元实验了以下几个配置的机器速度，洛杉矶机房20美元，洛杉矶机房5美元，日本机房5美元，日本机房10美元，发现ping vps-ip时美国机房都是170ms，日本机房是220ms，原因可能是即使日本离得近，去日本的路由也要绕道美国才到日本的，所以我们直接选择美国机房好了。位于西海岸的洛杉矶机房，让你打开youtube 1080P毫无压力，白天晚上都没问题。\n  如何手动搭建shadowsocks服务呢，网上有太多的教程了\n python版shadowsocks  ss服务的鼻祖，支持多用户多端口配置 参考教程：py版ss服务      1 2 3 4  wget --no-check-certificate https://raw.githubusercontent.com/tennfy/shadowsocks-libev/master/debian_shadowsocks_tennfy.sh chmod a+x debian_shadowsocks_tennfy.sh sudo ./debian_shadowsocks_tennfy.sh    * /etc/init.d/shadowsocks-libev start    shadowsocks客户端\n  全平台：windows、linux、OSX；android、ios；\n  客户端\n  windows\n  linux\n ubuntu用户建议使用apt-get安装 其他发行版用户。。。我还不知道    OSX\n 我没用过    android\n  ios\n    privoxy将sock5转为http连接\n macos    如果您觉得shadowsocks很容易搭建起来，想试一下的话，可以通过的推荐链接来注册，这样会有一定奖励:http://www.vultr.com/?ref=6870148\n  ","date":"2016-04-11T00:33:17+08:00","permalink":"https://bg2bkk.github.io/p/shadowsocks-go-through-the-fuck-gfw/","title":"shadowsocks go through the Fuck GFW"},{"content":"刷leetcode的时候，需要调试代码。 需要本地有开发环境，结果没有，上学的时候还自己弄了一个，lowb的很。近来还是想刷leetcode，发现还是需要个环境，这个时候我的想法就不一样了。上学的时候是，看见问题了就直接去解决这个问题，并不会多想；上一年班后，现在看这个问题，就会寻思下，有没有更好的办法，业界通用做法是什么，业界里的标杆公司和标杆人物又是怎么做的。\n我寻思了我的场景，发现我应该是要做单元测试的，写好一个函数或者接口，提交给测试框架（leetcode），那么就找找吧。\n所以我第一步是先google，关键词“c 单元测试”，中文信息还是比较少的，直接搜\u0026quot;c unit test\u0026quot;，效果还是不错的。首先是stackoverflow的结果，提到很多，junit，cunit等等，最后一个答案是googletest，眼前一亮，github搜一下，得到结果，是一个一直活跃着的项目。两篇博文，\u0026lsquo;testing c++ code with the GoogleTest framework\u0026rsquo;和\u0026lsquo;unit testing c code with the GoogleTest framework\u0026rsquo;。\ngoogletest其实由googletest和googlemock组成，前者是单元测试，后者是模拟c模块的。\ngoogletest的使用文档和陶辉的实践过程，还有coderzh的实践过程，IBM的教程\n","date":"2016-04-03T13:14:13+08:00","permalink":"https://bg2bkk.github.io/p/googletest-framework%E5%88%9D%E6%AD%A5%E4%B8%8A%E6%89%8B/","title":"googletest framework初步上手"},{"content":"lj-gc  usage:  1  [zhendong@D13124441 stapxx]$ sudo ./stap++ ./samples/lj-gc.sxx -x 43376    error:  1 2 3 4 5 6 7  Found exact match for libluajit: /usr/local/lib/libluajit-5.1.so.2.1.0 WARNING: cannot find module /usr/local/lib/libluajit-5.1.so.2.1.0 debuginfo: No DWARF information found [man warning::debuginfo] semantic error: type definition \u0026#39;lua_State\u0026#39; not found in \u0026#39;/usr/local/lib/libluajit-5.1.so.2.1.0\u0026#39;: operator \u0026#39;@cast\u0026#39; at stapxx-QIH_WYIt/luajit.stp:162:12 source: return @cast(L, \u0026#34;lua_State\u0026#34;, \u0026#34;/usr/local/lib/libluajit-5.1.so.2.1.0\u0026#34;)-\u0026gt;glref-\u0026gt;ptr32 ^ Pass 2: analysis failed. [man error::pass2]     reason:\nlibluajit-5.1没有dwarf信息，需要重新编译\n  resolve:\n  1 2  make CCDEBUG=\u0026#34;-g -O0 -gdwarf-2\u0026#34; -j # -gdwarf-2将会保持DWARF参数   elf一般由多个节(section)组成，不熟悉的可以看关于elf文件格式的文章。调试信息被包含在某几个节中，如果是用dwarf2格式编译的，这些节的名字一般是以.debug开头，如.debug_info，.debug_line，.debug_frame等，如果是用dwarf1格式编译的，这些节的名字一般是.debug，.line等。现在的编译器默认大多数是dwarf2格式编译，当然可以通过gcc的编译选项改变。\n1 2 3 4 5 6 7 8 9  # 查看elf文件的各段头部 readelf -S elffile # 查看elf文件的.debug_info段，关键在于info的i，所以采用 -wi参数 readelf -wi src/libluajit.so # 查看elf文件的.debug_line段，关键在于info的l，所以采用 -wl参数 readelf -wl src/libluajit.so   对于LuaJIT来说，-O0和-O2(默认)对于DWARF信息来说没有区别，因为dwarf信息是调试信息。而-gdwarf-2和-g的差别在于，前者能够保留更详细一步的信息(对于.dubeg_info段而言)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  #output by -gdwarf-2 \u0026lt;2\u0026gt;\u0026lt;134\u0026gt;: Abbrev Number: 8 (DW_TAG_member) \u0026lt;135\u0026gt; DW_AT_name : env\t\u0026lt;139\u0026gt; DW_AT_decl_file : 2\t\u0026lt;13a\u0026gt; DW_AT_decl_line : 661\t\u0026lt;13c\u0026gt; DW_AT_type : \u0026lt;0x3b9\u0026gt;\t\u0026lt;140\u0026gt; DW_AT_data_member_location: 2 byte block: 23 2c (DW_OP_plus_uconst: 44) #output by -g \u0026lt;2\u0026gt;\u0026lt;11c\u0026gt;: Abbrev Number: 8 (DW_TAG_member) \u0026lt;11d\u0026gt; DW_AT_name : env\t\u0026lt;121\u0026gt; DW_AT_decl_file : 2\t\u0026lt;122\u0026gt; DW_AT_decl_line : 661\t\u0026lt;124\u0026gt; DW_AT_type : \u0026lt;0x37e\u0026gt;\t\u0026lt;128\u0026gt; DW_AT_data_member_location: 44\t   correct result  1 2 3 4 5  [zhendong@D13124441 stapxx]$ sudo ./stap++ ./samples/lj-gc.sxx -x 13337 Found exact match for libluajit: /usr/local/lib/libluajit-5.1.so.2.1.0 Start tracing 13337 (/usr/local/nginx/sbin/nginx) Total GC count: 128828 bytes    extrainfo  在压测时，采用-c10000的压力，发现压力较大时报错\n1 2 3 4 5 6 7 8  [zhendong@D13124441 stapxx]$ sudo ./stap++ ./samples/lj-gc.sxx -x 13337 Found exact match for libluajit: /usr/local/lib/libluajit-5.1.so.2.1.0 ERROR: read fault [man error::fault] at 0x000000000077d8e8 (addr) near operator \u0026#39;@var\u0026#39; at stapxx-j8srK_I0/nginx.config.stp:7:80 Start tracing 13337 (/usr/local/nginx/sbin/nginx) WARNING: Number of errors: 1, skipped probes: 0 WARNING: /usr/bin/staprun exited with status: 1 Pass 5: run failed. [man error::pass5]   重启解决，很无奈\nngx-lua-shdict-info  采用openresty才能正常使用也是够了  [zhendong@D13124441 stapxx]$ sudo ./stap++ ./samples/ngx-lua-shdict-info.sxx -x 5545 \u0026ndash;arg dict=kv_api_root_upstream Start tracing 5545 (/data1/zhendong/openresty-1.9.7.4/build/nginx-1.9.7/objs/nginx) shm zone \u0026ldquo;api_root_sysConfig\u0026rdquo; shm zone \u0026ldquo;kv_api_root_upstream\u0026rdquo; shm zone \u0026ldquo;kv_api_root_upstream\u0026rdquo; owner: ngx_http_lua_shdict total size: 102400 KB free pages: 96392 KB (24098 pages, 29 blocks) rbtree black height: 10\n","date":"2016-04-01T18:38:31+08:00","permalink":"https://bg2bkk.github.io/p/stapxx%E4%BD%BF%E7%94%A8%E8%BF%87%E7%A8%8B/","title":"stapxx使用过程"},{"content":"github: https://github.com/ivandavidov/minimal blog: http://minimal.linux-bg.org/\nsudo apt-get install isolinux sudo apt-get install syslinux syslinux-common syslinux-efi syslinux-utils sudo apt-get install syslinux-themes-ubuntu-xenial\n7gen iso img时报找不到 isolinux.bin错误，需要事先copy到这里 sudo cp /usr/share/syslinux/themes/ubuntu-xenial/isolinux-live/isolinux.bin /usr/lib/syslinux/isolinux.bin\nsh ./qemu64.sh时，报can\u0026rsquo;t load ldlinux.c32, 首先将ldlinux.c32copy到该目录下\nsudo cp /usr/share/syslinux/themes/ubuntu-xenial/isolinux-live/ldlinux.c32 /usr/lib/syslinux/\n修改kernel的 arch/x86/boot/Makefile 将如下信息\n1 2 3  if [ -f /usr/$$i/syslinux/ldlinux.c32 ] ; then \\  cp /usr/$$i/syslinux/ldlinux.c32 $(obj)/isoimage ; \\  fi ; \\   写在\n1 2  if [ -f /usr/$$i/syslinux/isolinux.bin ] ; then \\  cp /usr/$$i/syslinux/isolinux.bin $(obj)/isoimage ; \\   之后\n在\n1  break ; \\   之后\nhttp://www.ruanyifeng.com/blog/2009/10/5_ways_to_search_for_files_using_the_terminal.html\n另外一个版本和方法\nhttp://mgalgs.github.io/2015/05/16/how-to-build-a-custom-linux-kernel-for-qemu-2015-edition.html\nhttps://github.com/SunliyMonkey/tiny_linux\n","date":"2016-03-30T15:13:13+08:00","permalink":"https://bg2bkk.github.io/p/minimal-linux-distro%E5%88%B6%E4%BD%9C%E8%BF%87%E7%A8%8B/","title":"minimal linux distro制作过程"},{"content":"   python crawler   http://aosabook.org/en/index.html done scrapy: xpath scrapy: login and cookie    xv6 lecture and homework   cs635 http://cs.usfca.edu/~cruse/cs635/ http://www.cs.usfca.edu/~cruse/    2.1. 6.824 mit\n  2.2 computer operating system\n  Programming In Lua. en version. edition 3   coroutine and goroutine  协程      compile linux kernel and boot from qemu   busybox buildroot    4.1. linux mm\n linux device driver    build a image file for rpi and boot    Bluetooth low energy of Android   development adnroid develop stm32 with st-link stm32 with sb on linux stm32 qemu-system-arm stm32 Makefile stm32 Hal    ngx_lua waf   kong    彻底用明白git    nginx的upstream模块，以及nginx plus的dynamic upstream模块的实现   upstream init upstream [ip_hash] [consistent hash] [least_conn] nginx源码    leetcode    编程之美——编程珠玑——算法——算法导论    简历以及准备面试    设计模式    HTTP/ TCP/ RFC    ","date":"2016-03-28T14:43:15+08:00","permalink":"https://bg2bkk.github.io/p/todo-list/","title":"TODO List"},{"content":" 1、想用nginx-gdb-utils来监控ngx_lua的内存使用情况 2、在CentOS 6.5上，gdb为7.2，python为2.6，没有一个符合的，想强上，没上了，只能在7上搞 3、CentSO 7的gdb是7.6，版本也很老，对于nginx-gdb-utils来说。python倒是2.7，可以搞 4、gdb需要编译安装，首先下载gdb-7.11  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  cd gdb-7.11 ./configure --with-python=python2.7 报错，报python2.7找不到，换成 ./configure --with-python=/usr/bin/python2.7 依然报错 很奇怪，难道不是要python2.7吗，怎么报找不到。 后来才知道，需要python，要的不是python2.7的可执行文件，而是python的库文件等待 sudo yum install python2.7-devel make -j24 --with-python 注意我这里不用写--with-python=blahblah了 终于不报错了 make -C gdb install 报错，报没有makeinfo的错误，经查，makeinfo是texinfo的一部分，用来生成说明文档的，因为它而不能安装，蛋疼 sudo yum install texinfo make -C gdb install 安装在/usr/local/bin/gdb    5、将nginx-gdb-utils写入gdb初始化文件中，这样以后就不用每次加载py文件了  1 2 3 4 5 6 7 8 9 10 11 12  vim ~/.gdbinit directory /path/to/nginx-gdb-utils py import sys py sys.path.append(\u0026#34;/path/to/nginx-gdb-utils\u0026#34;) source luajit20.gdb source ngx-lua.gdb source luajit21.py source ngx-raw-req.py set python print-stack full   但其实一般而言我们都是用root用户的，所以在sudo或者直接是root用户下时，需要重新写~/.gdbinit，这时应该是在/root/.gdbinit了\n  6、/usr/local/bin/gdb -p 12345\n  7、lgcstat\n  发现报一些函数或者变量找不到，比如Lgref找不到，这个原因是相关软件没有把用 -g 选项把符号编译进去\n 8、对于LuaJit而言，make CCDEBUG=-g -B -j8 9、对于lua-cjson而言，make CCDEBUG=-g -B -j8 10、对于tengine、nginx或者openresty而言，CFLAGS=\u0026quot;-g -O2\u0026quot; ./configure  11、自此就可以愉快的玩耍了。这些工具还是很有意思的。  ","date":"2016-03-25T20:16:51+08:00","permalink":"https://bg2bkk.github.io/p/nginx-gdb-utils%E7%9A%84%E7%BC%96%E8%AF%91-%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/","title":"nginx gdb utils的编译 安装和使用"},{"content":"EPOLL在linux 内核中的新发展 Epoll是linux专有的系统调用，用于快速地高效轮询大规模文件描述符fd。这个API在kernel-2.5版本时就已经合并，并使用至今。即使如此，epoll和其他接口一样，仍然有提升空间。现在有两个patch为epoll系列系统调用添加了新的功能。\nepoll概述 epoll的功能与select或者poll类似，但是epoll在应对轮询处理大规模文件描述符时拥有更灵活的选项和更高的性能。每次调用select和poll，都会将被轮询的fd集合复制，生成新的fd集合，所以内核需要检查每一个描述符是否合法，是否IO就绪，然后将执行监听的进程添加到相应的唤醒等待队列。但实际上，一般情况下，在两次select或者poll调用之间，有事件产生的fd并不多，所以对每个fd都进行前述流程实际上有很多不必要的重复性操作。Epoll将设置被监听fd和轮询fd是否就绪这两个任务分开，从而解决这一问题。\n使用epoll的话，必须首先新建epoll fd用于轮询，新建epfd通过如下调用：\n1 2 3 4  #include \u0026lt;sys/poll.h\u0026gt; int epoll_create(int size); int epoll_create1(int flags);   两者都返回epoll fd，而epoll_create()的size参数已经不再有意义，epoll_create1()的flag参数可以设置epfd的CLOSE_ON_EXEC标志。\n第二步是添加所有被监听的fd，通过调用：\n1  int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event);   参数op是EPOLL_CTL_ADD时，fd将被添加进epfd轮询的fd集合中，event参数用于指定哪个类型的事件被轮询，读事件、写事件或者其他事件，详情参考man page。\n最后，等待集合中fd是否就绪的工作由以下函数实现：\n1 2 3  int epoll_wait(int epfd, struct epoll_event *events, int maxevents, int timeout); int epoll_pwait(int epfd, struct epoll_event *events, int maxevents, int timeout, const sigset_t *sigmask);   有事件发生时，epoll_wait将返回，产生的时间存在参数events中，最多maxevents个事件。如果timeout时间内没有事件发生，epoll_wait也将返回，timeout的单位是ms。epoll_pwait可以使用信号集sigmask来屏蔽特定信号，可以使应用程序安全的等待fd就绪或者捕获信号。二者的关系和select与pselect关系一样。\npatch 1：epoll_ctl_batch() 和 epoll_pwait1() Fam Zheng为epoll引入了两个新的系统调用。\nFam的第一个系统调用是epoll_ctl_batch，用来解决一个性能问题：每次调用epoll_ctl，都只能添加、修改和删除一个fd，如果有大量fd需要修改，那么需要调用相应次数的epoll_ctl来实现，这会导致大量系统调用发生，而这个场景却是经常发生的。Fam引入的epoll_ctl_batch()通过在一个系统调用中添加多个fd来解决这个问题：\n1  int epoll_ctl_batch(int epfd, int flags, int ncmds, struct epoll_ctl_cmd *cmds);   结构体epoll_ctl_cmd用于描述一个待添加的事件，可以看作是epoll_ctl参数的一次打包：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  struct epoll_ctl_cmd { /* Reserved flags for future extension, must be 0. */ int flags; /* The same as epoll_ctl() op parameter. */ int op; /* The same as epoll_ctl() fd parameter. */ int fd; /* The same as the \u0026#34;events\u0026#34; field in struct epoll_event. */ uint32_t events; /* The same as the \u0026#34;data\u0026#34; field in struct epoll_event. */ uint64_t data; /* Output field, will be set to the return code after this * command is executed by kernel */ int result; };   将一个epoll_ctl_cmd数组cmds传入，则epoll_ctl_batch可以在一次系统调用中添加多个fd。\nFam的第二个系统调用是epoll_pwait1\n1 2 3 4 5 6 7 8 9  struct epoll_wait_params{ int clockid; struct timespec timeout; sigset_t *sigmask; size_t sigsetsize; } int epoll_pwait(int epfd, int flags, struct epoll_event *events, int maxevents, struct epoll_wait_params *params);   本版本的epoll_pwait1()添加了一个flags参数，但是并未定义任何flag值，所以flags置为0即可。其他参数，包括时间控制、信号屏蔽设置，都写在params参数中，目的是为应用程序提供更精细的时间控制。对于epoll_wait()来说，毫秒级的时钟分辨率已经被证明在一些场景中过于粗糙，新的系统供调用提供了纳秒级别的精度，解决了这个问题。\npatch2: 多线程环境下更好的性能，解决“惊群”问题 Jason Baron（Akamai公司）主要解决一个相对来说不那么常见的场景下，epoll现有的一个问题。通常情况下，一个给定的fd只被一个进程轮询，但是在Jason的场景中，会有多个进程轮询同一个fd集合。在这个场景设定下，一个fd有事件产生时将会唤醒所有监听进程，即使最后只有一个进程能够得到处理该事件的机会，这就是所谓的“惊群”问题。\nJason的解决方案是通过epoll_ctl向被轮询的fd再添加两个新的flag，第一个是EPOLLEXCLUSIVE，保证只有一个进程能被唤醒然后处理事件。该flag使得，有事件发生时，简单的用add_wait_queue_exclusive()代替add_wait_queue()，互斥的将进程放入等待队列中。很明显，所有轮询同一个fd的进程都要使用互斥模式来实现只有一个进程唤醒的效果。\n不过，这个变化没有完全解决问题，因为这会导致当有事件发生时，唤醒的都是同一个进程。由于Epoll存在的一个原因是，在两次epoll_wait()调用之间,，进程能留在epfd的等待唤醒队列中，处于等待队列头部的进程仍然在队列头部，所以这个进程将被唤醒并处理所有互斥模式的fd（这句翻译我有疑问）。但是我们的目的是，多个进程轮询同一fd集合时，能够散开执行，而每次都唤醒的是同一个进程与此相悖。为解决这个问题，Jason添加了另一个flag，叫做 EPOLLROUNDROBIN，使得内核按顺序处理唤醒每个进程。\n引入一个新的等待队列函数用来支持实现这种方式\n1  void add_wait_queue_rr(wait_queue_head_t *q, wait_queue_t *wait);   使用该函数后，当wait返回时，只有一个进程被唤醒，效果和add_wait_queue_exclusive()一样。但是，这个被唤醒的进程，将被从队列头移到队列尾，直到它前面的所有进程都得到唤醒机会后，才能再次被唤醒。\nJason的提交patch的同时也提交了一个用于压测的程序，压测结果显示，互斥模式使得执行时间降低了50%，当有大量的唤醒发生时，“惊群”效应带来的性能损耗就不会发生了。\n结语 以上提到的两个patch已经被多次review和comments，Fam的patch自从1月份提出后进行了多次修改。现在的编辑们对API相关的patch投入了越来越多的关注和审视，这是对的，因为API将会长期有效，(API lives forever),甚至是永远有效。所以最好在向用户推出之前就搞定所有bug，以提供永久支持的态度提交。这些patch目前看来已经接近就绪，可能将会在下一个窗口中合并。\n","date":"2016-03-22T01:48:41+08:00","permalink":"https://bg2bkk.github.io/p/new-evolvement-of-epoll/","title":"New evolvement of Epoll"},{"content":"curses\nreadline\n","date":"2016-03-22T01:48:07+08:00","permalink":"https://bg2bkk.github.io/p/linux-c-%E7%BB%88%E7%AB%AF%E7%BC%96%E7%A8%8B%E4%B9%8B%E4%BB%A3%E7%A0%81%E8%87%AA%E5%8A%A8%E8%A1%A5%E5%85%A8/","title":"Linux C 终端编程之代码自动补全"},{"content":"  排错，每个location设置cache时需要自己起名\n  local sysConfig = ngx.shared[ngx.var.sysConfig]\n  tcpcopy\n sudo iptables -I OUTPUT -p tcp \u0026ndash;sport 8030 -j QUEUE    ab和dyupsc，与前台的交互\n  设置runtime，无论成功与否，都会清除原系统中的runtime设置\n  列出所有policy\n  runtime_set 时的 policyid 以及 policygroupid\n  policy的upstream 和 dyupsc的upstream 重叠\n  TODO LIST\n 重新排版优化diversion.lua 测试shared dict做策略数据库性能 测试shared tree做策略数据库性能 log级别设置    问题：dump_config模块是不是不能支持least_conn之类的呢\n  ","date":"2016-03-16T09:50:21+08:00","permalink":"https://bg2bkk.github.io/p/7%E5%B1%82%E4%B8%8A%E7%BA%BF%E8%BF%87%E7%A8%8B/","title":"7层上线过程"},{"content":"openresty中如何写redis或者mysql的wraper  参考资料  ngx_lua获取post字段参数 在用户请求为POST方式时，如果想获取post中的各参数字段，比如post数据为 \u0026ldquo;uid=100\u0026amp;ip=10.13.112.53\u0026rdquo;，此时想获取该字段的话，可以调用ngx.req.get_post_args函数。按惯例返回table类型，post数据的各字段为table的key\n1 2 3 4 5  function get_uid() local args = ngx.req.get_post_args() local uid = args[\u0026#39;uid\u0026#39;] return uid end   关于HTTP的POST提交数据的方式，网上有很多讨论\n 四种常见的POST提交数据方式  application/x-www-form-urlencoded multipart/form-data application/json text/xml   HTTP header头的一些字段  ngx_lua同样提供了读写HTTP请求中uri参数，读写HTTP请求中的HEADER头部，这些在ngx_lua开发中为我们提供了丰富的工具，非常好的功能。\n最后回到主题，当我读出uid字段后，有时候会发现报错\u0026quot;requesty body in temp file not supported\u0026quot;，原因在于nginx会将用户请求的body字段缓存起来，如果超出缓存大小，则将用户body数据写到文件中；而ngx.req.get_post_args()是不支持从文件中读取数据的。因此解决办法是：适当加大 nginx 的 client_body_buffer_size 配置, 当 client_body_buffer_size 配置为和 client_max_body_size 一样大时，nginx就不会把请求体缓冲到文件系统了（但也要仔细内存占用）。\n对于client_max_body_size来说，\n1 2 3 4 5  Syntax:\tclient_max_body_size size; Default:\tclient_max_body_size 1m; Context:\thttp, server, location Sets the maximum allowed size of the client request body, specified in the “Content-Length” request header field. If the size in a request exceeds the configured value, the 413 (Request Entity Too Large) error is returned to the client. Please be aware that browsers cannot correctly display this error. Setting size to 0 disables checking of client request body size.   设置允许的client body最大值，对http server来说是种保护。\n对于client_body_buffer_size来说，\n1 2 3 4 5  Syntax:\tclient_body_buffer_size size; Default:\tclient_body_buffer_size 8k|16k; Context:\thttp, server, location Sets buffer size for reading client request body. In case the request body is larger than the buffer, the whole body or only its part is written to a temporary file. By default, buffer size is equal to two memory pages. This is 8K on x86, other 32-bit platforms, and x86-64. It is usually 16K on other 64-bit platforms.   如果client body size大于默认值，则nginx将会把body缓存在文件中。将client body buffer size设置为和client_max_body_size一样大，nginx将不会把它写进文件中。\nngx_lua中判断table为空  lua的table中，有两类kv，一类是以数字为index，比如{\u0026lsquo;abc\u0026rsquo;, \u0026lsquo;efg\u0026rsquo;}中，{k=1, v=abc}, {k=2, v=efg}，另一类以自己kv存储，比如{[\u0026lsquo;abc\u0026rsquo;] = \u0026lsquo;efg\u0026rsquo;}，k为abc的元素，v为efg #table中，#标识符是返回以数字为index的key，从1开始算，连续的key的数量  1 2 3 4 5 6 7  local t = {} t[1] = \u0026#39;a\u0026#39; t[2] = \u0026#39;b\u0026#39; t[20] = \u0026#39;c\u0026#39; print(#t) 2    因此#号不能获得table的真实大小，也不能用于判断table是否为空 table.maxn(tab)，maxn返回table中以数字为key的元素中，数字最大的那个  1 2 3 4 5 6 7  local t = {} t[1] = \u0026#39;a\u0026#39; t[2] = \u0026#39;b\u0026#39; t[20] = \u0026#39;c\u0026#39; print(table.maxn(t)) 20     next就是pairs遍历table时用来取下一个内容的函数，因此next(tab)可以用来判断table是否为空，如果next(tab)返回为nil的话，说明第一个元素不存在，所以该table为空\n  参考链接\n  ngx_lua中的参数获得 ngx_lua中获得req参数有如下几个方法：\n  ngx.var.arg_city 获取city参数\n host:port/uri?city=abc ngx.var.arg_city = abc host:port/uri?city= ngx.var.arg_city = \u0026lsquo;', and its length is 0 host:port/uri?city ngx.var.arg_city = nil，cause it doesn\u0026rsquo;t exist yet    ngx.req.get_headers()[\u0026lsquo;city\u0026rsquo;]，获取http请求头中的city参数\n host:port/uri -H \u0026lsquo;city:abc\u0026rsquo; 结果为abc host:port/uri -H \u0026lsquo;city:\u0026rsquo; 结果为nil      thread\n 虽然init_worker_by_lua阶段不能使用cosocket，不过可以先通过一个timer（定时时间为0让其立即调用）来发出对外的socket io操作，以实现一些初始化的目的。 openresty的两个缓存中，ngx shared dict是跨worker共享的，是一个单纯的kv缓存；预计接下来会有patch能够支持lpush等redis操作；lua-resty-lrucache是每个worker的Lua VM空间内缓存，不能跨worker共享，优点是可以存储所有lua对象，比如table，而不需要序列化和反序列化    worker 启动时，upstream 是空的，即 _M.data={}，所以这个时候是不能提供服务的。所以每次 reload config 都会导致一段时间内服务不可访问。\n 在 init_worker_by_lua 执行 cosocket 相关的 API 是不允许的（后期可能会添加支持），但可以调用标准 SOCKET 完成初始化加载，例如借助 luasocket 完成数据源获取并初始化 _M 。    不清楚 init_worker_by_lua 里是否可以进行文件操作？\n 是可以的，这个确定。    在ngx lua性能分析方面，agentzh提出一系列的工具，主要是nginx-systemtap-toolkit和stapxx两个工程。我们使用的脚本，说明文档\n  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  引用： 我们有一整套的基于 systemtap 的工具链可以用于在线或者离线的性能分析。 你的 nginx 进程的 CPU 使用率如果很高的话，可以使用 C 级别的 on-CPU 时间火焰图工具对你最忙的 nginx worker 进程进行采样： https://github.com/agentzh/nginx-systemtap-toolkit#sample-bt 如果你的 nginx 进程的 CPU 很低，但请求延时很高，则有两种可能： 1. 你的 nginx 阻塞在了某些阻塞的 IO 操作（比如文件 IO）或者系统的同步锁上，此时你可以使用 C 级别的 off-CPU 时间火焰图工具对某个典型的 nginx worker 进程进行采样： https://github.com/agentzh/nginx-systemtap-toolkit#sample-bt-off-cpu 如果你发现 Lua 代码占用了大部分的 CPU 时间，则可以进一步使用 ngx-lua-exec-time 工具加以确认： https://github.com/agentzh/stapxx#ngx-lua-exec-time 进一步地，你可以使用 Lua 代码级别的 on-CPU 火焰图工具在 Lua 层面上分析 CPU 时间的分布。如果你使用的是 LuaJIT 2.0.x，则可以使用下面这个工具进行采样： https://github.com/agentzh/nginx-systemtap-toolkit#ngx-sample-lua-bt 如果你使用的是 LuaJIT 2.1，则可以使用 lj-lua-stacks 工具进行采样： https://github.com/agentzh/stapxx#lj-lua-stacks 2. 你的 nginx 通过 ngx_lua 的 cosocket 或者 ngx_proxy 这样的 upstream 模块和上游服务进行通信时，上游服务的延时过大。此时你可以分别使用 ngx-lua-tcp-recv-time、ngx-lua-udp-recv-time 以及 ngx-single-req-latency 工具进行分析： https://github.com/agentzh/stapxx#ngx-lua-tcp-recv-time https://github.com/agentzh/stapxx#ngx-lua-udp-recv-time https://github.com/agentzh/stapxx#ngx-single-req-latency - 我们主要使用四个工具来生成火焰图以分析性能，sample-bt、sample-bt-off-cpu、ngx-sample-lua-bt 和 lj-lua-stacks。 - 实际使用中命令：   1 2 3 4  1、sudo ./sample-bt -p 8736 -t 20 -u -a \u0026#39;-DMAXSKIPPED=10000\u0026#39; \u0026gt; a.bt 2、sudo ./sample-bt-off-cpu -p 8736 -t 20 -u \u0026gt; b.bt 3、sudo ./ngx-sample-lua-bt --luajit20 -p 44252 -t 20 \u0026gt; c.bt 4、sudo ./samples/lj-lua-stacks.sxx --skip-badvars -x 44250 -I tapset/ \u0026gt; d.bt   - 通过a.bt生成火焰图  1  ../FlameGraph/stackcollapse-stap.pl a.bt | ../FlameGraph/flamegraph.pl \u0026gt; a.svg   - 通过脚本ngx-lua-conn-pools来追踪ngx lua connection pool的工作情况。\t 1  sudo ./ngx-lua-conn-pools --luajit20 -p 28261   ","date":"2016-03-14T16:36:14+08:00","permalink":"https://bg2bkk.github.io/p/openresty%E5%AD%A6%E4%B9%A0%E8%BF%87%E7%A8%8B%E4%B8%AD%E7%9A%84%E4%B8%80%E4%BA%9Btips/","title":"openresty学习过程中的一些tips"},{"content":"协程是什么？ what is coroutine ?  协程的概念   Coroutines are computer program components that generalize subroutines for nonpreemptive multitasking, by allowing multiple entry points for suspending and resuming execution at certain locations. Coroutines are well-suited for implementing more familiar program components such as cooperative tasks, exceptions, event loop, iterators, infinite lists and pipes.\n  According to Donald Knuth, the term coroutine was coined by Melvin Conway in 1958, after he applied it to construction of an assembly program.[1] The first published explanation of the coroutine appeared later, in 1963.[2]\n 协程是为实现非抢占式多任务而提出的计算机子程序，通过提供多个程序入口使得程序可以在特定地址挂起和恢复执行。协程天生的支持实现常见程序组件，比如协作式任务、异常、时间循环、迭代器、无边界列表和管道等。\n根据祖师爷高纳德节说，协程的概念由Melvin Conway在1958年提出，随后他将协程应用在编写汇编程序上。协程的第一个公开发表的解释出现在1963年。\n可见协程的概念比多线程还早，而且按照Knuth的说法，”子例程是协程的特例“，一次子例程调用就是一次子函数调用，协程是类函数一样的组件，我们可以在单线程中创建N多个协程，只要内存够用。\n* 协程与子例程的[区别](https://en.wikipedia.org/wiki/Coroutine) * 子例程只有一个调用入口起点，子例程退出后，执行结束；子例程只返回一次，在两次调用之间不保存状态； * 协程有多个入口，调用起始点、或者从上一次返回点接着执行；从协程自己的角度来看，他放弃执行时不是退出，而是去调用另一个协程，或者说将CPU主动让给另一个协程；协程保存状态; * 计算机科学中，[yield](https://en.wikipedia.org/wiki/Yield_(multithreading))用于使处理器放弃当前运行的线程thread，并将它放入运行队列的末尾 * 协程coroutine中的yield需要显式调用 * 每个子例程可以转换为一个不带yield的协程  协程有关的四个概念：coroutine、[yield](https://en.wikipedia.org/wiki/Yield_(multithreading)、Continuation、cooperative multitasking。以及其他相关概念：call stack\n Coroutines in C  给你一个直观的认识    1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  #include \u0026lt;stdio.h\u0026gt;#include \u0026lt;stdlib.h\u0026gt;int function(void) { static int i, state = 0; switch (state) { case 0: goto LABEL0; case 1: goto LABEL1; } LABEL0: /* start of function */ for (i = 0; i \u0026lt; 10; i++) { printf(\u0026#34;\\t\\t\\ti = %d\\n\u0026#34;, i); state = 1; /* so we will come back to LABEL1 */ return i; LABEL1: ; /* resume control straight after the return */ } } int main(){ int j = 0; for ( j = 0; j \u0026lt; 21; j++){ printf(\u0026#34;j = %d, func = %d\\n\u0026#34;, j, function()); } }   执行结果\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  i = 0 j = 0, func = 0 i = 1 j = 1, func = 1 i = 2 j = 2, func = 2 i = 3 j = 3, func = 3 i = 4 j = 4, func = 4 i = 5 j = 5, func = 5 i = 6 j = 6, func = 6 i = 7 j = 7, func = 7 i = 8 j = 8, func = 8 i = 9 j = 9, func = 9 j = 10, func = 10 j = 11, func = 11 j = 12, func = 12 j = 13, func = 13 j = 14, func = 14 j = 15, func = 15 j = 16, func = 16 j = 17, func = 17 j = 18, func = 18 j = 19, func = 19 j = 20, func = 20     执行结果分析\n 变量i 和 state 都是 static类型的，是文件全局作用域的 首次执行function函数时，state = 0，goto 到 LABEL0，然后进行正常循环和返回 当function调用次数超过十次后，每次进入function函数内部时，由switch分发到LABEL1；执行完循环体后，对i增1，然后进行判断是否 i \u0026lt; 10，发现不满足，退出程序 可能我们会比较纠结function程序在 i \u0026gt; 10后不再执行return i语句，为什么还会返回自增后的结果呢？  从代码的汇编结果来看，每次function返回时，i都在之前赋值给寄存器eax了，而eax存储的是函数的返回值，所以每次function的返回结果是i，即使不执行return语句   return在这里并不是返回的意思，而是yield的意思    仍然有两种更优化的写法: 左耳朵耗子的例子和上例的来源都是天才程序员 imon Tatham对协程做的尝试，以及关于swtich-case写法的duff机器的讨论\n  理解协程实现的基础就是程序中的函数调用导致的栈帧切换，在切换前先保存被切换subroutine的上下文，在切换时用新subroutine替换当前程序的执行状态。以Linux中用于实现协程的一个api：ucontext来说，makecontext函数将context的eip设置为func参数的地址，所以当该context得以执行时，func函数就开始执行了；swapcontext(old, new)将当前程序处于的old状态切换到new状态，然后new状态的func就得以执行。\n  Linux对于协程实现提供了setjmp/longjmp和ucontext两种机制，现有的协程库，比如protothread，甚至是LuaVM中的协程实现，也会基于这两种机制之一来实现。当然，您也可以手动切换cpu的所有寄存器状态，以实现协程，也是可以的，但是是极不推荐的。\n  setjump \u0026amp; longjmp man longjmp 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  NAME longjmp, siglongjmp - nonlocal jump to a saved stack context SYNOPSIS #include \u0026lt;setjmp.h\u0026gt; void longjmp(jmp_buf env, int val); void siglongjmp(sigjmp_buf env, int val); DESCRIPTION longjmp() and setjmp(3) are useful for dealing with errors and interrupts encountered in a low-level subroutine of a program. longjmp和setjmp在处理程序调用子例程过程中遇到错误或中断时非常有用。 longjmp() restores the environment saved by the last call of setjmp(3) with the corresponding env argument. After longjmp() is completed, program execution continues as if the corresponding call of setjmp(3) had just returned the value val. longjmp() cannot cause 0 to be returned. If longjmp() is invoked with a second argument of 0, 1 will be returned instead. longjmp将恢复最近一次调用setjmp时通过env参数保存的上下文环境。longjmp完成后，原来调用setjmp的地方将会返回，并且setjmp的返回值是longjmp的val参数。longjmp不会返回0。如果longjmp调用时第二个参数是0，那么它将会返回1. siglongjmp() is similar to longjmp() except for the type of its env argument. If, and only if, the sigsetjmp(3) call that set this env used a nonzero savesigs flag, siglongjmp() also restores the signal mask that was saved by sigsetjmp(3). RETURN VALUE These functions never return.   man setjmp 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  NAME setjmp, sigsetjmp - save stack context for nonlocal goto SYNOPSIS #include \u0026lt;setjmp.h\u0026gt; int setjmp(jmp_buf env); int sigsetjmp(sigjmp_buf env, int savesigs); DESCRIPTION setjmp() and longjmp(3) are useful for dealing with errors and interrupts encountered in a low-level subroutine of a program. setjmp() saves the stack context/environment in env for later use by longjmp(3). The stack context will be invalidated if the function which called setjmp() returns. setjmp() 在参数env中保存栈帧，稍后longjmp调用时，将从setjmp执行； sigsetjmp() is similar to setjmp(). If, and only if, savesigs is nonzero, the process\u0026#39;s current signal mask is saved in env and will be restored if a siglongjmp(3) is later performed with this env. RETURN VALUE setjmp() and sigsetjmp() return 0 if returning directly, and nonzero when returning from longjmp(3) or siglongjmp(3) using the saved context.   示例代码 代码地址 博客评论区\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41  #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;unistd.h\u0026gt;#include \u0026lt;setjmp.h\u0026gt; jmp_buf jmpbuf_th0; jmp_buf jmpbuf_th1; static int cnt1 = 0; static int cnt0 = 0; static void thread_0() { printf(\u0026#34;%s \\n\\n\u0026#34;, __FUNCTION__); sleep(1); longjmp(jmpbuf_th0, cnt0++); } static void thread_1() { printf(\u0026#34;%s \\n\\n\u0026#34;, __FUNCTION__); sleep(1); longjmp(jmpbuf_th1, cnt1++); } int main() { int rc0, rc1 = 0; entry_thread_0: rc0 = setjmp(jmpbuf_th0); printf(\u0026#34;rc0 = %d\\n\u0026#34;, rc0); if (rc0 != 0) thread_1(); entry_thread_1: rc1 = setjmp(jmpbuf_th1); printf(\u0026#34;rc1 = %d\\n\u0026#34;, rc1); thread_0(); return 0; }   执行结果\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  rc0 = 0 rc1 = 0 thread_0 rc0 = 1 thread_1 rc1 = 1 thread_0 rc0 = 1 thread_1 rc1 = 1 thread_0 rc0 = 2 thread_1 rc1 = 2 thread_0 rc0 = 3 thread_1 rc1 = 3 thread_0     执行过程分析\n setjmp和longjmp都是基于程序空间中额外的jmpbuf setjmp将当前环境存储在jmpbuf中，longjmp到同一个jmpbuf时，setjmp将会再次返回，返回值是longjmp的第二个参数val 如果setjmp不是因为longjmp返回的，返回值为0 不知道为什么执行结果中，自增的cnt0和cnt1在值为1的时候停顿了一次？    setjump \u0026amp; longjmp 进阶实现\n  setjump \u0026amp; longjmp 进阶实现\n  ucontext man getcontext 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  In a System V-like environment, one has the two types mcontext_t and ucontext_t defined in \u0026lt;ucontext.h\u0026gt; and the four functions getcontext(), setcontext(), makecontext(3), and swapcontext(3) that allow user-level context switching between multiple threads of control within a process. The mcontext_t type is machine-dependent and opaque. The ucontext_t type is a structure that has at least the following fields: typedef struct ucontext { struct ucontext *uc_link; sigset_t uc_sigmask; stack_t uc_stack; mcontext_t uc_mcontext; ... } ucontext_t; with sigset_t and stack_t defined in \u0026lt;signal.h\u0026gt;. Here uc_link points to the context that will be resumed when the current context terminates (in case the current context was created using makecon‐ text(3)), uc_sigmask is the set of signals blocked in this context (see sigprocmask(2)), uc_stack is the stack used by this context (see sigaltstack(2)), and uc_mcontext is the machine-specific rep‐ resentation of the saved context, that includes the calling thread\u0026#39;s machine registers. The function getcontext() initializes the structure pointed at by ucp to the currently active context. The function setcontext() restores the user context pointed at by ucp. A successful call does not return. The context should have been obtained by a call of getcontext(), or makecontext(3), or passed as third argument to a signal handler. If the context was obtained by a call of getcontext(), program execution continues as if this call just returned. If the context was obtained by a call of makecontext(3), program execution continues by a call to the function func specified as the second argument of that call to makecontext(3). When the function func returns, we continue with the uc_link member of the structure ucp specified as the first argument of that call to makecontext(3). When this member is NULL, the thread exits. If the context was obtained by a call to a signal handler, then old standard text says that \u0026#34;program execution continues with the program instruction following the instruction interrupted by the sig‐ nal\u0026#34;. However, this sentence was removed in SUSv2, and the present verdict is \u0026#34;the result is unspecified\u0026#34;.   man makecontext 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  In a System V-like environment, one has the type ucontext_t defined in \u0026lt;ucontext.h\u0026gt; and the four functions getcontext(3), setcontext(3), makecontext() and swapcontext() that allow user-level context switching between multiple threads of control within a process. 在类System V环境下，结构体ucontext_t和四个函数 getcontext、setcontext、makecontext和swapcontext提供了在一个进程内通过用户级上下文切换的方式实现多线程的方式 For the type and the first two functions, see getcontext(3). The makecontext() function modifies the context pointed to by ucp (which was obtained from a call to getcontext(3)). Before invoking makecontext(), the caller must allocate a new stack for this context and assign its address to ucp-\u0026gt;uc_stack, and define a successor context and assign its address to ucp-\u0026gt;uc_link. makecontext函数将修改ucp指向的 ucontext_t（必须是从getcontext获得的对象），在调用makecontext前，调用者必须为改上下文分配一个新的栈，并将ucp-\u0026gt;uc_stack指向栈的地址，同时将ucp-\u0026gt;uc_link指向下一个context When this context is later activated (using setcontext(3) or swapcontext()) the function func is called, and passed the series of integer (int) arguments that follow argc; the caller must specify the number of these arguments in argc. When this function returns, the successor context is activated. If the successor context pointer is NULL, the thread exits. 当该context稍后被激活(通过setcontext或者swapcontext)，makecontext函数参数中的func将被调用，同时向func传递argc个参数。当func返回时，下一个context将被激活调用。如果下一个context是null的话，该线程结束。 The swapcontext() function saves the current context in the structure pointed to by oucp, and then activates the context pointed to by ucp. swapcontext函数将当前context保存在oucp结构体，同时激活ucp指向的context。   man page 中的例子 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61  #include \u0026lt;ucontext.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; static ucontext_t uctx_main, uctx_func1, uctx_func2; #define handle_error(msg) \\ do { perror(msg); exit(EXIT_FAILURE); } while (0) static void func1(void) { printf(\u0026#34;func1: started\\n\u0026#34;); printf(\u0026#34;func1: swapcontext(\u0026amp;uctx_func1, \u0026amp;uctx_func2)\\n\u0026#34;); if (swapcontext(\u0026amp;uctx_func1, \u0026amp;uctx_func2) == -1) handle_error(\u0026#34;swapcontext\u0026#34;); printf(\u0026#34;func1: returning\\n\u0026#34;); } static void func2(void) { printf(\u0026#34;func2: started\\n\u0026#34;); printf(\u0026#34;func2: swapcontext(\u0026amp;uctx_func2, \u0026amp;uctx_func1)\\n\u0026#34;); if (swapcontext(\u0026amp;uctx_func2, \u0026amp;uctx_func1) == -1) handle_error(\u0026#34;swapcontext\u0026#34;); printf(\u0026#34;func2: returning\\n\u0026#34;); } int main(int argc, char *argv[]) { char func1_stack[16384]; char func2_stack[16384]; if (getcontext(\u0026amp;uctx_func1) == -1) handle_error(\u0026#34;getcontext\u0026#34;); uctx_func1.uc_stack.ss_sp = func1_stack; uctx_func1.uc_stack.ss_size = sizeof(func1_stack); uctx_func1.uc_link = \u0026amp;uctx_main; makecontext(\u0026amp;uctx_func1, func1, 0); if (getcontext(\u0026amp;uctx_func2) == -1) handle_error(\u0026#34;getcontext\u0026#34;); uctx_func2.uc_stack.ss_sp = func2_stack; uctx_func2.uc_stack.ss_size = sizeof(func2_stack); /* Successor context is f1(), unless argc \u0026gt; 1 */ uctx_func2.uc_link = (argc \u0026gt; 1) ? NULL : \u0026amp;uctx_func1; makecontext(\u0026amp;uctx_func2, func2, 0); printf(\u0026#34;main: swapcontext(\u0026amp;uctx_main, \u0026amp;uctx_func2)\\n\u0026#34;); if (swapcontext(\u0026amp;uctx_main, \u0026amp;uctx_func2) == -1) handle_error(\u0026#34;swapcontext\u0026#34;); printf(\u0026#34;main: exiting\\n\u0026#34;); exit(EXIT_SUCCESS); } // http://stackoverflow.com/questions/20778735/is-the-type-stack-t-no-longer-defined-on-linux   执行结果：\n1 2 3 4 5 6 7 8 9 10 11  $ gcc context.c -o context.o $ ./context.o main: swapcontext(\u0026amp;uctx_main, \u0026amp;uctx_func2) func2: started func2: swapcontext(\u0026amp;uctx_func2, \u0026amp;uctx_func1) func1: started func1: swapcontext(\u0026amp;uctx_func1, \u0026amp;uctx_func2) func2: returning func1: returning main: exiting   通过manpage中提供的ucontext_t源码，结合man page中的解释，我们对此做一分析。\n 执行过程详解  getcontext(\u0026amp;uctx_func2) 用当前上下文初始化ucontext_t结构体对象：uctx_func2 在调用makecontext前，调用者为该上下文分配一个新的栈，并将成员uc_stack指向栈的地址，同时将uc_link指向下一个context。此时argc为0，所以uctx_func2的uc_link指向uctx_func1，也就是说当uctx_func2执行完后，会自动激活uctx_func1执行 makecontext(\u0026amp;uctx_func2, func2, 0) 函数设置当uctx_func2激活时，调用func2函数，参数为0个；当func2返回时，下一个context将被激活，在这里是uctx_func1 swapcontext(\u0026amp;uctx_main, \u0026amp;uctx_func2) 函数将进程当前执行的上下文保存在uctx_main中，并激活uctx_func2；uctx_func2开始执行，首先被执行的是func2函数，  func2: started func2: swapcontext(\u0026amp;uctx_func2, \u0026amp;uctx_func1)   随后func2函数调用 swapcontext(\u0026amp;uctx_func2, \u0026amp;uctx_func1)，将当前上下文环境保存在uctx_func2中，激活uctx_func1；uctx_func1开始执行，首先执行的是func1，打印出：  func1: started func1: swapcontext(\u0026amp;uctx_func1, \u0026amp;uctx_func2)   随后func1函数调用swapcontext(\u0026amp;uctx_func1, \u0026amp;uctx_func2)，将当前上下文环境保存在uctx_func1中，并激活uctx_func2；上一次uctx_func2保存的上下文环境将被回复，然后进程执行返回到上次被swap_context的点，打印出:  func2: returning   func2函数返回后，uctx_func2也就返回了，下一个context将被激活，也就是uctx_func1；打印出：  func1: returning   uctx_func1也执行结束，而它的下一个context是uctx_main，在main函数中最开始调用swap_context(\u0026amp;uctx_main, \u0026amp;uctx_func2)时，当时程序执行的上下文的地址就是这句，那么在main中继续执行，打印出：  main: exiting      1 2 3 4 5 6 7  $ ./context.o x main: swapcontext(\u0026amp;uctx_main, \u0026amp;uctx_func2) func2: started func2: swapcontext(\u0026amp;uctx_func2, \u0026amp;uctx_func1) func1: started func1: swapcontext(\u0026amp;uctx_func1, \u0026amp;uctx_func2) func2: returning    执行过程详解  当argc个数不为0时，uctx_func2的uc_link为NULL，所以如果uctx_func2结束生命周期，那么整个进程将会退出 在第一次swap_context(\u0026amp;uctx_main, \u0026amp;uctx_func2)时开始调用func2，func2中打印出：  func2: started func2: swapcontext(\u0026amp;uctx_func2, \u0026amp;uctx_func1)   随后swap执行uctx_func1，打印：  func1: started func1: swapcontext(\u0026amp;uctx_func1, \u0026amp;uctx_func2)   随后swap返回uctx_func2，打印：  func2: returning   而func2返回时，由于uctx_func2-\u0026gt;uc_link为NULL，所以整个进程退出，并不会返回到之前保存过的uctx_main执行上下文中。    通过以上分析，您有没有对协程有一个直观的认识呢？本质上，协程调度只是将当前执行的上下文保存起来；调度协程的时候就是将两个执行上下文context切换；指定context的下一个context，在本context执行结束后自动激活下一个context，实现协作；本context执行过程中，通过swap_context主动让出CPU，而不是被抢占放弃CPU。\n 可以参考下进一步的实现，加深下印象：  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54  #include \u0026lt;stdio.h\u0026gt;#include \u0026lt;stdbool.h\u0026gt;#include \u0026lt;ucontext.h\u0026gt; static char stack[2][65536]; // a stack for each coroutine static ucontext_t coroutine_state[2]; // container to remember context  // switch current coroutine (0 -\u0026gt; 1 -\u0026gt; 0 -\u0026gt; 1 ...) static inline void yield_to_next(void) { static int current = 0; int prev = current; int next = 1 - current; current = next; swapcontext(\u0026amp;coroutine_state[prev], \u0026amp;coroutine_state[next]); } static void coroutine(int coroutine_number) { int i; for (i = 0; i \u0026lt; 5; i++) { printf(\u0026#34;Coroutine %d counts i=%d (\u0026amp;i=%p)\\n\u0026#34;, coroutine_number, i, \u0026amp;i); yield_to_next(); } } int main() { ucontext_t return_to_main; // set up  int i; for (i = 0; i \u0026lt; 2; i++) { // initialize ucontext_t  getcontext(\u0026amp;coroutine_state[i]); // set up per-context stack  coroutine_state[i].uc_stack.ss_sp = stack[i]; coroutine_state[i].uc_stack.ss_size = sizeof(stack[i]); // when done, resume \u0026#39;return_to_main\u0026#39; context  coroutine_state[i].uc_link = \u0026amp;return_to_main; // let context[i] perform a call to coroutine(i) when swapped to  makecontext(\u0026amp;coroutine_state[i], (void (*)(void))coroutine, 1, i); } printf(\u0026#34;Starting coroutines...\\n\u0026#34;); swapcontext(\u0026amp;return_to_main, \u0026amp;coroutine_state[0]); printf(\u0026#34;Done.\\n\u0026#34;); return 0; }     another demo\n lib    gnu portable threads\n pt    libtask\n libtask的coroutine    云风的实现\n  其他一些应用\n coroutine-libevent  在libevent里通过协程实现同步      Lua的协程   lua不支持那种真正的多线程（共享同一地址空间的抢占式线程），原因是\n ANSI C没有原生的多线程，所以lua不能直接调用实现 最重要的原因是，我们不认为多线程在lua中是个好主意    多线程是提供给底层编程的。多线程的同步机制，比如信号量和监控都是在操作系统上下文实现的，而非应用程序。调试多线程比较麻烦。而且，由于程序临界区的同步和竞争，多线程也会引起性能下降。\n  多线程引起的问题，主要是抢占式线程和共享内存导致的，lua解决这两个问题的方法是：lua coroutine是协作式的，非抢占式的，所以能避免线程切换导致的问题；lua coroutine之间不共享内存。\n  我见过的最lua的lua代码和博客\n  lua的coroutine and stack\n  lua的c runtime stack和lua runtime stack是什么样子的\n  https://www.zhihu.com/question/21483863\n  lua协程调度\n lua内部  当resume的时候，就切换lua_state环境，然后setjmp，紧接着由于pc指向新地址，所以会直接跳转到该位置 当yield时，直接回复环境，然后longjmp到该resume点   lua with C  当在C函数内入yield时，会恢复环境，longjmp到resume点，之后再次resume的时候，会因为环境被破坏，导致resume出错，此时lua会调用k系列函数，让resume继续下去      lua实现调度器\n  consumer-producer\n  lua yield 和 resume\n http://www.lua.org/manual/5.2/manual.html#pdf-coroutine.resume    1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  -- http://my.oschina.net/wangxuanyihaha/blog/186401 function foo(a) print(\u0026#34;foo\u0026#34;, a) return coroutine.yield(2 * a) end co = coroutine.create(function ( a, b ) print(\u0026#34;co-body\u0026#34;, a, b) local r = foo(a + 1) print(\u0026#34;co-body\u0026#34;, r) local r, s = coroutine.yield(a + b, a - b) print(\u0026#34;co-body\u0026#34;, r, s) return b, \u0026#34;end\u0026#34; end) print(\u0026#34;main\u0026#34;, coroutine.resume(co, 1, 10)) print(\u0026#34;main\u0026#34;, coroutine.resume(co, \u0026#34;m\u0026#34;))\t-- resume的参数 \u0026#39;m\u0026#39; 是在调用yield传入的，所以本次是在第5行 return m print(\u0026#34;main\u0026#34;, coroutine.resume(co, \u0026#34;x\u0026#34;, \u0026#34;y\u0026#34;)) print(\u0026#34;main\u0026#34;, coroutine.resume(co, \u0026#34;x\u0026#34;, \u0026#34;y\u0026#34;))   1 2 3 4 5 6 7 8  co-body\t1\t10 foo\t2 main\ttrue\t4 co-body\tm main\ttrue\t11\t-9 co-body\tx\ty main\ttrue\t10\tend main\tfalse\tcannot resume dead coroutine   python的协程(待续)  http://www.ibm.com/developerworks/cn/opensource/os-cn-python-yield/  简单地讲，yield 的作用就是把一个函数变成一个 generator，带有 yield 的函数不再是一个普通函数，Python 解释器会将其视为一个 generator 产生一个iterable对象    golang的协程(待续)  http://stackoverflow.com/questions/13107958/what-exactly-does-runtime-gosched-do  stm32/ contiki/ coroutine stm32上的协程实现 * http://blog.linux.org.tw/~jserv/archives/001848.html\n","date":"2016-03-13T17:59:29+08:00","permalink":"https://bg2bkk.github.io/p/coroutine-and-goroutine/","title":"coroutine and goroutine"},{"content":"目录  前言 基于openssl自建证书  CentOS Ubuntu   nginx的支持HTTP/2的patch nghttp2安装，配置，使用  nghttpd作为http2 server nghttp作为http2 client nghttpx作为proxy，转向nginx后端 h2load作为压测工具    前言  在研究HTTP/2协议时，常常和https协议混在一起，而二者之间的关系是怎样的呢？ 现有的http2 server中，nginx基于1.9.*有HTTP/2协议的patch，还有nghttp2 server，已经有人运行在个人博客做前端。  只说实践过程，作为记录。\n关于涉及到的概念等，需要在别的文档中写。\n基于openssl自建证书 在线上配置HTTPS时，需要从权威CA申请证书，在nginx中配置证书crt和私钥key。\n listen 8443 ssl; ssl_certificate /usr/lib/ssl/nginx.crt; ssl_certificate_key /usr/lib/ssl/nginx.key;  而在线下调试时，如果需要配置https，则需要自建和签发证书。 基于openssl自建证书\n在CentOS系统上自建证书 1.自建CA，颁发证书\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50  CA首先需要自建证书，作为颁发证书所用的根证书。CA的openssl配置文件/etc/pki/tls/openssl.cnf： #################################################################### [ ca ] default_ca\t= CA_default\t# The default ca section #################################################################### [ CA_default ] dir\t= /etc/pki/CA\t# Where everything is kept certs\t= $dir/certs\t# Where the issued certs are kept crl_dir\t= $dir/crl\t# Where the issued crl are kept database\t= $dir/index.txt\t# database index file. #unique_subject\t= no\t# Set to \u0026#39;no\u0026#39; to allow creation of # several ctificates with same subject. new_certs_dir\t= $dir/newcerts\t# default place for new certs. certificate\t= $dir/cacert.pem # The CA certificate serial\t= $dir/serial # The current serial number crlnumber\t= $dir/crlnumber\t# the current crl number # must be commented out to leave a V1 CRL crl\t= $dir/crl.pem # The current CRL private_key\t= $dir/private/cakey.pem# The private key RANDFILE\t= $dir/private/.rand\t# private random number file x509_extensions\t= usr_cert\t# The extentions to add to the cert # Comment out the following two lines for the \u0026#34;traditional\u0026#34; # (and highly broken) format. name_opt = ca_default\t# Subject Name options cert_opt = ca_default\t# Certificate field options default_days\t= 365\t# how long to certify for default_crl_days= 30\t# how long before next CRL default_md\t= default\t# use public key default MD preserve\t= no\t# keep passed DN ordering policy\t= policy_match # For the CA policy [ policy_match ] countryName\t= match stateOrProvinceName\t= match organizationName\t= match organizationalUnitName\t= optional commonName\t= supplied emailAddress\t= optional ...   其中我们可以看到根地址在/etc/pki/CA下，且指明了CA证书certificate是该目录下的cacert.pem，私钥在private/cakey.pem中，CA需要匹配countryName、stateOrProvinceName和organizationName，且commonName需要提供，这点比较重要。\n1 2 3 4 5  在/etc/pki/CA下创建初始文件 $ touch serial index.txt $ echo 01 \u0026gt; serial   2.生成根密钥\n1 2  $ cd /etc/pki/CA $ openssl genrsa -out private/cakey.pem 2048   3.生成根证书\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  使用req指令，通过私钥，生成自签证书 $ openssl req -new -x509 -key private/cakey.pem -out cacert.pem You are about to be asked to enter information that will be incorporated into your certificate request. What you are about to enter is what is called a Distinguished Name or a DN. There are quite a few fields but you can leave some blank For some fields there will be a default value, If you enter \u0026#39;.\u0026#39;, the field will be left blank. ----- Country Name (2 letter code) [XX]:CN State or Province Name (full name) []:BeiJing Locality Name (eg, city) [Default City]: Organization Name (eg, company) [Default Company Ltd]: Organizational Unit Name (eg, section) []: Common Name (eg, your name or your server\u0026#39;s hostname) []:root Email Address []:   4.为nginx server生成密钥\n1 2  $ mkdir /data/zhendong/nginx_ssl $ openssl genrsa -out nginx.key 2048   5.为nginx生成 证书签署请求\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  $ openssl req -new -key nginx.key -out nginx.csr You are about to be asked to enter information that will be incorporated into your certificate request. What you are about to enter is what is called a Distinguished Name or a DN. There are quite a few fields but you can leave some blank For some fields there will be a default value, If you enter \u0026#39;.\u0026#39;, the field will be left blank. ----- Country Name (2 letter code) [XX]:CN State or Province Name (full name) []:BeiJing Locality Name (eg, city) [Default City]: Organization Name (eg, company) [Default Company Ltd]: Organizational Unit Name (eg, section) []: Common Name (eg, your name or your server\u0026#39;s hostname) []:localhost Email Address []: Please enter the following \u0026#39;extra\u0026#39; attributes to be sent with your certificate request A challenge password []: An optional company name []: Common Name填成nginx server的server_name用来访问。 在openssl.cnf中需要match的项目，一定要一样。   6.向CA请求证书\n1 2 3 4 5  $ openssl ca -in nginx.csr -out nginx.crt 如果失败，可以尝试以下命令 $ openssl x509 -req -in nginx.csr -CA /etc/pki/CA/cacert.pem -CAkey /etc/pki/CA/private/cakey.pem -CAcreateserial -out nginx.crt   7.配置nginx\n1 2 3  listen 8443 ssl ; ssl_certificate /data1/zhendong/nginx_ssl/nginx.crt; ssl_certificate_key /data1/zhendong/nginx_ssl/nginx.key;   8.通过curl访问\n1 2 3 4 5  $ curl --cacert /etc/pki/CA/cacert.pem https://localhost:8443/ this is abtesting server $ curl --cacert /etc/pki/CA/cacert.pem https://127.0.0.1:8443/ curl: (51) SSL: certificate subject name \u0026#39;localhost\u0026#39; does not match target host name \u0026#39;127.0.0.1\u0026#39;   ###在Ubuntu系统上自建证书\nUbuntu系统与CentOS的不同之处在于软件包管理不同，当克服这部分不同后，就可以执行与CentOS系统一样的操作。\n首先Ubuntu的openssl目录在**/usr/lib/ssl**下，而实际上这是一个软链接。\n1 2 3 4 5 6 7  huang@ThinkPad-X220:/usr/lib/ssl$ ll /usr/lib/ssl/ total 52 drwxr-xr-x 3 root root 4096 8月 27 12:18 ./ drwxr-xr-x 238 root root 40960 8月 26 11:18 ../ lrwxrwxrwx 1 root root 14 2月 4 2015 certs -\u0026gt; /etc/ssl/certs/ drwxr-xr-x 2 root root 4096 7月 8 14:34 misc/ lrwxrwxrwx 1 root root 20 6月 11 23:35 openssl.cnf -\u0026gt; /etc/ssl/openssl.cnf lrwxrwxrwx 1 root root 16 2月 4 2015 private -\u0026gt; /etc/ssl/private/   不管怎样，我们的工作将在**/usr/lib/ssl**进行。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  /usr/lib/ssl/openssl.cnf内容如下： #################################################################### [ ca ] default_ca\t= CA_default\t# The default ca section #################################################################### [ CA_default ] dir\t= ./demoCA\t# Where everything is kept certs\t= $dir/certs\t# Where the issued certs are kept crl_dir\t= $dir/crl\t# Where the issued crl are kept database\t= $dir/index.txt\t# database index file. #unique_subject\t= no\t# Set to \u0026#39;no\u0026#39; to allow creation of # several ctificates with same subject. new_certs_dir\t= $dir/newcerts\t# default place for new certs. certificate\t= $dir/cacert.pem # The CA certificate serial\t= $dir/serial # The current serial number crlnumber\t= $dir/crlnumber\t# the current crl number # must be commented out to leave a V1 CRL crl\t= $dir/crl.pem # The current CRL private_key\t= $dir/private/cakey.pem# The private key RANDFILE\t= $dir/private/.rand\t# private random number file x509_extensions\t= usr_cert\t# The extentions to add to the cert   从配置文件中看到，我们需要在**/usr/lib/ssl下建立demoCA**目录以及其他。\n1 2 3 4  $ cd /usr/lib/ssl $ mkdir demoCA $ mkdir demoCA/newcerts $ mkdir demoCA/private   余下的操作将与在CentOS系统上没有区别。最后执行情况为：\n1 2  $ curl --cacert /usr/lib/ssl/demoCA/cacert.pem https://localhost:8443 this is abtesting server   nginx的支持HTTP/2的patch  nginx目前已正式支持HTTP/2，包括tengine-2.1.2+ 和 openresty\n nginx在8月份的时候从1.9.3版本推出了支持HTTP/2的patch，使用时与标准nginx并无区别。\n1 2 3 4 5  $ cd nginx-1.9.4/ $ patch -p1 \u0026lt; patch.http2-v3_1.9.4.txt $ ./configure --with-http_v2_module --with-http_ssl_module $ make $ make install   支持http2的nginx关键配置为\n1  listen 8443 http2;   只需要在listen后加http2就可以了。目前curl在基于nghttp2提供的HTTP/2库后，可以支持访问http2的server，但是目前没有配置成功，所以对支持http2的nginx进行访问的工作，将在介绍完nghttp2后一并记录。\nnghttp2安装，配置，使用 nghttp2是由tatsuhiro开发的，之前的spdylay也是他开发的，一直走在http2.0的前列。nghttp2包括了HTTP/2.0的库，基于这个库tatsu实现了HTTP/2.0的server、client和压测工具h2load。\n由于nghttp2所依赖的库太新了，目前只在Ubuntu系统成功安装。安装过程：\n1 2 3 4 5  $ autoreconf -i $ automake $ autoconf $ ./configure $ make   其中**./configure**的结果非常重要\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47  Version: 1.2.2-DEV shared 14:8:0 Host type: x86_64-unknown-linux-gnu Install prefix: /usr/local C compiler: gcc CFLAGS: -g -O2 WARNCFLAGS: LDFLAGS: LIBS: CPPFLAGS: C preprocessor: gcc -E C++ compiler: g++ CXXFLAGS: -g -O2 -std=c++11 CXXCPP: g++ -E Library types: Shared=yes, Static=yes Python: Python: /usr/bin/python PYTHON_VERSION: 2.7 pyexecdir: ${exec_prefix}/lib/python2.7/dist-packages Python-dev: yes PYTHON_CPPFLAGS:-I/usr/include/python2.7 PYTHON_LDFLAGS: -L/usr/lib -lpython2.7 Cython: cython Test: CUnit: yes Failmalloc: yes Libs: OpenSSL: yes Libxml2: yes Libev: yes Libevent(SSL): yes Spdylay: yes Jansson: yes Jemalloc: yes Zlib: yes Boost CPPFLAGS: Boost LDFLAGS: Boost::ASIO: Boost::System: Boost::Thread: Features: Applications: yes HPACK tools: yes Libnghttp2_asio:no Examples: yes Python bindings:yes Threading: yes Third-party: yes   编译帮助文档\n1  make html   nghttpd作为http2 server http2-no-tls\nnghttpd -v 8080 -n 24 --no-tls -d ~/workspace/Nginx_ABTesting/utils/html/  http2-with-tls\nnghttpd -v 8080 -n 24 /usr/lib/ssl/nginx.key /usr/lib/ssl/nginx.crt -d ~/workspace/Nginx_ABTesting/utils/html/  关于nghttpd的选项，其实可以与nginx配置做到一一对照的。目前对nghttpd的源码及实现了解的比较少，因其日本人的过于C++代码的风格实在晦涩难懂，所以很少做调优。\nnghttp作为http2 client http2-client-no-tls\nnghttp http://127.0.0.1:8080  http2-client-with-tls\nnghttp --cert /usr/lib/ssl/demoCA/cacert.pem https://127.0.0.1:8080 nghttp https://127.0.0.1:8080  经过使用，nghttp也可以对nginx发出http2请求并成功返回。\n通过strace和阅读源码，nghttp（包括压测工具h2load）作为client时，会读取系统的证书/usr/lib/ssl/demoCA/cacert.pem，因此可以不用指定。\nnghttpx作为proxy，转向nginx后端 client ——\u0026gt; http2-proxy-no-tls ——\u0026gt; http1.1 upstream(nginx):\n# nghttpx -f127.0.0.1,8080 -b127.0.0.1,8022 --frontend-no-tls # curl 127.0.0.1:8022 this is beta3 server # nghttp http://127.0.0.1:8080 this is beta3 server  client ——\u0026gt; http2-proxy-with-tls ——\u0026gt; http1.1 upstream(nginx):\n# nghttpx -f127.0.0.1,8080 -b127.0.0.1,8022 /usr/lib/ssl/nginx.key /usr/lib/ssl/nginx.crt # nghttp https://127.0.0.1:8080 this is beta3 server  采用nginx-http2作为proxy，使用方法与nginx-http1.1没有区别。\nh2load作为压测工具 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  $ h2load -n100 -c10 -t4 https://127.0.0.1:8080 starting benchmark... spawning thread #0: 3 concurrent clients, 25 total requests spawning thread #1: 3 concurrent clients, 25 total requests spawning thread #2: 2 concurrent clients, 25 total requests spawning thread #3: 2 concurrent clients, 25 total requests Protocol: TLSv1.2 Cipher: ECDHE-RSA-AES128-GCM-SHA256 progress: 8% done progress: 16% done progress: 24% done progress: 32% done progress: 40% done progress: 48% done progress: 56% done progress: 64% done progress: 72% done progress: 80% done progress: 88% done progress: 96% done finished in 67.29ms, 1486 req/s, 111.02KB/s requests: 100 total, 100 started, 100 done, 100 succeeded, 0 failed, 0 errored status codes: 100 2xx, 0 3xx, 0 4xx, 0 5xx traffic: 7650 bytes total, 3450 bytes headers, 2100 bytes data min max mean sd +/- sd time for request: 343us 8.76ms 1.40ms 1.49ms 91.00%   h2load的使用与wrk没有区别，参数都是一样的。\n根据不同配置，我们有以下几种场景：\n1 2 3 4 5  server/proxy\thttps nginx-http/1.1\twith-tls nginx-http/2\tno-tls nghttpd   相结合，压测场景比较多。幸运的是，不论server是nginx还是nghttpd，其参数和调优都可以指定，比如线程数；不论wrk还是h2load，参数也可以指定，使用起来区别不大。\n","date":"2016-03-12T16:17:52+08:00","permalink":"https://bg2bkk.github.io/p/http2%E7%9A%84%E5%AE%9E%E8%B7%B5%E8%BF%87%E7%A8%8B/","title":"HTTP2的实践过程"},{"content":"UML类图  认真读图  单例模式  单例模式  http://tengj.top/2016/04/06/sjms4singleton/ http://liuxp0827.blog.51cto.com/5013343/1354360    工厂模式   简单工厂模式\n design pattern in GO interface　相当于是　abstract class    工厂方法模式\n 工厂方法模式的用意是定义一个创建产品对象的工厂接口，将实际创建工作推迟到子类中。    抽象工厂模式\n 抽象工厂模式可以向客户端提供一个接口，使得客户端在不必指定产品的具体类型的情况下，创建多个产品族中的产品对象。这就是抽象工厂的用意。    观察者模式  http://www.runoob.com/design-pattern/observer-pattern.html http://www.cnblogs.com/java-my-life/archive/2012/05/16/2502279.html  设计模式的不同实现   lua\n  java\n  cpp\n  java\n  book\n  ","date":"2016-03-11T11:33:10+08:00","permalink":"https://bg2bkk.github.io/p/design-patterns-%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/","title":"design patterns 设计模式"},{"content":" register_filesystem中的二级指针，刚开始没看懂。怒了，如果这个都没看懂，还搞什么C语言编程 leetcode中的反转链表，二级指针操作巨好用 先上代码吧  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121  #include\u0026lt;stdio.h\u0026gt;#include\u0026lt;stdlib.h\u0026gt; typedef struct ListNode{ int val; struct ListNode *next; } ListNode; void printList(ListNode *head){ if(head){ printf(\u0026#34;%d\\n\u0026#34;, head-\u0026gt;val); printList(head-\u0026gt;next); } } void printList_r(ListNode *head){ if(!head) return; if(head -\u0026gt; next) printList_r(head-\u0026gt;next); printf(\u0026#34;%d\\n\u0026#34;, head-\u0026gt;val); } ListNode ** addToTail(ListNode **list){ ListNode **p ; for( p = list; *p; p = \u0026amp; (*p)-\u0026gt;next); return p; } void reverseList(ListNode **list){ ListNode *head = NULL; ListNode **p = list; while(*p){ ListNode *next = (*p)-\u0026gt;next; (*p)-\u0026gt;next = head; head = *p; *p = next; } *list = head; } /* * delete first item whose val equals to val * */ void deleteNodeAll(ListNode **l, int val){ while(*l){ if((*l)-\u0026gt;val == val){ ListNode *tmp = (*l)-\u0026gt;next; free(*l); *l = tmp; break; } l = \u0026amp;(*l)-\u0026gt;next; } } //delete all the items whose val equals to val void deleteNodeFirst(ListNode **l, int val){ while(*l){ if((*l)-\u0026gt;val == val){ ListNode *tmp = (*l)-\u0026gt;next; free(*l); *l = tmp; } else l = \u0026amp;(*l)-\u0026gt;next; } } int main() { int a[] = {1, 2, 3, 2, 3 ,4}; int len = sizeof(a) / sizeof(int); int i = 0; static ListNode *list; for( i = 0; i \u0026lt; len; i++) { ListNode *node = malloc(sizeof(struct ListNode)); node-\u0026gt;val = a[i]; ListNode **p = addToTail(\u0026amp;list); *p = node; } printf(\u0026#34;--------print list in sequence------------\\n\u0026#34;); printList(list); printf(\u0026#34;--------print list after reversed------------------\\n\u0026#34;); reverseList(\u0026amp;list); printList(list); printf(\u0026#34;--------delete first 1----------\\n\u0026#34;); deleteNodeFirst(\u0026amp;list, 1); printList(list); printf(\u0026#34;--------delete first 3----------------\\n\u0026#34;); deleteNodeFirst(\u0026amp;list, 3); printList(list); printf(\u0026#34;--------delete first 4-----------------\\n\u0026#34;); deleteNodeFirst(\u0026amp;list, 4); printList(list); printf(\u0026#34;--------delete non-existed item-------------\\n\u0026#34;); deleteNodeFirst(\u0026amp;list, 4); printList(list); printf(\u0026#34;--------delete the last item----------------\\n\u0026#34;); deleteNodeFirst(\u0026amp;list, 2); printList(list); printf(\u0026#34;--------reverse an empty list---------------\\n\u0026#34;); reverseList(\u0026amp;list); printList(list); }   ","date":"2016-03-01T11:00:34+08:00","permalink":"https://bg2bkk.github.io/p/%E9%87%87%E7%94%A8%E4%BA%8C%E7%BA%A7%E6%8C%87%E9%92%88%E5%AE%9E%E7%8E%B0%E5%8D%95%E9%93%BE%E8%A1%A8%E6%93%8D%E4%BD%9C-%E5%8D%95%E9%93%BE%E8%A1%A8%E7%BF%BB%E8%BD%AC-%E5%88%A0%E9%99%A4%E5%8D%95%E9%93%BE%E8%A1%A8%E7%BB%93%E7%82%B9/","title":"采用二级指针实现单链表操作 单链表翻转 删除单链表结点"},{"content":"虚拟文件系统  虚拟文件系统为用户空间程序提供了文件和文件系统的接口 通过VFS，程序可以通过标准的UNIX系统调用操作不同的文件系统和介质，包括各种软硬件设备 Linux等现代操作系统引入VFS作为抽象层，极大方便系统调用  Unix文件系统   UNIX系统使用了四种和文件系统相关的抽象概念: 文件、目录项、索引结点和挂载点。\n  将文件的相关信息和文件加以区分\n 文件相关信息单独存储在索引结点中，又称为元数据，包括文件的控制权限、文件大小、属主和创建与访问时间等 文件相关信息和文件系统的相关信息密不可分，后者存储在***超级块(super block)***中，超级块是包含文件系统信息的数据结构。 文件按照索引结点存储在单独的块中，文件系统的控制信息存在超级块中    VFS中有四个主要对象类型\n 超级块对象，代表一个具体的已安装的文件系统 索引结点对象，代表一个具体文件  inode才代表具体文件   目录项对象，代表一个目录项，是路径的组成部分  目录项不是目录，而是一个文件。不存在目录对象   文件对象，代表由进程打开的文件  每个进程都有自己的打开文件列表，文件对象是一个动态生成动态销毁的对象      超级块\n 超级块对象 super block  用于存储特定文件系统的信息 通常放在磁盘的特定扇区中，所以被称为超级块对象 并非基于磁盘的文件系统，内核会现场创建，并保存在内存中   超级块操作  super_operations        索引结点\n 索引结点对象 inode  索引结点对象包含了内核在操作文件或目录时的所有信息 索引结点对象都是在内存中创建的，不会写回硬盘的   索引结点操作  inode_operations      目录项\n 目录项对象  VFS把目录当做文件对待，解析目录时，将路径中的每个组成部分都是一个索引结点对象，比如\u0026quot;/bin/ls\u0026quot;中的‘/’、‘bin’和‘ls’。进行路径查找和解析是比较耗时的，为了方便操作，VFS引入了目录项dentry的概念，每个dentry都是路径的组成部分 目录项对象都是根据字符串形式现场创建的，并没有保存在磁盘   目录项状态  被使用  被使用的dentry对应一个有效的inode，即dentry结构体中d_inode指向的inode 该对象的引用计数d_count为正，至少有一个使用者，不能随意丢弃   未被使用  未被使用的dentry，其d_inode也指向一个inode，但是d_count为0 此时该dentry仍然在缓存中，可能会再次使用。不会立刻被释放，但如果系统要回收内存的话，可以被释放回收   负状态  负状态的dentry没有对应的有效inode，原因可能是inode已被删除，或者路径不再正确 此时将其缓存起来仍然有些用处，比如一个守护进程一直读一个不存在的文件，缓存dentry不至于让进程总是去搜索     目录项缓存  遍历路径名中所有元素并逐个解析成dentry，是非常费时费力的，所以内核引入目录项缓存dcache，将目录项对象都缓存起来 目录项缓存包括  \u0026ldquo;被使用的\u0026quot;目录项链表  该链表通过inode中的i_dentry指针连接相关inode 一个给定的inode可能有多个链接（软硬链接），所有就有可能有多个目录项对象，因此用一个链表链接   \u0026ldquo;最近使用的\u0026quot;双向链表  该链表包含所有 未被使用的 和 负状态的 dentry 总是在表头添加元素，所以回收dentry时从最后开始回收   哈希表和相应的哈希函数  快速将给定路径解析为相关目录项对象 哈希表由dentry_hashtable数组表示，每个元素都指向一个具有相同键值的目录项对象链表指针 哈希函数d_hash() 查找函数d_lookup()       目录项操作  dentry_operation      文件\n 文件对象  表示进程已经打开的文件。文件对象是已打开的文件（物理文件）在内存中的表示 多个进程可以打开同一个物理文件，所以一个物理文件会有多个文件对象 文件对象指向目录项对象，目录项对象指向索引结点inode 具体而言，是文件对象filep中的f_dentry指向目录项对象，目录项对象的d_inode指向索引结点inode   文件操作  file_operations      相关数据结构\n file_system_type  用于描述各种特定文件系统类型，用于支持不同文件系统 struct file_system_type {}  get_sb() 从磁盘读取超级块，并在文件系统安装时在内存中组装超级块对象   每个文件系统只有一个   vfsmount  系统挂载时，将有一个vfsmount结构体在挂载点创建，代表文件系统的实例 struct vfsmount {}  各种链表        和进程相关的数据结构\n  每个进程都有自己的一组打开爱的文件，比如根文件系统、当前工作目录、挂载点等\n  struct files_struct {}\n 该结构提由进程描述符中的files指向，一般都是current-\u0026gt;files    struct fs_struct {}\n 包含文件系统和进程相关的信息，由fs域指向，一般是current-\u0026gt;fs    struct namespace {}\n 使得每个进程在系统中能看到唯一的安装文件系统，mm-\u0026gt;namespace    每个进程都有指向自己的fs_struct和files_struct，多个进程可能指向同一个，比如通过带有CLONE_FILES和CLONE_FS标志创建的进程（其实是线程），所以这两个struct都有引用计数，以防出错\n  而对于namespace来说，除非使用CLONE_NEWS标志创建进程，会创建新的namespace结构体，否则所有进程共享一个namespace\n    ","date":"2016-02-29T15:33:32+08:00","permalink":"https://bg2bkk.github.io/p/vfs%E8%99%9A%E6%8B%9F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/","title":"VFS虚拟文件系统"},{"content":"pipe在linux内核中的实现 在之前关于linux shell多线程并发数控制的博文中，我们使用了fifo作为token池，通过读写fifo实现token分发控制，进而实现了控制线程数的目的。 我对pipe这个*** *NIX ***系统中最常用的组件（|）产生了兴趣\n fifo和pipe是什么关系？ fifo或者pipe的使用方法？ pipe在linux kernel中的实现是怎样的？ fifo或者pipe的容量有多大，可以配置吗？  先说结论吧\n fifo和pipe的区别  pipe是匿名管道，没有名字，只能用于两个拥有pipe读写两端fd的进程通信； fifo在文件系统中有自己的名称，操作fifo与操作普通文件几无差别，可以用于两个没有关系的进程间通信   fifo和pipe在kernel层面上都实现在fs/pipe.c中，所以本质上二者是一个东西。 pipe作为linux文件系统的一部分，与epoll一样，都是在向kernel注册了自己的文件系统，可以使用VFS提供的通用接口，比如open、read和write等操作 pipe的容量不是无限大的，早期linux版本（kernel-2.4）中pipe容量只能是4KB大小，新版本可以在运行时根据需要扩大到64KB  本文主要基于linux-2.4.20内核中的pipe实现进行分析，理由是该版本的pipe实现与新版本kernel并没有太大差别，但是代码可读性要强很多，可以快速了解pipe的实际实现；从2.4.20内核中对pipe的架构有整体了解后，再阅读新版本(4.4.1)中的新feature，会比较顺遂。\npipe在fs/pipe.c中一些函数 - new_inode() - register_filesystem() - get_empty_file - get_unused_fd() - do_pipe作为pipe系统调用函数，在/arch/i386/sys_i386.c中定义 - pipe的module_init在initcall中调用，但是pipe.c是编译在fs.o中的，他的module_init是如何调用进去的，需要进一步查找 - struct dentry在include/linux/dcache.h中定义  具体实现 * pipe文件系统初始化 * 注册pipefs * register_filesystems * pipe系统调用 * pipe调用do_pipe * do_pipe() * f1\u0026amp;f2 get_empty_filep分配filep数据结构 * inode = get_pipe_inode()从pipe文件系统获得inode * new_inode() * pipe_new()新建pipe * __get_free_pages(GFP_USER)为该pipe分配一页内存（4KB） * inode-\u0026gt;i_pipe = kmalloc(sizeof(struct pipe_inde_info), GFP_KERNEL)分配pipe信息结构 * i\u0026amp;j = get_unused_fd()获取两个fd * dentry = d_alloc()从pipefs分配dentry * d_add(dentry, inode)将inode插入到dentry中 * 将f1设置成O_RDONLY，将f2设置成O_WRONLY * 进程的files列表中，files[i] = f1, files[j] = f2 * 实现函数 * pipe * pipe_read * pipe_write   tips   pipe不允许使用seek\n  低版本linux-2.4.20在pipe写的时候是固定大小，而高版本的是会按需分配直至64KB的。\n  高版本kernel内核中sysctl的配置参数fs.pipe-max-size 可以设置固定的pipe大小。但是也不能超过64KB大小，即使配置数据大于这个数字，pipe大小也会限制在64KB。\n  测试代码\n    1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  #!/bin/bash test $# -ge 1 || { echo \u0026#34;usage: $0write-size [wait-time]\u0026#34;; exit 1; } test $# -ge 2 || set -- \u0026#34;$@\u0026#34; 1 bytes_written=$( { exec 3\u0026gt;\u0026amp;1 { perl -e \u0026#39; $size = $ARGV[0]; $block = q(a) x $size; $num_written = 0; sub report { print STDERR $num_written * $size, qq(\\n); } report; while (defined syswrite STDOUT, $block) { $num_written++; report; } \u0026#39; \u0026#34;$1\u0026#34; 2\u0026gt;\u0026amp;3 } | (sleep \u0026#34;$2\u0026#34;; exec 0\u0026lt;\u0026amp;-); } | tail -1 ) printf \u0026#34;write size: %10d; bytes successfully before error: %d\\n\u0026#34; \\  \u0026#34;$1\u0026#34; \u0026#34;$bytes_written\u0026#34;   * 测试结果  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  huang@ThinkPad-X220:~/workspace/cpp$ /bin/bash -c \u0026#39;for p in {0..18}; do ./pipe.sh $((2 ** $p)) 0.5; done\u0026#39; write size: 1; bytes successfully before error: 65536 write size: 2; bytes successfully before error: 65536 write size: 4; bytes successfully before error: 65536 write size: 8; bytes successfully before error: 65536 write size: 16; bytes successfully before error: 65536 write size: 32; bytes successfully before error: 65536 write size: 64; bytes successfully before error: 65536 write size: 128; bytes successfully before error: 65536 write size: 256; bytes successfully before error: 65536 write size: 512; bytes successfully before error: 65536 write size: 1024; bytes successfully before error: 65536 write size: 2048; bytes successfully before error: 65536 write size: 4096; bytes successfully before error: 65536 write size: 8192; bytes successfully before error: 65536 write size: 16384; bytes successfully before error: 65536 write size: 32768; bytes successfully before error: 65536 write size: 65536; bytes successfully before error: 65536 write size: 131072; bytes successfully before error: 0 write size: 262144; bytes successfully before error: 0   * 内核中64KB大小的限制在哪里设置的？(TO DO) * 只有在高版本的pipe实现中才有64KB大小，低版本都是4KB的。 * ulimit -a 的结果中，\u0026quot;pipe size (512 bytes, -p) 8\u0026quot;，表示一个pipe拥有8个512KB的buffer，总共是4KB * 在include/linux/fs_pipe_i.h中，#define PIPE_DEF_BUFFERS 16, 这里是[按buffer的数量分配的](http://home.gna.org/pysfst/tests/pipe-limit.html)。 * 在fs/pipe.c中，pipe_write和pipe_read是在运行时按页大小分配的 * sysctl中fs.max_pipe_size的设置，fs.pipe-max-size = 1048576，又会起什么作用   函数分析  init_pipe_fs向文件系统注册pipe组件    1 2 3 4 5 6 7 8 9 10 11 12 13  static int __init init_pipe_fs(void) { int err = register_filesystem(\u0026amp;pipe_fs_type); if (!err) { pipe_mnt = kern_mount(\u0026amp;pipe_fs_type); err = PTR_ERR(pipe_mnt); if (IS_ERR(pipe_mnt)) unregister_filesystem(\u0026amp;pipe_fs_type); else err = 0; } return err; }   1  static DECLARE_FSTYPE(pipe_fs_type, \u0026#34;pipefs\u0026#34;, pipefs_read_super, FS_NOMOUNT);   1 2 3 4 5 6 7  #define DECLARE_FSTYPE(var,type,read,flags) \\ struct file_system_type var = { \\ name:\ttype, \\ read_super:\tread, \\ fs_flags:\tflags, \\ owner:\tTHIS_MODULE, \\ }   * pipe源码（2.4的实现中实在没什么可讲的，比较有价值的是pipe_write和pipe_read中处理缓冲队列源码可以参考）  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256  /* * We use a start+len construction, which provides full use of the * allocated memory. * -- Florian Coosmann (FGC) * * Reads with count = 0 should always return 0. * -- Julian Bradfield 1999-06-07. */ /* Drop the inode semaphore and wait for a pipe event, atomically */ void pipe_wait(struct inode * inode) { DECLARE_WAITQUEUE(wait, current); current-\u0026gt;state = TASK_INTERRUPTIBLE; add_wait_queue(PIPE_WAIT(*inode), \u0026amp;wait); up(PIPE_SEM(*inode)); schedule(); remove_wait_queue(PIPE_WAIT(*inode), \u0026amp;wait); current-\u0026gt;state = TASK_RUNNING; down(PIPE_SEM(*inode)); } static ssize_t pipe_read(struct file *filp, char *buf, size_t count, loff_t *ppos) { struct inode *inode = filp-\u0026gt;f_dentry-\u0026gt;d_inode; ssize_t size, read, ret; /* Seeks are not allowed on pipes. */ ret = -ESPIPE; read = 0; if (ppos != \u0026amp;filp-\u0026gt;f_pos) goto out_nolock; /* Always return 0 on null read. */ ret = 0; if (count == 0) goto out_nolock; /* Get the pipe semaphore */ ret = -ERESTARTSYS; if (down_interruptible(PIPE_SEM(*inode))) goto out_nolock; if (PIPE_EMPTY(*inode)) { do_more_read: ret = 0; if (!PIPE_WRITERS(*inode)) goto out; ret = -EAGAIN; if (filp-\u0026gt;f_flags \u0026amp; O_NONBLOCK) goto out; for (;;) { PIPE_WAITING_READERS(*inode)++; pipe_wait(inode); PIPE_WAITING_READERS(*inode)--; ret = -ERESTARTSYS; if (signal_pending(current)) goto out; ret = 0; if (!PIPE_EMPTY(*inode)) break; if (!PIPE_WRITERS(*inode)) goto out; } } /* Read what data is available. */ ret = -EFAULT; while (count \u0026gt; 0 \u0026amp;\u0026amp; (size = PIPE_LEN(*inode))) { char *pipebuf = PIPE_BASE(*inode) + PIPE_START(*inode); ssize_t chars = PIPE_MAX_RCHUNK(*inode); if (chars \u0026gt; count) chars = count; if (chars \u0026gt; size) chars = size; if (copy_to_user(buf, pipebuf, chars)) goto out; read += chars; PIPE_START(*inode) += chars; PIPE_START(*inode) \u0026amp;= (PIPE_SIZE - 1); PIPE_LEN(*inode) -= chars; count -= chars; buf += chars; } /* Cache behaviour optimization */ if (!PIPE_LEN(*inode)) PIPE_START(*inode) = 0; if (count \u0026amp;\u0026amp; PIPE_WAITING_WRITERS(*inode) \u0026amp;\u0026amp; !(filp-\u0026gt;f_flags \u0026amp; O_NONBLOCK)) { /* * We know that we are going to sleep: signal * writers synchronously that there is more * room. */ wake_up_interruptible_sync(PIPE_WAIT(*inode)); if (!PIPE_EMPTY(*inode)) BUG(); goto do_more_read; } /* Signal writers asynchronously that there is more room. */ wake_up_interruptible(PIPE_WAIT(*inode)); ret = read; out: up(PIPE_SEM(*inode)); out_nolock: if (read) ret = read; UPDATE_ATIME(inode); return ret; } static ssize_t pipe_write(struct file *filp, const char *buf, size_t count, loff_t *ppos) { struct inode *inode = filp-\u0026gt;f_dentry-\u0026gt;d_inode; ssize_t free, written, ret; /* Seeks are not allowed on pipes. */ ret = -ESPIPE; written = 0; if (ppos != \u0026amp;filp-\u0026gt;f_pos) goto out_nolock; /* Null write succeeds. */ ret = 0; if (count == 0) goto out_nolock; ret = -ERESTARTSYS; if (down_interruptible(PIPE_SEM(*inode))) goto out_nolock; /* No readers yields SIGPIPE. */ if (!PIPE_READERS(*inode)) goto sigpipe; /* If count \u0026lt;= PIPE_BUF, we have to make it atomic. */ free = (count \u0026lt;= PIPE_BUF ? count : 1); /* Wait, or check for, available space. */ if (filp-\u0026gt;f_flags \u0026amp; O_NONBLOCK) { ret = -EAGAIN; if (PIPE_FREE(*inode) \u0026lt; free) goto out; } else { while (PIPE_FREE(*inode) \u0026lt; free) { PIPE_WAITING_WRITERS(*inode)++; pipe_wait(inode); PIPE_WAITING_WRITERS(*inode)--; ret = -ERESTARTSYS; if (signal_pending(current)) goto out; if (!PIPE_READERS(*inode)) goto sigpipe; } } /* Copy into available space. */ ret = -EFAULT; while (count \u0026gt; 0) { int space; char *pipebuf = PIPE_BASE(*inode) + PIPE_END(*inode); ssize_t chars = PIPE_MAX_WCHUNK(*inode); if ((space = PIPE_FREE(*inode)) != 0) { if (chars \u0026gt; count) chars = count; if (chars \u0026gt; space) chars = space; if (copy_from_user(pipebuf, buf, chars)) goto out; written += chars; PIPE_LEN(*inode) += chars; count -= chars; buf += chars; space = PIPE_FREE(*inode); continue; } ret = written; if (filp-\u0026gt;f_flags \u0026amp; O_NONBLOCK) break; do { /* * Synchronous wake-up: it knows that this process * is going to give up this CPU, so it doesn\u0026#39;t have * to do idle reschedules. */ wake_up_interruptible_sync(PIPE_WAIT(*inode)); PIPE_WAITING_WRITERS(*inode)++; pipe_wait(inode); PIPE_WAITING_WRITERS(*inode)--; if (signal_pending(current)) goto out; if (!PIPE_READERS(*inode)) goto sigpipe; } while (!PIPE_FREE(*inode)); ret = -EFAULT; } /* Signal readers asynchronously that there is more data. */ wake_up_interruptible(PIPE_WAIT(*inode)); inode-\u0026gt;i_ctime = inode-\u0026gt;i_mtime = CURRENT_TIME; mark_inode_dirty(inode); out: up(PIPE_SEM(*inode)); out_nolock: if (written) ret = written; return ret; sigpipe: if (written) goto out; up(PIPE_SEM(*inode)); send_sig(SIGPIPE, current, 0); return -EPIPE; } /* No kernel lock held - fine */ static unsigned int pipe_poll(struct file *filp, poll_table *wait) { unsigned int mask; struct inode *inode = filp-\u0026gt;f_dentry-\u0026gt;d_inode; poll_wait(filp, PIPE_WAIT(*inode), wait); /* Reading only -- no need for acquiring the semaphore. */ mask = POLLIN | POLLRDNORM; if (PIPE_EMPTY(*inode)) mask = POLLOUT | POLLWRNORM; if (!PIPE_WRITERS(*inode) \u0026amp;\u0026amp; filp-\u0026gt;f_version != PIPE_WCOUNTER(*inode)) mask |= POLLHUP; if (!PIPE_READERS(*inode)) mask |= POLLERR; return mask; }   ","date":"2016-02-27T09:49:41+08:00","permalink":"https://bg2bkk.github.io/p/pipe%E5%9C%A8%E5%86%85%E6%A0%B8%E4%B8%AD%E7%9A%84%E5%AE%9E%E7%8E%B0/","title":"pipe在内核中的实现"},{"content":" redis主从复制  在介绍REDIS的RDB持久化方式时，我们提到了主从复制的实现过程  第一次同步，slave发送sync命令开始同步，master生成快照全量发送给slave，快照生成之后的变更命令缓存起来，也一块发送给slave 第二次及以后的同步，master收到命令后修改数据，并将数据修改后的结果同步给slave；如果此时发生断开重连情况，则重新进行第一步操作； redis-2.8版本后，如果发生断开重连，则进行增量传输，而不是全量传输   这里有两个值得介绍的地方  不论是否设置RDB持久化，主从复制都会产生快照 redis.conf中不设置save 900 1等配置时，只是不自动产生快照，如果执行save，还是会产生快照的 主从复制时，master执行完命令后会立刻将结果返回client，而不是等待同步给slave后再返回给client。这里可能会有一个不一致窗口，如果主从在master执行完指令和同步给client之间断开，这里会发生不一致现象，需要注意   主从复制的常见设计思路  用于保证数据持久化  master正常读写，不设置RDB或者AOF的持久化 slave设置RDB和AOF方式持久化，保证数据安全   基于实用目的的主从复制  master设置为只写模式，将结果同步给slave slave设置为只读模式，作为系统缓存        一般而言，了解以上知识，只能算是对redis的主从同步机制有了整体和粗糙的认识，而主从复制过程中发生了什么，如果能充分挖掘，也能感受到作者当时的苦心孤诣，学习到新的知识。\n好吧，装逼的话说完了，我想说，面试58的分布式存储工程师的时候，我被问到了这些问题，这些问题问的非常好，我需要补补课！\nreplication of redis replication\n抓包发现，首次同步时，master将rdb文件整体发给slave，之后master有变动的话，master将会同步命令给salve，比如直接同步set key val命令。\nv2.8之后的redis增量复制   redis slave有6个状态:\n REDIS_REPL_NONE  收到 slaveof host port，或者初始化进行主从同步时，进入下一状态   REDIS_REPL_CONNECT  redis会周期的执行replicationCron函数，而在该状态下，replicationCron函数将创建socket连接master，进入下一状态   REDIS_REPL_CONNECTING  同步socket将发送PING消息给master，随后关闭该socket的写事件，进入下一状态   REDIS_REPL_RECEIVE_PONG  socket收到PONG后，进行redis认证，认证成功后发送SYNC命令请求同步；新建临时文件接收rdb文件；进入下一状态   REDIS_REPL_TRANSFER  socket读取rdb数据，写到rdb文件   REDIS_REPL_CONNECTED  完全获取rdb文件后，进入CONNECTED状态；把master当做一个特殊的client，接收写命令      redis master 有4个状态\n REDIS_REPL_WAIT_BGSAVE_START REDIS_REPL_WAIT_BGSAVE_END_ REDIS_REPL_WAIT_BGSAVE_BULK REDIS_REPL_WAIT_BGSAVE_ONLINE    增量复制\n 增量复制的区别，同步时，客户端先做增量复制，不然时间太久也只能全量复制了。 rdb文件格式    ","date":"2016-02-26T16:15:31+08:00","permalink":"https://bg2bkk.github.io/p/redis%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","title":"redis主从复制学习笔记"},{"content":"  虽然网络上关于redis持久化的相关内容数不胜数，但是一来作为我的学习笔记，好记性不如烂笔头；二来除去官方redis之外，很多有意义的修改或补充都非常值得讨论，所以我想做一下记录。\n  持久化用于重启后的数据恢复，而持久化的引入导致了redis可能产生的性能抖动\n  redis持久化的两种方法 \n  RDB方式\n  RDB方式是redis的默认持久化方式\n  快照RDB持久化过程:\n redis调用fork，产生子进程 父进程继续接受用户请求；子进程负责将内存内容写入临时文件，写入完成后rename为dump文件，实现替换 在子进程写内存内容期间，父进程如果要修改内存数据，os将会通过写时复制为父进程创建副本，所以此时子进程写入的仍然是fork时刻的整个数据库内容    不足之处在于:\n 如果redis出现问题崩溃了，此时的rdb文件可能不是最新的数据，从上次RDB文件生成到redis崩溃这段时间的数据全部丢掉。 产生快照时，redis最多将占用2倍于现有数据规模的内存，因此当内存占用过多时，RDB方式可能导致系统负载过高，甚至假死。（有个说法是，当redis的内存占用超过物理内存的3/5时，进行RDB主从复制就比较危险了）    主从复制过程\n 第一次同步  slave向master发送sync同步请求，master先dump出rdb文件，并将其全量传输给slave；master将产生rdb文件之后这段时间内的修改命令缓存起来，并发送给slave。首次同步完成。   第二次及以后的同步实现方式：  master将变量的快照（有修改的变量）直接实时发送给slave。 如果发生断开重连，则重复第一步第二步   reids-2.8版本之后，重连后进行第一步时，不用全量更新了。      AOF方式\n  AOF方式持久化过程\n Append Only File Redis将每次收到的命令都追加到文件中，类似于mysql的binlog；当redis重启时重新执行文件中的所有命令来重建数据 如果将所有命令不加甄别的都写入文件中，持久化文件会越来越大，比如INCR test命令执行100次，效果与SET test 100一样。此时需要进行rewrite，合并命令。 Redis提供了bgrewriteaof命令，执行过程与产生RDB文件的机制类似，fork出的子进程将内存中的数据以命令的方式重写持久化文件。本质上讲，该命令是将数据库中所有数据内容以命令的方式重写进新的AOF文件    AOF方式之我的想法\n AOF方式是redis在收到命名后将命令写入文件内，如果redis发生故障，重启时直接读取AOF文件重新执行命令即可恢复，可以克服RDB方式的缺点 bgrewriteaof指令是对AOF方式的一次优化，执行bgrewriteaof命令时是根据此时数据库内容来写入AOF文件，并替换旧的AOF文件。这个过程与RDB快照产生方式一样      RDB方式和AOF方式的对比\n RDB方式恢复起来快，而AOF方式需要一条条命令执行 RDB文件不需要经过编码，是数据库内容的直接克隆，所以文件比较小；而AOF文件内是一条条命令，需要依次执行 RDB文件可能会丢失部分数据，而AOF则专门解决这个问题    选择哪种方式\n 官方推荐：  如果想要很高的数据保障，则同时使用两种方式 如果可以接受数据丢失，则仅使用RDB方式   通常的设计思路是  利用replication机制弥补持久化在性能和设计上的不足 master上不做RDB和AOF，保证读写性能 slave同时开启两种方式，保证数据安全性        Redis数据恢复过程\n AOF优先级高于RDB方式，如果同时配置了AOF和RDB，AOF生效    1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  void loadDataFromDisk(void) { long long start = ustime(); if (server.aof_state == REDIS_AOF_ON) { if (loadAppendOnlyFile(server.aof_filename) == REDIS_OK) redisLog(REDIS_NOTICE,\u0026#34;DB loaded from append only file: %.3f seconds\u0026#34;,(float)(ustime()-start)/1000000); } else { if (rdbLoad(server.rdb_filename) == REDIS_OK) { redisLog(REDIS_NOTICE,\u0026#34;DB loaded from disk: %.3f seconds\u0026#34;, (float)(ustime()-start)/1000000); } else if (errno != ENOENT) { redisLog(REDIS_WARNING,\u0026#34;Fatal error loading the DB: %s. Exiting.\u0026#34;,strerror(errno)); exit(1); } } }    持久化和RDB文件格式  ","date":"2016-02-26T14:56:41+08:00","permalink":"https://bg2bkk.github.io/p/redis%E6%8C%81%E4%B9%85%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","title":"redis持久化学习笔记"},{"content":"在我尝试从kernel中深入了解TCP IP协议栈时，遇到了难题。 我选择的是linux-2.4.20 kernel，理由如下： 1. 首先是\u0026lt;TCP/IP Architecture, Design, And Implementation In Linux\u0026gt;一书采用的是该版本，会有按图索骥的效果。 2. 第二个理由，正如书中所说的，TCP/IP协议栈在2.4内核中就已经基本成型，而根据我实际对比，2.4.20内核与4.4.1内核在TCP/IP实现的框架上大体是相同的，区别是2.6 kernel以后完全将VFS中的各组件namespace化，另外是一些高版本内核引入的措施（比如对比net/socket.c中sock_create函数）。 3. 第三个理由是，linux-2.4 kernel的代码还没有开始爆炸，适合初学者入门，也适合我这样学力不足的人。 采用linux-2.4 kernel的不足之处在于，版本较老，想亲自动手实验，需要做一些兼容性的准备。  我搜到了这样一篇帖子， 收益颇深。解决了我的疑问，用我最能接受的方式，先从kernel启动的函数说起，然后调用到我能看到的net/socket.c中的函数；然后又通过修改kernel源码添加标记，打印运行log来标志函数执行；然后通过讲解module_init注册的静态模块是如何加进内核可执行文件里的，然后编译出linux.map文件，进一步确定函数执行顺序。这个方式让我非常容易接受，也很感慨写博客的人功力之深，通篇干货没有废话；更感慨的是，这个帖子写于2001左右，当时进行kernel修改还是比较容易的事情，现在的kernel代码越来越庞大，初学者为此望而却步，很难入手；新人难以入门的问题，近年来也多有讨论。\n那我就先把原作者的文章翻译过来，再继续下一步工作吧。\n先说结论  kernel启动时，第一个与network有关的函数是sock_init()，用来向kernel注册sock文件系统并挂载，以及加载其他模块，比如netfilter loopback设备随后被初始化，因为该设备比较简单。drivers/net/loopback.c dummy 和 Ethernet 设备随后被初始化 TCP/IP协议栈是在inet_init()中初始化的 Unix Domain Socket是在af_unix_init()中初始化的。1~5步按时间顺序排列。  Linux Kernel 2.4的入口函数 1.经过基本硬件设置后，启动代码(定义在head.S中)调用 /init/main.c 的 start_kernel()函数\n1 2 3 4  #arch/i386/kernel/head.S ... call SYMBOL_NAME(start_kernel) ...   2.sock_init()调用过程，向系统注册sock文件系统并挂载\nsock_init()将向系统注册sock文件系统 do_initcalls()中循环调用所有MODULE_INIT()的模块，包括系统中的inet_init和af_unix_init，至于如何关联起来的，稍后会有介绍。  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41  asmlinkage void __init start_kernel(void) { ... printk(linux_banner);\t// \u0026#34;linux_banner\u0026#34; is defined in init/version.c (W.N.). ... ... // Dozens of initialize routines ... kernel_thread(init, NULL, CLONE_FS | CLONE_FILES | CLONE_SIGNAL); ... cpu_idle(); } static int init(void * unused) { ... do_basic_setup(); ... execve(\u0026#34;/sbin/init\u0026#34;,argv_init,envp_init); ... } static void __init do_basic_setup(void) { ... sock_init();\t// net/socket.c (SEE BELOW) ... do_initcalls(); ... } static void __init do_initcalls(void) { initcall_t *call; call = \u0026amp;__initcall_start; do { (*call)(); call++; } while (call \u0026lt; \u0026amp;__initcall_end); ... }   3.sock_init()的内容\n欢迎信息printk() 清空协议栈数组，此时系统中没有任何协议  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38  ... /* * The protocol list. Each protocol is registered in here. */ static struct net_proto_family *net_families[NPROTO];\t// Current NPROTO is defined as 32 \t// in \u0026lt;linux/net.h\u0026gt; (W.N.). ... void __init sock_init(void) { int i; printk(KERN_INFO \u0026#34;Linux NET4.0 for Linux 2.4\\n\u0026#34;); printk(KERN_INFO \u0026#34;Based upon Swansea University Computer Society NET3.039\\n\u0026#34;); /* * Initialize all address (protocol) families. */ #清空所有协议  for (i = 0; i \u0026lt; NPROTO; i++) net_families[i] = NULL; ... /* * Initialize the protocols module. */ #注册文件系统并挂载，sock_fs_type之前被初始化  register_filesystem(\u0026amp;sock_fs_type); sock_mnt = kern_mount(\u0026amp;sock_fs_type); /* The real protocol initialization is performed when * do_initcalls is run. */ ... }   4.do_initcalls()中的调用函数\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  #init/main.c  static void __init do_initcalls(void) { initcall_t *call; call = \u0026amp;__initcall_start; do { #添加打印语句，dmesg命令可以输出启动结果  printk(KERN_INFO \u0026#34;+++ do_initcall: %08X\\n\u0026#34;, call);\t// Dump the entry address of initializer (W.N.).  (*call)(); call++; } while (call \u0026lt; \u0026amp;__initcall_end); /* Make sure there is no pending stuff from the initcall sequence */ flush_scheduled_tasks(); }   同时也修改loopback_init函数\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  #drivers/net/loopback.c  int __init loopback_init(struct net_device *dev) { #添加打印语句  printk(KERN_INFO \u0026#34;=== Executing loopback_init ===\\n\u0026#34;); dev-\u0026gt;mtu = PAGE_SIZE - LOOPBACK_OVERHEAD; dev-\u0026gt;hard_start_xmit = loopback_xmit; dev-\u0026gt;hard_header = eth_header; dev-\u0026gt;hard_header_cache = eth_header_cache; dev-\u0026gt;header_cache_update= eth_header_cache_update; dev-\u0026gt;hard_header_len = ETH_HLEN; /* 14 */ dev-\u0026gt;addr_len = ETH_ALEN; /* 6 */ ... };   重新编译内核，替换并重启，dmesg的输出结果为：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135  Linux version 2.4.3 (root@mebius) (gcc version 2.95.3 20010315 (Debian release)) #9 Tue Apr 3 17:37: 44 JST 2001 BIOS-provided physical RAM map: BIOS-e820: 0000000000000000 - 000000000009f800 (usable) BIOS-e820: 000000000009f800 - 00000000000a0000 (reserved) BIOS-e820: 00000000000ebc00 - 0000000000100000 (reserved) BIOS-e820: 0000000000100000 - 0000000007ff0000 (usable) BIOS-e820: 0000000007ff0000 - 0000000007fffc00 (ACPI data) BIOS-e820: 0000000007fffc00 - 0000000008000000 (ACPI NVS) BIOS-e820: 00000000fff80000 - 0000000100000000 (reserved) On node 0 totalpages: 32752 zone(0): 4096 pages. zone(1): 28656 pages. zone(2): 0 pages. Kernel command line: root=/dev/hda1 mem=131008K Initializing CPU#0 Detected 333.350 MHz processor. Console: colour VGA+ 80x25 Calibrating delay loop... 665.19 BogoMIPS Memory: 126564k/131008k available (1076k kernel code, 4056k reserved, 387k data, 184k init, 0k highm em) Dentry-cache hash table entries: 16384 (order: 5, 131072 bytes) Buffer-cache hash table entries: 4096 (order: 2, 16384 bytes) Page-cache hash table entries: 32768 (order: 5, 131072 bytes) Inode-cache hash table entries: 8192 (order: 4, 65536 bytes) CPU: Before vendor init, caps: 0183f9ff 00000000 00000000, vendor = 0 CPU: L1 I cache: 16K, L1 D cache: 16K CPU: L2 cache: 256K Intel machine check architecture supported. Intel machine check reporting enabled on CPU#0. CPU: After vendor init, caps: 0183f9ff 00000000 00000000 00000000 CPU: After generic, caps: 0183f9ff 00000000 00000000 00000000 CPU: Common caps: 0183f9ff 00000000 00000000 00000000 CPU: Intel Mobile Pentium II stepping 0a Enabling fast FPU save and restore... done. Checking \u0026#39;hlt\u0026#39; instruction... OK. POSIX conformance testing by UNIFIX PCI: PCI BIOS revision 2.10 entry at 0xfd9be, last bus=0 PCI: Using configuration type 1 PCI: Probing PCI hardware PCI: Using IRQ router PIIX [8086/7110] at 00:07.0 got res[10000000:10000fff] for resource 0 of Ricoh Co Ltd RL5c475 Limiting direct PCI/PCI transfers. #sock_init()的运行log Linux NET4.0 for Linux 2.4\t// Message from sock_init() Based upon Swansea University Computer Society NET3.039 #sock_init()运行结束  #do_initcalls()中的每个initcall +++ do_initcall: C029F4E8\t// do_initcalls() START +++ do_initcall: C029F4EC +++ do_initcall: C029F4F0\t// apm_init() in arch/i386/kernel/kernel.o apm: BIOS version 1.2 Flags 0x03 (Driver version 1.14) +++ do_initcall: C029F4F4 +++ do_initcall: C029F4F8 +++ do_initcall: C029F4FC\t// kswapd_init() in mm/mm.o Starting kswapd v1.8 +++ do_initcall: C029F500 +++ do_initcall: C029F504 +++ do_initcall: C029F508 +++ do_initcall: C029F50C +++ do_initcall: C029F510 +++ do_initcall: C029F514 +++ do_initcall: C029F518 +++ do_initcall: C029F51C +++ do_initcall: C029F520 +++ do_initcall: C029F524 +++ do_initcall: C029F528\t// partition_setup() in fs/fs.o pty: 256 Unix98 ptys configured block: queued sectors max/low 84058kB/28019kB, 256 slots per queue RAMDISK driver initialized: 16 RAM disks of 8000K size 1024 blocksize Uniform Multi-Platform E-IDE driver Revision: 6.31 ide: Assuming 33MHz system bus speed for PIO modes; override with idebus=xx PIIX4: IDE controller on PCI bus 00 dev 39 PIIX4: chipset revision 1 PIIX4: not 100% native mode: will probe irqs later ide0: BM-DMA at 0xfc90-0xfc97, BIOS settings: hda:DMA, hdb:pio ide1: BM-DMA at 0xfc98-0xfc9f, BIOS settings: hdc:pio, hdd:pio hda: TOSHIBA MK8113MAT, ATA DISK drive ide0 at 0x1f0-0x1f7,0x3f6 on irq 14 hda: 16006410 sectors (8195 MB), CHS=996/255/63, UDMA(33) Partition check: hda: hda1 hda2 hda3 hda4 \u0026lt; hda5 hda6 hda7 hda8 hda9 hda10 \u0026gt; Floppy drive(s): fd0 is 1.44M FDC 0 is a National Semiconductor PC87306 #在loopback_init()中添加printk函数的结果 === Executing loopback_init ===\t// loopback initialization is here!  +++ do_initcall: C029F52C\t// ext2_fs() in fs/fs.o +++ do_initcall: C029F530 +++ do_initcall: C029F534 +++ do_initcall: C029F538 +++ do_initcall: C029F53C +++ do_initcall: C029F540 loop: loaded (max 8 devices) +++ do_initcall: C029F544 Serial driver version 5.05 (2000-12-13) with MANY_PORTS SHARE_IRQ SERIAL_PCI enabled ttyS00 at 0x03f8 (irq = 4) is a 16550A +++ do_initcall: C029F548\t// dummy_init_module() in drivers/net/net.o +++ do_initcall: C029F54C\t// rtl8139_init_module() in drivers/net/net.o 8139too Fast Ethernet driver 0.9.15c loaded PCI: Found IRQ 9 for device 00:03.0 PCI: The same IRQ used for device 00:07.2 eth0: RealTek RTL8139 Fast Ethernet at 0xc8800c00, 08:00:1f:06:79:20, IRQ 9 eth0: Identified 8139 chip type \u0026#39;RTL-8139B\u0026#39; +++ do_initcall: C029F550 +++ do_initcall: C029F554 +++ do_initcall: C029F558 +++ do_initcall: C029F55C +++ do_initcall: C029F560 #inet_init()的initcall结果 +++ do_initcall: C029F564\t// inet_init() in net/network.o NET4: Linux TCP/IP 1.0 for NET4.0 IP Protocols: ICMP, UDP, TCP IP: routing cache hash table of 512 buckets, 4Kbytes TCP: Hash tables configured (established 8192 bind 8192) #af_unix_inet()的initcall结果 +++ do_initcall: C029F568\t// af_unix_init() in net/network.o NET4: Unix domain sockets 1.0/SMP for Linux NET4.0. +++ do_initcall: C029F56C +++ do_initcall: C029F570 +++ do_initcall: C029F574\t// atalk_init() in net/network.o NET4: AppleTalk 0.18a for Linux NET4.0\t// do_initcalls() END fatfs: bogus cluster size reiserfs: checking transaction log (device 03:01) ... Using r5 hash to sort names ReiserFS version 3.6.25 VFS: Mounted root (reiserfs filesystem) readonly. Freeing unused kernel memory: 184k freed Adding Swap: 128516k swap-space (priority -1) eth0: Setting half-duplex based on auto-negotiated partner ability 0000.   5.initcalls的实现机制\n首先我们可以看到每个module都有使用module_init宏。\n1 2 3 4 5 6 7 8 9 10  #net/ipv4/af_inet.c  static int __init inet_init(void) { ... printk(KERN_INFO \u0026#34;NET4: Linux TCP/IP 1.0 for NET4.0\\n\u0026#34;); ... } module_init(inet_init);   __init宏和 module_init宏在 include/linux/init.h 中定义\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43  #ifndef MODULE #ifndef __ASSEMBLY__ ... typedef int (*initcall_t)(void); ... extern initcall_t __initcall_start, __initcall_end; #define __initcall(fn) \\ static initcall_t __initcall_##fn __init_call = fn ... #endif /* __ASSEMBLY__ */ /* * Mark functions and data as being only used at initialization * or exit time. */ #define __init __attribute__ ((__section__ (\u0026#34;.text.init\u0026#34;))) ... #define __init_call __attribute__ ((unused,__section__ (\u0026#34;.initcall.init\u0026#34;))) ... /** * module_init() - driver initialization entry point * @x: function to be run at kernel boot time or module insertion * * module_init() will add the driver initialization routine in * the \u0026#34;__initcall.int\u0026#34; code segment if the driver is checked as * \u0026#34;y\u0026#34; or static, or else it will wrap the driver initialization * routine with init_module() which is used by insmod and * modprobe when the driver is used as a module. */ #define module_init(x) __initcall(x); ... #else // MODULE ... #define __init ... #define __initcall(fn) ... #define module_init(x) \\ int init_module(void) __attribute__((alias(#x))); \\ extern inline __init_module_func_t __init_module_inline(void) \\ { return x; } ... #endif // MODULE   * init.h中的#define MODULE是在Makefile中的 -DMODULE 设置的，表示可以动态添加MODULE * 目前 CONFIG_INET (/arch/i386/defconfig) 不是 可选module （M），而是静态编译进内核的（y）。静态模块由init.h中的#ifndef MODULE块预处理，而可动态加载的模块（M）则会调用 #else //MODULE 后的初始化代码 * 所以经过预编译后，inet_init()函数将由上述代码的#ifndef MODULE 预处理为  1 2 3 4 5 6 7 8 9  #include/linux/init.h static int __attribute__ ((__section__ (\u0026#34;.text.init\u0026#34;))) inet_init(void) { ... printk(KERN_INFO \u0026#34;NET4: Linux TCP/IP 1.0 for NET4.0\\n\u0026#34;); ... } initcall_t __initcall_inet_init __attribute__ ((unused,__section__ (\u0026#34;.initcall.init\u0026#34;))) = inet_init;    这个扩展过程意味着：  inet_init()函数的代码段text code将编译进kernel可执行文件的***.text.init***段中，这种机制的目的是kernel启动，注册模块后能够释放所占用的内存 预处理后的***__initcall_inet_init***作为inet_init()函数的入口，将被存储在kernel可执行文件的 .initcall.init 段中。  注意这个宏定义是static类型的，所以我们并不能确定这个宏定义的结果是否在kernel的全局符号表中。（只有全局变量才在符号表中）     为了能够一探究竟，移除该宏定义的static标志，然后***_initcall*** ***这些入口就是全局变量了，然后我们就能在内核编译后的符号表中看到这些入口函数。  注意如果这些入口函数不是static作用域后，会导致一些链接错误，原因是命名冲突，比如netfilter中有类似命名   Let\u0026rsquo;s hack the kernel!!!  5.如何从内部观察linux kernel\n* linux kernel只是一个ELF可执行目标文件，和/bin/ls之类的可执行文件没有区别 * 所以作为kernel ELF文件，vmlinux可以通过nm、objdump和readelf等工具观察 * 默认情况下，linux kernel的顶层Makefile编译成功后将生成System.map文件，以方便调试，而这个文件不过是一个符号表。所以我向这个编译添加\u0026quot;--cref -Map linux.map\u0026quot;选项，可以生成一个包含更多信息的符号表  1 2 3 4 5 6 7 8 9 10 11 12 13 14  #Makefile #添加 --cref -Map linux.map 选项 vmlinux: $(CONFIGURATION) init/main.o init/version.o linuxsubdirs $(LD) $(LINKFLAGS) $(HEAD) init/main.o init/version.o \\ --start-group \\ $(CORE_FILES) \\ $(DRIVERS) \\ $(NETWORKS) \\ $(LIBS) \\ --end-group \\ --cref -Map linux.map \\ -o vmlinux $(NM) vmlinux | grep -v \u0026#39;\\(compiled\\)\\|\\(\\.o$$\\)\\|\\( [aUw] \\)\\|\\(\\.\\.ng$$\\)\\|\\(LASH[RL]DI\\)\u0026#39; | sort \u0026gt; System.map   * make vmlinux编译kernle源码，生成vmlinux和linux.map，通过objdump -h vmlinux查看各段信息 * 可以看到***.text.init***段和***.initcall.init***段  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39  #objdump -h vmlinux vmlinux: file format elf32-i386 Sections: Idx Name Size VMA LMA File off Algn 0 .text 0010bf68 c0100000 c0100000 00001000 2**4 CONTENTS, ALLOC, LOAD, READONLY, CODE 1 .text.lock 00001130 c020bf68 c020bf68 0010cf68 2**2 CONTENTS, ALLOC, LOAD, READONLY, CODE 2 .rodata 0004407c c020d0a0 c020d0a0 0010e0a0 2**5 CONTENTS, ALLOC, LOAD, READONLY, DATA 3 .kstrtab 000062fe c0251120 c0251120 00152120 2**5 CONTENTS, ALLOC, LOAD, READONLY, DATA 4 __ex_table 00001418 c0257420 c0257420 00158420 2**2 CONTENTS, ALLOC, LOAD, READONLY, DATA 5 __ksymtab 00001d68 c0258838 c0258838 00159838 2**2 CONTENTS, ALLOC, LOAD, READONLY, DATA 6 .data 00013abc c025a5a0 c025a5a0 0015b5a0 2**5 CONTENTS, ALLOC, LOAD, DATA 7 .data.init_task 00002000 c0270000 c0270000 00170000 2**5 CONTENTS, ALLOC, LOAD, DATA 8 .text.init 0000f56c c0272000 c0272000 00172000 2**4 CONTENTS, ALLOC, LOAD, READONLY, CODE 9 .data.init 0001de60 c0281580 c0281580 00181580 2**5 CONTENTS, ALLOC, LOAD, DATA 10 .setup.init 00000108 c029f3e0 c029f3e0 0019f3e0 2**2 CONTENTS, ALLOC, LOAD, DATA 11 .initcall.init 00000090 c029f4e8 c029f4e8 0019f4e8 2**2 CONTENTS, ALLOC, LOAD, DATA 12 .data.page_aligned 00000800 c02a0000 c02a0000 001a0000 2**5 CONTENTS, ALLOC, LOAD, DATA 13 .data.cacheline_aligned 00001fe0 c02a0800 c02a0800 001a0800 2**5 CONTENTS, ALLOC, LOAD, DATA 14 .bss 0002b3d8 c02a27e0 c02a27e0 001a27e0 2**5 ALLOC 15 .comment 00003bc9 00000000 00000000 001a27e0 2**0 CONTENTS, READONLY 16 .note 00001a90 00000000 00000000 001a63a9 2**0 CONTENTS, READONLY   * 如下是linux.map的文件内容 * __initcall_start 和 __initcall_end 定义了***.initcall.init***段的起始和结束，并出现在do_initcalls()函数中 * 之前将__initcall()宏的static关键字去掉了，所以__initcall_***这些入口函数地址，比如__initcall_inet_init就全局可见了，我们可以在文件中看到内核启动过程 * 内核开发者们总是喜欢用grep等工具来找某个函数在哪个文件中，而我们在linux.map中可以看到每个函数在哪个模块中，只需要less linux.map就可以了  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66  0xc029f4e8 __initcall_start=. .initcall.init 0xc029f4e8 0x90 *(.initcall.init) .initcall.init 0xc029f4e8 0xc arch/i386/kernel/kernel.o 0xc029f4e8 __initcall_dmi_scan_machine 0xc029f4ec __initcall_cpuid_init 0xc029f4f0 __initcall_apm_init .initcall.init 0xc029f4f4 0x4 kernel/kernel.o 0xc029f4f4 __initcall_uid_cache_init .initcall.init 0xc029f4f8 0xc mm/mm.o 0xc029f4f8 __initcall_kmem_cpucache_init 0xc029f4fc __initcall_kswapd_init 0xc029f500 __initcall_init_shmem_fs .initcall.init 0xc029f504 0x3c fs/fs.o 0xc029f504 __initcall_bdflush_init 0xc029f508 __initcall_init_pipe_fs 0xc029f50c __initcall_fasync_init 0xc029f510 __initcall_filelock_init 0xc029f514 __initcall_dnotify_init 0xc029f518 __initcall_init_misc_binfmt 0xc029f51c __initcall_init_script_binfmt 0xc029f520 __initcall_init_elf_binfmt 0xc029f524 __initcall_init_proc_fs 0xc029f528 __initcall_partition_setup 0xc029f52c __initcall_init_ext2_fs 0xc029f530 __initcall_init_fat_fs 0xc029f534 __initcall_init_msdos_fs 0xc029f538 __initcall_init_iso9660_fs 0xc029f53c __initcall_init_reiserfs_fs .initcall.init 0xc029f540 0x4 drivers/block/block.o 0xc029f540 __initcall_loop_init .initcall.init 0xc029f544 0x4 drivers/char/char.o 0xc029f544 __initcall_rs_init .initcall.init 0xc029f548 0x8 drivers/net/net.o 0xc029f548 __initcall_dummy_init_module 0xc029f54c __initcall_rtl8139_init_module .initcall.init 0xc029f550 0x4 drivers/ide/idedriver.o 0xc029f550 __initcall_ide_cdrom_init .initcall.init 0xc029f554 0x4 drivers/cdrom/driver.o 0xc029f554 __initcall_cdrom_init .initcall.init 0xc029f558 0x4 drivers/pci/driver.o 0xc029f558 __initcall_pci_proc_init .initcall.init 0xc029f55c 0x1c net/network.o 0xc029f55c __initcall_p8022_init 0xc029f560 __initcall_snap_init 0xc029f564 __initcall_inet_init 0xc029f568 __initcall_af_unix_init 0xc029f56c __initcall_netlink_proto_init 0xc029f570 __initcall_packet_init 0xc029f574 __initcall_atalk_init 0xc029f578 __initcall_end=. 0xc02a0000 .=ALIGN(0x1000) 0xc029f578 __init_end=. 0xc02a0000 .=ALIGN(0x1000)   linux.map中的信息可以帮助我们和dmesg的输出信息对照起来，可以看到内核中每个我们感兴趣的静态模块的加载顺序。\n以上工作都是基于linux-2.4内核实现的，新版本内核该如何实现呢？\n","date":"2016-02-24T23:13:13+08:00","permalink":"https://bg2bkk.github.io/p/tcp-ip%E5%8D%8F%E8%AE%AE%E6%A0%88%E5%9C%A8linux%E5%86%85%E6%A0%B8%E5%90%AF%E5%8A%A8%E4%B8%AD%E7%9A%84%E9%A1%BA%E5%BA%8F/","title":"tcp ip协议栈在linux内核启动中的顺序"},{"content":"一、tegine编译+高版本的httpluamodule  tengine-2.1.0的ngx_lua模块随着tengine软件发布，和以往版本的tengine不一样。 tengine自带的ngx_lua模块版本太老，与openresty相比要差几个版本，导致openresty里的一些好的软件工具不可用。  编译tengine+lua时需要手动指定ngx_lua模块和LuaJIT2.1  新版本ngx_lua能弥补openrestysystemtap在probe某些函数时的错误  关键脚本ngx-lua-exec-time.sxx中第58行@pfunc(ngx_http_lua_free_fake_request)函数找不到   使用LuaJIT2.1能解决lua执行时的stap问题。      1 2 3 4 5 6 7 8  #关键脚本stapxx/samples/ngx-lua-exec-time.sxx中第58行@pfunc(ngx_http_lua_free_fake_request)函数找不到的问题： 2\u0026gt; sudo ./samples/ngx-lua-exec-time.sxx -x 11070 semantic error: while resolving probe point: identifier \u0026#39;process\u0026#39; at \u0026lt;input\u0026gt;:58:7 source: process(\u0026#34;/usr/local/nginx/sbin/nginx\u0026#34;).function(\u0026#34;ngx_http_lua_free_fake_request\u0026#34;) ^ semantic error: no match (similar functions: ngx_http_lua_get_request, ngx_http_create_request, ngx_http_free_request, ngx_http_lua_post_subrequest, ngx_http_scgi_create_request) Pass 2: analysis failed. [man error::pass2]   1 2 3 4 5 6 7 8 9 10 11 12  #tegine编译选项 CFLAGS=\u0026#34;-g -O2\u0026#34; ./configure --add-module=/path/ngx_openresty-1.7.10.1/bundle/ngx_lua-0.9.15/ --with-luajit-lib=/usr/local/lib/ --with-luajit-inc=/usr/local/include/luajit-2.1/ --with-ld-opt=-Wl,-rpath,/usr/local/lib make -j16 #新版本ngx_lua在openresty的bundle的ngx_lua-0.9.15/里，也可以从https://github.com/openresty/lua-nginx-module获得 #LuaJIT2.1的源代码也在bundle里，也可以从https://github.com/openresty/luajit2获得。 LuaJIT2.1的编译选项是： make CCDEBUG=-g -B -j8 make -j16   二、axel下载工具和debuginfo.centos.org  我们在安装kernel的debuginfo包的时候，由于只有debuginfo.centos.org上面有rpm包，所以yum源设置为它，但是在国内访问实在是慢，因此推荐使用axel或者mwget下载。mwget顾名思义是多线程的wget工具，下载rpm包非常快，值得推荐。 当我们为了系统中的systemtap安装时，需要安装kernel-debuginfo，这时需要注意严格按照自己的kernel版本来，centos系的需要注意是否2.6.32-431.11.2.el6.toa.2.x86_64后面有toa之类的  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  #debian系的可以使用dpkg -l linux-image*命令，查看具体内核版本； huang@ThinkPad-X220:~$ dpkg -l linux-image* Desired=Unknown/Install/Remove/Purge/Hold | Status=Not/Inst/Conf-files/Unpacked/halF-conf/Half-inst/trig-aWait/Trig-pend |/ Err?=(none)/Reinst-required (Status,Err: uppercase=bad) ||/ Name Version Architecture Description +++-======================-================-================-================================================== un linux-image \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; (no description available) un linux-image-3.0 \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; (no description available) ii linux-image-3.13.0-24- 3.13.0-24.47 amd64 Linux kernel image for version 3.13.0 on 64 bit x8 ii linux-image-3.13.0-24- 3.13.0-24.47 amd64 Linux kernel debug image for version 3.13.0 on 64 ii linux-image-extra-3.13 3.13.0-24.46 amd64 Linux kernel extra modules for version 3.13.0 on 6 ii linux-image-generic 3.13.0.24.28 amd64 Generic Linux kernel image #特别要注意的是3.13.0-24.46、 47、 48，小版本很重要的。   三、centos6.4的gcc版本过低导致的问题  在使用stapxx的工具追踪nginx运行情况时，发现有如下情况，比如：  1 2 3 4 5 6 7 8 9 10 11 12  2\u0026gt; sudo ./samples/ngx-rewrite-latency-distr.sxx -x 11070 semantic error: not accessible at this address [man error::dwarf] (0x44a53b, dieoffset: 0x13a891): identifier \u0026#39;$r\u0026#39; at \u0026lt;input\u0026gt;:67:9 source: r = $r ^ Pass 2: analysis failed. [man error::pass2] # 这个r是没有问题的，在nginx-systemtap-toolkit/ngx-active-reqs中有类似定义： my $c = \u0026#39;@cast(c, \u0026#34;ngx_connection_t\u0026#34;)\u0026#39;; my $r = \u0026#39;@cast(r, \u0026#34;ngx_http_request_t\u0026#34;)\u0026#39;; my $u = \u0026#39;@cast(u, \u0026#34;ngx_http_upstream_t\u0026#34;)\u0026#39;; my $p = \u0026#39;@cast(p, \u0026#34;ngx_event_pipe_t\u0026#34;)\u0026#39;;     产生原因\n tengine的DWARF信息不完整  低版本的gcc在O2时优化掉很多东西，而高版本gcc智能的多      解决方法有两种\n 一种方法是将gcc的编译优化选项降低为O0，以前是O2，则这个ngx_http_request_t的符号，即nginx的DWARF信息可以保留下来。 另一种方法是升级gcc，考虑到在线上服务器升级gcc不太好，这里介绍一种暂时升级gcc的办法    1 2 3 4 5 6  $ sudo wget http://people.centos.org/tru/devtools-1.1/devtools-1.1.repo -P /etc/yum.repos.d $ sudo sh -c \u0026#39;echo \u0026#34;enabled=1\u0026#34; \u0026gt;\u0026gt; /etc/yum.repos.d/devtools-1.1.repo\u0026#39; $ sudo yum install devtoolset-1.1 $ scl enable devtoolset-1.1 bash $ gcc --version # 通过devtoolset工具可以暂时提高gcc版本，而不更改之前服务器的配置，这个很有效果，高版本的gcc会智能保留symbol。   四、apache的压测工具ab升级高版本 在压测过程中，我们想微观的通过tcpdump抓包分析通信过程。\n 发现ab工具在发起keepalive请求时，在完成-n的请求数后额外的发出一个请求，随后又发出F包关闭连接，导致通信过程多出一次。 已有的httpd 2.3自带的ab工具有这个bug，升级httpd2.4后这个问题修复。  五、tcpdump抓取fin包 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  # tcp包里有个flags字段表示包的类型，tcpdump可以根据该字段抓取相应类型的包： # tcp[13] 就是 TCP flags (URG,ACK,PSH,RST,SYN,FIN) # Unskilled 32 # Attackers 16 # Pester 8 # Real 4 # Security 2 # Folks 1 #抓取fin包： tcpdump -ni any port 9001 and \u0026#39;tcp[13] \u0026amp; 1 != 0 \u0026#39; -s0 -w fin.cap -vvv #抓取syn+fin包： tcpdump -ni any port 9001 and \u0026#39;tcp[13] \u0026amp; 3 != 0 \u0026#39; -s0 -w syn_fin.cap -vvv #抓取rst包： tcpdump -ni any port 9001 and \u0026#39;tcp[13] \u0026amp; 4 != 0 \u0026#39; -s0 -w rst.cap -vvv   参考链接\n六、redis内部监测工具 redis-faina redis-faina是facebook出品的，用于监控redis内部情况统计的一个工具。使用方法是：\n1  redis-cli -p 6379 MONITOR | head -n 100000 | ./redis-faina/redis-faina.py   七、压测过程中发现lua获取用户特征时，如果用户特征不存在，比如headers中的UID参数，事实上它是处于ngx.req.get_headers()函数返回值(table类型)中，如果lua提取用户特征时，找不到UID，则会扩大范围去上一级里找，此时性能会大大下降\n","date":"2016-02-22T11:15:36+08:00","permalink":"https://bg2bkk.github.io/p/openresty%E5%8E%8B%E6%B5%8B%E8%BF%87%E7%A8%8B%E5%92%8Csystemtap%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8%E4%B8%AD%E7%9A%84%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98/","title":"openresty压测过程和systemtap工具使用中的一些问题"},{"content":"shell脚本多线程应用  同事将新上线APP的一部分log交给我，让我统计下这些log中供出现了哪些deviceid  采用awk就可以实现这部分匹配和统计功能，还是比较简单的 挑战在于，这批log文件非常多非常大，单进程工作处理起来非常的慢。因此我想到了多进程方式。 以往需要使用shell来实现多进程时，采用以下模板    1 2 3 4 5  for seq; do { task }\u0026amp; done   * 当任务较为简单，并发数不多时，这招很管用。然而现在log文件有好几K个，grep处理文件非常耗CPU，上述模板将会按文件数启动进程，系统的CPU Load一跃而起，泪目。 * 此时的情况是，解决问题的思路和方向没有错，方式上还需要改进。关键在于：控制并发任务，合理使用CPU。 * 如何在shell中控制并发进程数呢，我找到这样一个帖子 * http://blog.sciencenet.cn/blog-548663-750136.html   shell脚本中控制并发任务数的大体方式是：  初始化token池，形成一定token空间，又能在为空时阻塞想拿token的进程  生成一个数组，执行任务前先从数组中获得一个元素，能够获得就继续执行，否则阻塞。数组大小最好为CPU核心数。任务执行完成后将元素放回，以供别的进程使用。 生成一个阻塞访问的管道pipe，先向管道中写入若干行，任务执行前从管道中获取token，任务结束后放回。     最终脚本如下所示  我在理解这个脚本的时候感到吃力，比如exec、read等既熟悉又陌生的指令，毕竟没写过shell脚本 后来我发现，man bash和man sh是第一手消息资料  if -p $directory中，-p是什么意思，在man bash的CONDITIONAL EXPRESSIONS中 read -u999中，-u又是什么意思，在man bash的 SHELL BUILTIN COMMANDS的read指令中 exec 999\u0026lt;\u0026gt;$Pfifo中，man bash的REDIRECTION小节中      1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49  #!/bin/sh  awk=/usr/bin/awk uniq=/usr/bin/uniq Nproc=24 #$$是进程pid Pfifo=\u0026#34;/tmp/$$.fifo\u0026#34; mkfifo $Pfifo #以999为文件描述符打开管道,\u0026lt;\u0026gt;表示可读可写 exec 999\u0026lt;\u0026gt;$Pfifo rm -f $Pfifo #向管道中写入Nproc行,作为令牌 for((i=1; i\u0026lt;=$Nproc; i++)); do echo done \u0026gt;\u0026amp;999 echo \u0026#39;\u0026#39; \u0026gt; out echo \u0026#39;\u0026#39; \u0026gt; ooo filenames=`ls *.log` for filename in $filenames; do #从管道中取出1行作为token，如果管道为空，read将会阻塞 #man bash可以知道-u是从fd中读取一行 read -u999 { #所要执行的任务 `$awk -F\u0026#39;,\u0026#39; \u0026#39;/did/ {for(i=1;i\u0026lt;=NF;i++) if($i ~ /did/) print $i i}\u0026#39; $filename | $awk -F\u0026#39;:\u0026#39; \u0026#39;{print $2}\u0026#39; | $awk -F\u0026#39;\u0026#34;\u0026#39; \u0026#39;{print $2}\u0026#39; | $uniq | $awk \u0026#39;{count[$1]++}END{for(name in count)print name \u0026gt;\u0026gt; \u0026#34;out\u0026#34;}\u0026#39;` \u0026amp;\u0026amp; { echo \u0026#34;$filenamedone\u0026#34; } || { echo \u0026#34;$filenameerror\u0026#34; } sleep 1 #归还token echo \u0026gt;\u0026amp;999 }\u0026amp; done #等待所有子进程结束 wait #关闭管道 exec 999\u0026gt;\u0026amp;- echo `$awk \u0026#39;{count[$0]++}END{for(name in count)print name}\u0026#39; out \u0026gt; ooo; awk \u0026#39;END{print NR}\u0026#39; ooo`    单进程方式处理这些log需要3个小时，而控制并发进程数的话只需要10分钟不到。  可见大部分计算资源都浪费在CPU切换上了。    参考链接 linux shell 和 lsof 等工具使用的一些tips linux shell数据输入输出的重定向分析 lsof 一切皆文件\n文件描述符与进程间通信 IO重定向和文件描述符 文件描述符与进程间通信的关联\nlinux shell cocurrency并发控制 Bash脚本实现批量作业并行化\nA script for running processes in parallel in Bash\nawk\u0026amp;sed sed\u0026amp;awk入门 一 sed\u0026amp;awk入门 二 awk用法汇总\n","date":"2016-02-19T10:54:28+08:00","permalink":"https://bg2bkk.github.io/p/linux-shell%E6%8E%A7%E5%88%B6%E5%B9%B6%E5%8F%91%E8%BF%9B%E7%A8%8B%E6%95%B0%E5%AE%9E%E8%B7%B5/","title":"linux shell控制并发进程数实践"},{"content":"实时视频流解决方案 mjpg-streamer site: https://github.com/codewithpassion/mjpg-streamer/tree/master/mjpg-streamer link: http://www.cnblogs.com/hnrainll/archive/2011/06/08/2074909.html link: http://blog.163.com/chenhongswing@126/blog/static/1335924432011825104144612/  1 2 3 4 5 6 7 8 9  #提供一个可以直接使用的demo git clone https://github.com/codewithpassion/mjpg-streamer/tree/master/mjpg-streamer cd mjpg-streamer ./mjpg_streamer -i \u0026#34;input_uvc.so -d /dev/video0 -r 640x480 -y\u0026#34; -o \u0026#34;output_http.so -w ./www\u0026#34; 127.0.0.1:8080访问主页，可以获得stream、static以及通过vlc和mplayer播放   ffmpeg+websocket播放 site: https://github.com/phoboslab/jsmpeg link: http://segmentfault.com/a/1190000000392586  1 2 3 4 5 6 7 8 9 10 11 12 13  #提供可以直接运行的demo git clone https://github.com/phoboslab/jsmpeg nodejs stream-server.js huang\t监听随机端口 Listening for MPEG Stream on http://127.0.0.1:8082/\u0026lt;secret\u0026gt;/\u0026lt;width\u0026gt;/\u0026lt;height\u0026gt; Awaiting WebSocket connections on ws://127.0.0.1:8084/ Stream Connected: 127.0.0.1:52460 size: 640x480 New WebSocket Connection (1 total) Disconnected WebSocket (0 total) ffmpeg -s 640x480 -f video4linux2 -i /dev/video0 -f mpeg1video -b 800k -r 30 http://localhost:8082/huang/640/480/\tffmpeg采集编码并发送视频流 google-chrome stream-example.html\t使用websocket在线观看   vlc视频流输出和vlc视频流播放 site: http://www.cnblogs.com/fx2008/p/4315416.html  1 2 3 4 5 6  a、关掉防火墙，至少将视频流端口开启 b、vlc --ttl 12 -vvv --color -I telnet --telnet-password videolan --rtsp-host 0.0.0.0 --rtsp-port 5554 c、通过telnet启动vlc的vlm管理中，telnet 127.0.0.1 4212，密码是刚才的videolan d、new Test vod enabled 新建一个vod，名字是Test e、setup Test input /path/video.file 给Test输入视频 f、vlc rtsp://127.0.0.1:5554/Test 启动vlc观看视频流，这里还差声音   nginx的rtmp转播 site: http://itony.me/619.html site: https://github.com/arut/nginx-rtmp-module site: http://openresty.org site: http://blog.csdn.net/leixiaohua1020/article/details/12029543 site: http://blog.csdn.net/leixiaohua1020/article/details/39803457 site: http://blog.csdn.net/fireroll/article/details/18899285  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  a、安装openresty和rtmp模块 b、配置nginx，rtmp配置块与http配置块平级 rtmp { server { listen 1935; application live1 { live on; record off; } } } c、ffmpeg转发视频流 ffmpeg -re -i xxx.mp4 -c copy -f flv rtmp://localhost:1935/live1/room1 其中的live1是应用，room1是将来要打开的节点 d、在vlc中打开视频流： rtmp://localhost:1935/live1/room1 e、ffmpeg -f video4linux2 -i /dev/video0 -c:v libx264 -an -f flv rtmp://localhost:1935/live1/room1 试试摄像头   aliyun+nginx+rtmp在线转播 site: http://blog.csdn.net/xdwyyan/article/details/43198985 注意：在nginx中配置rtmp后，reload是不够的，需要kill掉重新启动nginx。 通过sudo netstat -tlnp | grep 1935来观察nginx是否将端口打开  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37  sudo ffmpeg -i /dev/video0 -acodec acc -strict experimental -ar 44100 -ac 2 -b:a 96k -r 25 -b:v 500k -s 640*480 -f flv rtmp://101.200.124.174:1935/live1/room1 vlc rtmp://101.200.124.174:1935/live1/room1 ffmpeg -loglevel verbose -re -i xxx.mp4 -vcodec libx264 -vprofile baseline -acodec libmp3lame -ar 44100 -ac 1 -f flv rtmp://101.200.124.174:1935/hls/movie vlc http://101.200.124.174/hls/movie.m3u8 #v4l2读取摄像头，进行x264编码并将视频流发送至阿里云，进而进行hls播放 ffmpeg -f video4linux2 -s 320x240 -i /dev/video0 -vcodec libx264 -f flv rtmp://101.200.124.174:1935/hls/movie vlc http://101.200.124.174/hls/movie.m3u8 手机浏览器打开也行 #http config block rtmp { server { listen 1935; application live1 { live on; record off; } application hls{ live on; hls on; hls_path /tmp/hls; } } } #server config block location /hls { types { application/vnd.apple.mpegurl m3u8; video/mp2t ts; } root /tmp; add_header Cache-Control no-cache; }   Extra Info 防火墙设置，配置1985端口可以被外网访问 huang@vultr:~$ sudo iptables -A INPUT -m state --state NEW -m tcp -p tcp --dport 1985 -j ACCEPT  ","date":"2016-02-18T20:57:19+08:00","permalink":"https://bg2bkk.github.io/p/livestream%E7%9A%84%E5%87%A0%E7%A7%8D%E5%88%9D%E6%AD%A5%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/","title":"livestream的几种初步解决方案"}]
<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on BG2BKK Hugo Site</title>
    <link>https://bg2bkk.github.io/post/</link>
    <description>Recent content in Posts on BG2BKK Hugo Site</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 26 Feb 2016 16:15:31 +0800</lastBuildDate>
    <atom:link href="https://bg2bkk.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>redis主从复制学习笔记</title>
      <link>https://bg2bkk.github.io/post/redis%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Fri, 26 Feb 2016 16:15:31 +0800</pubDate>
      
      <guid>https://bg2bkk.github.io/post/redis%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;redis&lt;a href=&#34;http://qifuguang.me/2015/10/18/Redis%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/&#34;&gt;主从复制&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;在介绍REDIS的RDB持久化方式时，我们提到了主从复制的实现过程

&lt;ul&gt;
&lt;li&gt;第一次同步，slave发送sync命令开始同步，master生成快照全量发送给slave，快照生成之后的变更命令缓存起来，也一块发送给slave&lt;/li&gt;
&lt;li&gt;第二次及以后的同步，master收到命令后修改数据，并将数据修改后的结果同步给slave；如果此时发生断开重连情况，则重新进行第一步操作；&lt;/li&gt;
&lt;li&gt;redis-2.8版本后，如果发生断开重连，则进行增量传输，而不是全量传输&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;这里有两个值得介绍的地方

&lt;ul&gt;
&lt;li&gt;不论是否设置RDB持久化，主从复制都会产生快照&lt;/li&gt;
&lt;li&gt;redis.conf中不设置save 900 1等配置时，只是不自动产生快照，如果执行save，还是会产生快照的&lt;/li&gt;
&lt;li&gt;主从复制时，master执行完命令后会立刻将结果返回client，而不是等待同步给slave后再返回给client。这里可能会有一个不一致窗口，如果主从在master执行完指令和同步给client之间断开，这里会发生不一致现象，需要注意&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;主从复制的常见设计思路

&lt;ul&gt;
&lt;li&gt;用于保证数据持久化

&lt;ul&gt;
&lt;li&gt;master正常读写，不设置RDB或者AOF的持久化&lt;/li&gt;
&lt;li&gt;slave设置RDB和AOF方式持久化，保证数据安全&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;基于实用目的的主从复制

&lt;ul&gt;
&lt;li&gt;master设置为只写模式，将结果同步给slave&lt;/li&gt;
&lt;li&gt;slave设置为只读模式，作为系统缓存&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>redis持久化学习笔记</title>
      <link>https://bg2bkk.github.io/post/redis%E6%8C%81%E4%B9%85%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Fri, 26 Feb 2016 14:56:41 +0800</pubDate>
      
      <guid>https://bg2bkk.github.io/post/redis%E6%8C%81%E4%B9%85%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;&lt;p&gt;虽然网络上关于redis持久化的相关内容数不胜数，但是一来作为我的学习笔记，好记性不如烂笔头；二来除去官方redis之外，很多有意义的修改或补充都非常值得讨论，所以我想做一下记录。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;持久化用于重启后的数据恢复，而持久化的引入导致了redis可能产生的性能抖动&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;redis持久化的&lt;a href=&#34;http://www.cnblogs.com/zhoujinyi/archive/2013/05/26/3098508.html&#34;&gt; 两种方法 &lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;RDB方式&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;RDB方式是redis的默认持久化方式&lt;/li&gt;
&lt;li&gt;快照RDB持久化过程:

&lt;ul&gt;
&lt;li&gt;redis调用fork，产生子进程&lt;/li&gt;
&lt;li&gt;父进程继续接受用户请求；子进程负责将内存内容写入临时文件，写入完成后rename为dump文件，实现替换&lt;/li&gt;
&lt;li&gt;在子进程写内存内容期间，父进程如果要修改内存数据，os将会通过写时复制为父进程创建副本，所以此时子进程写入的仍然是fork时刻的整个数据库内容&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;不足之处在于:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;如果redis出现问题崩溃了，此时的rdb文件可能不是最新的数据，从上次RDB文件生成到redis崩溃这段时间的数据全部丢掉。&lt;/li&gt;
&lt;li&gt;产生快照时，redis最多将占用2倍于现有数据规模的内存，因此当内存占用过多时，RDB方式可能导致系统负载过高，甚至假死。（有个说法是，当redis的内存占用超过物理内存的3/5时，进行RDB主从复制就比较危险了）&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;主从复制过程&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;第一次同步

&lt;ul&gt;
&lt;li&gt;slave向master发送sync同步请求，master先dump出rdb文件，并将其全量传输给slave；master将产生rdb文件之后这段时间内的修改命令缓存起来，并发送给slave。首次同步完成。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;第二次及以后的同步实现方式：

&lt;ul&gt;
&lt;li&gt;master将变量的快照（有修改的变量）直接实时发送给slave。&lt;/li&gt;
&lt;li&gt;如果发生断开重连，则重复第一步第二步&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;reids-2.8版本之后，重连后进行第一步时，不用全量更新了。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;AOF方式&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;AOF方式持久化过程&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Append Only File&lt;/li&gt;
&lt;li&gt;Redis将每次收到的命令都追加到文件中，类似于mysql的binlog；当redis重启时重新执行文件中的所有命令来重建数据&lt;/li&gt;
&lt;li&gt;如果将所有命令不加甄别的都写入文件中，持久化文件会越来越大，比如INCR test命令执行100次，效果与SET test 100一样。此时需要进行rewrite，合并命令。&lt;/li&gt;
&lt;li&gt;Redis提供了bgrewriteaof命令，执行过程与产生RDB文件的机制类似，fork出的子进程将内存中的数据以命令的方式重写持久化文件。本质上讲，该命令是将数据库中所有数据内容以命令的方式重写进新的AOF文件&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;AOF方式之我的想法&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;AOF方式是redis在收到命名后将命令写入文件内，如果redis发送故障，重启时直接读取AOF文件重新执行命令即可恢复，可以克服RDB方式的缺点&lt;/li&gt;
&lt;li&gt;bgrewriteaof指令是对AOF方式的一次优化，执行bgrewriteaof命令时是根据此时数据库内容来写入AOF文件，并替换旧的AOF文件。这个过程与RDB快照产生方式一样&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;RDB方式和AOF方式的对比&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;RDB方式恢复起来快，而AOF方式需要一条条命令执行&lt;/li&gt;
&lt;li&gt;RDB文件不需要经过编码，是数据库内容的直接克隆，所以文件比较小；而AOF文件内是一条条命令，需要依次执行&lt;/li&gt;
&lt;li&gt;RDB文件可能会丢失部分数据，而AOF则专门解决这个问题&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;选择哪种方式&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;官方推荐：

&lt;ul&gt;
&lt;li&gt;如果想要很高的数据保障，则同时使用两种方式&lt;/li&gt;
&lt;li&gt;如果可以接受数据丢失，则仅使用RDB方式&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;通常的设计思路是

&lt;ul&gt;
&lt;li&gt;利用replication机制弥补持久化在性能和设计上的不足&lt;/li&gt;
&lt;li&gt;master上不做RDB和AOF，保证读写性能&lt;/li&gt;
&lt;li&gt;slave同时开启两种方式，保证数据安全性&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Redis数据恢复过程&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;AOF优先级高于RDB方式，如果同时配置了AOF和RDB，AOF生效&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;    void loadDataFromDisk(void) {
        long long start = ustime();
        if (server.aof_state == REDIS_AOF_ON) {
            if (loadAppendOnlyFile(server.aof_filename) == REDIS_OK)
                redisLog(REDIS_NOTICE,&amp;quot;DB loaded from append only file: %.3f seconds&amp;quot;,(float)(ustime()-start)/1000000);
        } else {
            if (rdbLoad(server.rdb_filename) == REDIS_OK) {
                redisLog(REDIS_NOTICE,&amp;quot;DB loaded from disk: %.3f seconds&amp;quot;,
                    (float)(ustime()-start)/1000000);
            } else if (errno != ENOENT) {
                redisLog(REDIS_WARNING,&amp;quot;Fatal error loading the DB: %s. Exiting.&amp;quot;,strerror(errno));
                exit(1);
            }
        }
    }
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>tcp ip协议栈在linux内核启动中的顺序</title>
      <link>https://bg2bkk.github.io/post/tcp%20ip%E5%8D%8F%E8%AE%AE%E6%A0%88%E5%9C%A8linux%E5%86%85%E6%A0%B8%E5%90%AF%E5%8A%A8%E4%B8%AD%E7%9A%84%E9%A1%BA%E5%BA%8F/</link>
      <pubDate>Wed, 24 Feb 2016 23:13:13 +0800</pubDate>
      
      <guid>https://bg2bkk.github.io/post/tcp%20ip%E5%8D%8F%E8%AE%AE%E6%A0%88%E5%9C%A8linux%E5%86%85%E6%A0%B8%E5%90%AF%E5%8A%A8%E4%B8%AD%E7%9A%84%E9%A1%BA%E5%BA%8F/</guid>
      <description>

&lt;p&gt;在我尝试从kernel中深入了解TCP IP协议栈时，遇到了难题。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;我选择的是linux-2.4.20 kernel，理由如下：

1. 首先是&amp;lt;TCP/IP Architecture, Design, And Implementation In Linux&amp;gt;一书采用的是该版本，会有按图索骥的效果。
2. 第二个理由，正如书中所说的，TCP/IP协议栈在2.4内核中就已经基本成型，而根据我实际对比，2.4.20内核与4.4.1内核在TCP/IP实现的框架上大体是相同的，区别是2.6 kernel以后完全将VFS中的各组件namespace化，另外是一些高版本内核引入的措施（比如对比net/socket.c中sock_create函数）。
3. 第三个理由是，linux-2.4 kernel的代码还没有开始爆炸，适合初学者入门，也适合我这样学力不足的人。

采用linux-2.4 kernel的不足之处在于，版本较老，想亲自动手实验，需要做一些兼容性的准备。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我搜到了这样一篇帖子，&lt;a href=&#34;http://www.skyfree.org/linux/kernel_network/startup.html，&#34;&gt;http://www.skyfree.org/linux/kernel_network/startup.html，&lt;/a&gt; 收益颇深。解决了我的疑问，用我最能接受的方式，先从kernel启动的函数说起，然后调用到我能看到的net/socket.c中的函数；然后又通过修改kernel源码添加标记，打印运行log来标志函数执行；然后通过讲解module_init注册的静态模块是如何加进内核可执行文件里的，然后编译出linux.map文件，进一步确定函数执行顺序。这个方式让我非常容易接受，也很感慨写博客的人功力之深，通篇干货没有废话；更感慨的是，这个帖子写于2001左右，当时进行kernel修改还是比较容易的事情，现在的kernel代码越来越庞大，初学者为此望而却步，很难入手；新人难以入门的问题，近年来也多有讨论。&lt;/p&gt;

&lt;p&gt;那我就先把原作者的文章翻译过来，再继续下一步工作吧。&lt;/p&gt;

&lt;h2 id=&#34;先说结论:45e9e7b94f065f59195b43c12d821283&#34;&gt;先说结论&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;kernel启动时，第一个与network有关的函数是sock_init()，用来向kernel注册sock文件系统并挂载，以及加载其他模块，比如netfilter&lt;/li&gt;
&lt;li&gt;loopback设备随后被初始化，因为该设备比较简单。&lt;strong&gt;&lt;em&gt;drivers/net/loopback.c&lt;/em&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;dummy 和 Ethernet 设备随后被初始化&lt;/li&gt;
&lt;li&gt;TCP/IP协议栈是在inet_init()中初始化的&lt;/li&gt;
&lt;li&gt;Unix Domain Socket是在af_unix_init()中初始化的。1~5步按时间顺序排列。&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;linux-kernel-2-4的入口函数:45e9e7b94f065f59195b43c12d821283&#34;&gt;Linux Kernel 2.4的入口函数&lt;/h2&gt;

&lt;p&gt;1.经过基本硬件设置后，启动代码(定义在head.S中)调用 /init/main.c 的 start_kernel()函数&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;#arch/i386/kernel/head.S
...
    call SYMBOL_NAME(start_kernel)
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2.sock_init()调用过程，向系统注册sock文件系统并挂载&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sock_init()将向系统注册sock文件系统
do_initcalls()中循环调用所有MODULE_INIT()的模块，包括系统中的inet_init和af_unix_init，至于如何关联起来的，稍后会有介绍。
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;asmlinkage void __init start_kernel(void)
{
...
        printk(linux_banner);	// &amp;quot;linux_banner&amp;quot; is defined in init/version.c (W.N.).
...
...     // Dozens of initialize routines
...
        kernel_thread(init, NULL, CLONE_FS | CLONE_FILES | CLONE_SIGNAL);
...
        cpu_idle();
}

static int init(void * unused)
{
...
        do_basic_setup();
...
        execve(&amp;quot;/sbin/init&amp;quot;,argv_init,envp_init);
...
}

static void __init do_basic_setup(void)
{
...
        sock_init();		// net/socket.c (SEE BELOW)
...
        do_initcalls();
...
}

static void __init do_initcalls(void)
{
        initcall_t *call;

        call = &amp;amp;__initcall_start;
        do {
                (*call)();
                call++;
        } while (call &amp;lt; &amp;amp;__initcall_end);
...
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;3.sock_init()的内容&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;欢迎信息printk()
清空协议栈数组，此时系统中没有任何协议
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;...

/*
 *      The protocol list. Each protocol is registered in here.
 */

static struct net_proto_family *net_families[NPROTO];	// Current NPROTO is defined as 32
																// in &amp;lt;linux/net.h&amp;gt; (W.N.).
...

void __init sock_init(void)
{
        int i;

        printk(KERN_INFO &amp;quot;Linux NET4.0 for Linux 2.4\n&amp;quot;);
        printk(KERN_INFO &amp;quot;Based upon Swansea University Computer Society NET3.039\n&amp;quot;);

        /*
         *      Initialize all address (protocol) families.
         */

        #清空所有协议
        for (i = 0; i &amp;lt; NPROTO; i++)
                net_families[i] = NULL;
...
        /*
         *      Initialize the protocols module.
         */

        #注册文件系统并挂载，sock_fs_type之前被初始化
        register_filesystem(&amp;amp;sock_fs_type);
        sock_mnt = kern_mount(&amp;amp;sock_fs_type);

        /* The real protocol initialization is performed when
         *  do_initcalls is run.
         */
...
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;4.do_initcalls()中的调用函数&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#init/main.c

static void __init do_initcalls(void)
{
        initcall_t *call;

        call = &amp;amp;__initcall_start;
        do {
                #添加打印语句，dmesg命令可以输出启动结果
                printk(KERN_INFO &amp;quot;+++ do_initcall: %08X\n&amp;quot;, call);	// Dump the entry address of initializer (W.N.).

                (*call)();
                call++;
        } while (call &amp;lt; &amp;amp;__initcall_end);

        /* Make sure there is no pending stuff from the initcall sequence */
        flush_scheduled_tasks();
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;同时也修改loopback_init函数&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#drivers/net/loopback.c

int __init loopback_init(struct net_device *dev)
{
        #添加打印语句
        printk(KERN_INFO &amp;quot;=== Executing loopback_init ===\n&amp;quot;);

        dev-&amp;gt;mtu                = PAGE_SIZE - LOOPBACK_OVERHEAD;
        dev-&amp;gt;hard_start_xmit    = loopback_xmit;
        dev-&amp;gt;hard_header        = eth_header;
        dev-&amp;gt;hard_header_cache  = eth_header_cache;
        dev-&amp;gt;header_cache_update= eth_header_cache_update;
        dev-&amp;gt;hard_header_len    = ETH_HLEN;             /* 14                   */
        dev-&amp;gt;addr_len           = ETH_ALEN;             /* 6                    */
...
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;重新编译内核，替换并重启，dmesg的输出结果为：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;Linux version 2.4.3 (root@mebius) (gcc version 2.95.3 20010315 (Debian release)) #9 Tue Apr 3 17:37:
44 JST 2001
BIOS-provided physical RAM map:
 BIOS-e820: 0000000000000000 - 000000000009f800 (usable)
 BIOS-e820: 000000000009f800 - 00000000000a0000 (reserved)
 BIOS-e820: 00000000000ebc00 - 0000000000100000 (reserved)
 BIOS-e820: 0000000000100000 - 0000000007ff0000 (usable)
 BIOS-e820: 0000000007ff0000 - 0000000007fffc00 (ACPI data)
 BIOS-e820: 0000000007fffc00 - 0000000008000000 (ACPI NVS)
 BIOS-e820: 00000000fff80000 - 0000000100000000 (reserved)
On node 0 totalpages: 32752
zone(0): 4096 pages.
zone(1): 28656 pages.
zone(2): 0 pages.
Kernel command line: root=/dev/hda1 mem=131008K
Initializing CPU#0
Detected 333.350 MHz processor.
Console: colour VGA+ 80x25
Calibrating delay loop... 665.19 BogoMIPS
Memory: 126564k/131008k available (1076k kernel code, 4056k reserved, 387k data, 184k init, 0k highm
em)
Dentry-cache hash table entries: 16384 (order: 5, 131072 bytes)
Buffer-cache hash table entries: 4096 (order: 2, 16384 bytes)
Page-cache hash table entries: 32768 (order: 5, 131072 bytes)
Inode-cache hash table entries: 8192 (order: 4, 65536 bytes)
CPU: Before vendor init, caps: 0183f9ff 00000000 00000000, vendor = 0
CPU: L1 I cache: 16K, L1 D cache: 16K
CPU: L2 cache: 256K
Intel machine check architecture supported.
Intel machine check reporting enabled on CPU#0.
CPU: After vendor init, caps: 0183f9ff 00000000 00000000 00000000
CPU: After generic, caps: 0183f9ff 00000000 00000000 00000000
CPU: Common caps: 0183f9ff 00000000 00000000 00000000
CPU: Intel Mobile Pentium II stepping 0a
Enabling fast FPU save and restore... done.
Checking &#39;hlt&#39; instruction... OK.
POSIX conformance testing by UNIFIX
PCI: PCI BIOS revision 2.10 entry at 0xfd9be, last bus=0
PCI: Using configuration type 1
PCI: Probing PCI hardware
PCI: Using IRQ router PIIX [8086/7110] at 00:07.0
  got res[10000000:10000fff] for resource 0 of Ricoh Co Ltd RL5c475
Limiting direct PCI/PCI transfers.

#sock_init()的运行log
Linux NET4.0 for Linux 2.4				// Message from sock_init()
Based upon Swansea University Computer Society NET3.039
#sock_init()运行结束

#do_initcalls()中的每个initcall
+++ do_initcall: C029F4E8				// do_initcalls() START
+++ do_initcall: C029F4EC
+++ do_initcall: C029F4F0				// apm_init() in arch/i386/kernel/kernel.o
apm: BIOS version 1.2 Flags 0x03 (Driver version 1.14)
+++ do_initcall: C029F4F4
+++ do_initcall: C029F4F8
+++ do_initcall: C029F4FC				// kswapd_init() in mm/mm.o
Starting kswapd v1.8
+++ do_initcall: C029F500
+++ do_initcall: C029F504
+++ do_initcall: C029F508
+++ do_initcall: C029F50C
+++ do_initcall: C029F510
+++ do_initcall: C029F514
+++ do_initcall: C029F518
+++ do_initcall: C029F51C
+++ do_initcall: C029F520
+++ do_initcall: C029F524
+++ do_initcall: C029F528				// partition_setup() in fs/fs.o
pty: 256 Unix98 ptys configured
block: queued sectors max/low 84058kB/28019kB, 256 slots per queue
RAMDISK driver initialized: 16 RAM disks of 8000K size 1024 blocksize
Uniform Multi-Platform E-IDE driver Revision: 6.31
ide: Assuming 33MHz system bus speed for PIO modes; override with idebus=xx
PIIX4: IDE controller on PCI bus 00 dev 39
PIIX4: chipset revision 1
PIIX4: not 100% native mode: will probe irqs later
    ide0: BM-DMA at 0xfc90-0xfc97, BIOS settings: hda:DMA, hdb:pio
    ide1: BM-DMA at 0xfc98-0xfc9f, BIOS settings: hdc:pio, hdd:pio
hda: TOSHIBA MK8113MAT, ATA DISK drive
ide0 at 0x1f0-0x1f7,0x3f6 on irq 14
hda: 16006410 sectors (8195 MB), CHS=996/255/63, UDMA(33)
Partition check:
 hda: hda1 hda2 hda3 hda4 &amp;lt; hda5 hda6 hda7 hda8 hda9 hda10 &amp;gt;
Floppy drive(s): fd0 is 1.44M
FDC 0 is a National Semiconductor PC87306

#在loopback_init()中添加printk函数的结果
=== Executing loopback_init ===			// loopback initialization is here!

+++ do_initcall: C029F52C				// ext2_fs() in fs/fs.o
+++ do_initcall: C029F530
+++ do_initcall: C029F534
+++ do_initcall: C029F538
+++ do_initcall: C029F53C
+++ do_initcall: C029F540
loop: loaded (max 8 devices)
+++ do_initcall: C029F544
Serial driver version 5.05 (2000-12-13) with MANY_PORTS SHARE_IRQ SERIAL_PCI enabled
ttyS00 at 0x03f8 (irq = 4) is a 16550A
+++ do_initcall: C029F548				// dummy_init_module() in drivers/net/net.o
+++ do_initcall: C029F54C				// rtl8139_init_module() in drivers/net/net.o
8139too Fast Ethernet driver 0.9.15c loaded
PCI: Found IRQ 9 for device 00:03.0
PCI: The same IRQ used for device 00:07.2
eth0: RealTek RTL8139 Fast Ethernet at 0xc8800c00, 08:00:1f:06:79:20, IRQ 9
eth0:  Identified 8139 chip type &#39;RTL-8139B&#39;
+++ do_initcall: C029F550
+++ do_initcall: C029F554
+++ do_initcall: C029F558
+++ do_initcall: C029F55C
+++ do_initcall: C029F560

#inet_init()的initcall结果
+++ do_initcall: C029F564				// inet_init() in net/network.o
NET4: Linux TCP/IP 1.0 for NET4.0
IP Protocols: ICMP, UDP, TCP
IP: routing cache hash table of 512 buckets, 4Kbytes
TCP: Hash tables configured (established 8192 bind 8192)

#af_unix_inet()的initcall结果
+++ do_initcall: C029F568				// af_unix_init() in net/network.o
NET4: Unix domain sockets 1.0/SMP for Linux NET4.0.
+++ do_initcall: C029F56C
+++ do_initcall: C029F570
+++ do_initcall: C029F574				// atalk_init() in net/network.o
NET4: AppleTalk 0.18a for Linux NET4.0	// do_initcalls() END
fatfs: bogus cluster size
reiserfs: checking transaction log (device 03:01) ...
Using r5 hash to sort names
ReiserFS version 3.6.25
VFS: Mounted root (reiserfs filesystem) readonly.
Freeing unused kernel memory: 184k freed
Adding Swap: 128516k swap-space (priority -1)
eth0: Setting half-duplex based on auto-negotiated partner ability 0000.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;5.initcalls的实现机制&lt;/p&gt;

&lt;p&gt;首先我们可以看到每个module都有使用module_init宏。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#net/ipv4/af_inet.c

static int __init inet_init(void)
{
...
        printk(KERN_INFO &amp;quot;NET4: Linux TCP/IP 1.0 for NET4.0\n&amp;quot;);
...
}

module_init(inet_init);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;__init宏和 module_init宏在 &lt;em&gt;include/linux/init.h&lt;/em&gt; 中定义&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#ifndef MODULE
#ifndef __ASSEMBLY__
...
typedef int (*initcall_t)(void);
...
extern initcall_t __initcall_start, __initcall_end;
#define __initcall(fn)                                                          \
        static initcall_t __initcall_##fn __init_call = fn
...
#endif /* __ASSEMBLY__ */

/*
 * Mark functions and data as being only used at initialization
 * or exit time.
 */
#define __init          __attribute__ ((__section__ (&amp;quot;.text.init&amp;quot;)))
...
#define __init_call     __attribute__ ((unused,__section__ (&amp;quot;.initcall.init&amp;quot;)))
...
/**
 * module_init() - driver initialization entry point
 * @x: function to be run at kernel boot time or module insertion
 *
 * module_init() will add the driver initialization routine in
 * the &amp;quot;__initcall.int&amp;quot; code segment if the driver is checked as
 * &amp;quot;y&amp;quot; or static, or else it will wrap the driver initialization
 * routine with init_module() which is used by insmod and
 * modprobe when the driver is used as a module.
 */
#define module_init(x)  __initcall(x);
...
#else // MODULE
...
#define __init
...
#define __initcall(fn)
...
#define module_init(x) \
        int init_module(void) __attribute__((alias(#x))); \
        extern inline __init_module_func_t __init_module_inline(void) \
        { return x; }
...
#endif // MODULE
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;* init.h中的#define MODULE是在Makefile中的 -DMODULE 设置的，表示可以动态添加MODULE
* 目前 CONFIG_INET (/arch/i386/defconfig) 不是 可选module （M），而是静态编译进内核的（y）。静态模块由init.h中的#ifndef MODULE块预处理，而可动态加载的模块（M）则会调用 #else //MODULE 后的初始化代码
* 所以经过预编译后，inet_init()函数将由上述代码的#ifndef MODULE 预处理为
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;    #include/linux/init.h
    static int __attribute__ ((__section__ (&amp;quot;.text.init&amp;quot;))) inet_init(void)
    {
    ...
            printk(KERN_INFO &amp;quot;NET4: Linux TCP/IP 1.0 for NET4.0\n&amp;quot;);
    ...
    }
    
    initcall_t __initcall_inet_init  __attribute__ ((unused,__section__ (&amp;quot;.initcall.init&amp;quot;))) = inet_init;
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;这个扩展过程意味着：

&lt;ul&gt;
&lt;li&gt;inet_init()函数的代码段text code将编译进kernel可执行文件的&lt;strong&gt;&lt;em&gt;.text.init&lt;/em&gt;&lt;/strong&gt;段中，这种机制的目的是kernel启动，注册模块后能够释放所占用的内存&lt;/li&gt;
&lt;li&gt;预处理后的&lt;strong&gt;&lt;em&gt;__initcall_inet_init&lt;/em&gt;&lt;/strong&gt;作为inet_init()函数的入口，将被存储在kernel可执行文件的 &lt;strong&gt;&lt;em&gt;.initcall.init&lt;/em&gt;&lt;/strong&gt; 段中。

&lt;ul&gt;
&lt;li&gt;注意这个宏定义是static类型的，所以我们并不能确定这个宏定义的结果是否在kernel的全局符号表中。（只有全局变量才在符号表中）&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;为了能够一探究竟，&lt;strong&gt;&lt;em&gt;移除该宏定义的static标志&lt;/em&gt;&lt;/strong&gt;，然后&lt;strong&gt;&lt;em&gt;_&lt;em&gt;initcall&lt;/em&gt;&lt;/em&gt;&lt;/strong&gt; ***这些入口就是全局变量了，然后我们就能在内核编译后的符号表中看到这些入口函数。

&lt;ul&gt;
&lt;li&gt;注意如果这些入口函数不是static作用域后，会导致一些链接错误，原因是命名冲突，比如netfilter中有类似命名&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Let&amp;rsquo;s hack the kernel!!!&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;5.如何从内部观察linux kernel&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;* linux kernel只是一个ELF可执行目标文件，和/bin/ls之类的可执行文件没有区别
* 所以作为kernel ELF文件，vmlinux可以通过nm、objdump和readelf等工具观察
* 默认情况下，linux kernel的顶层Makefile编译成功后将生成System.map文件，以方便调试，而这个文件不过是一个符号表。所以我向这个编译添加&amp;quot;--cref -Map linux.map&amp;quot;选项，可以生成一个包含更多信息的符号表
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#Makefile
#添加 --cref -Map linux.map 选项
vmlinux: $(CONFIGURATION) init/main.o init/version.o linuxsubdirs
        $(LD) $(LINKFLAGS) $(HEAD) init/main.o init/version.o \
                --start-group \
                $(CORE_FILES) \
                $(DRIVERS) \
                $(NETWORKS) \
                $(LIBS) \
                --end-group \
                --cref -Map linux.map \
                -o vmlinux
        $(NM) vmlinux | grep -v &#39;\(compiled\)\|\(\.o$$\)\|\( [aUw] \)\|\(\.\.ng$$\)\|\(LASH[RL]DI\)&#39;
 | sort &amp;gt; System.map
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;* make vmlinux编译kernle源码，生成vmlinux和linux.map，通过objdump -h vmlinux查看各段信息
* 可以看到***.text.init***段和***.initcall.init***段
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#objdump -h vmlinux
vmlinux:     file format elf32-i386

Sections:
Idx Name          Size      VMA       LMA       File off  Algn
  0 .text         0010bf68  c0100000  c0100000  00001000  2**4
                  CONTENTS, ALLOC, LOAD, READONLY, CODE
  1 .text.lock    00001130  c020bf68  c020bf68  0010cf68  2**2
                  CONTENTS, ALLOC, LOAD, READONLY, CODE
  2 .rodata       0004407c  c020d0a0  c020d0a0  0010e0a0  2**5
                  CONTENTS, ALLOC, LOAD, READONLY, DATA
  3 .kstrtab      000062fe  c0251120  c0251120  00152120  2**5
                  CONTENTS, ALLOC, LOAD, READONLY, DATA
  4 __ex_table    00001418  c0257420  c0257420  00158420  2**2
                  CONTENTS, ALLOC, LOAD, READONLY, DATA
  5 __ksymtab     00001d68  c0258838  c0258838  00159838  2**2
                  CONTENTS, ALLOC, LOAD, READONLY, DATA
  6 .data         00013abc  c025a5a0  c025a5a0  0015b5a0  2**5
                  CONTENTS, ALLOC, LOAD, DATA
  7 .data.init_task 00002000  c0270000  c0270000  00170000  2**5
                  CONTENTS, ALLOC, LOAD, DATA
  8 .text.init    0000f56c  c0272000  c0272000  00172000  2**4
                  CONTENTS, ALLOC, LOAD, READONLY, CODE
  9 .data.init    0001de60  c0281580  c0281580  00181580  2**5
                  CONTENTS, ALLOC, LOAD, DATA
 10 .setup.init   00000108  c029f3e0  c029f3e0  0019f3e0  2**2
                  CONTENTS, ALLOC, LOAD, DATA
 11 .initcall.init 00000090  c029f4e8  c029f4e8  0019f4e8  2**2
                  CONTENTS, ALLOC, LOAD, DATA
 12 .data.page_aligned 00000800  c02a0000  c02a0000  001a0000  2**5
                  CONTENTS, ALLOC, LOAD, DATA
 13 .data.cacheline_aligned 00001fe0  c02a0800  c02a0800  001a0800  2**5
                  CONTENTS, ALLOC, LOAD, DATA
 14 .bss          0002b3d8  c02a27e0  c02a27e0  001a27e0  2**5
                  ALLOC
 15 .comment      00003bc9  00000000  00000000  001a27e0  2**0
                  CONTENTS, READONLY
 16 .note         00001a90  00000000  00000000  001a63a9  2**0
                  CONTENTS, READONLY
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;* 如下是linux.map的文件内容
* __initcall_start 和 __initcall_end 定义了***.initcall.init***段的起始和结束，并出现在do_initcalls()函数中
* 之前将__initcall()宏的static关键字去掉了，所以__initcall_***这些入口函数地址，比如__initcall_inet_init就全局可见了，我们可以在文件中看到内核启动过程
* 内核开发者们总是喜欢用grep等工具来找某个函数在哪个文件中，而我们在linux.map中可以看到每个函数在哪个模块中，只需要less linux.map就可以了
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;     0xc029f4e8                __initcall_start=.

.initcall.init  0xc029f4e8       0x90
 *(.initcall.init)
 .initcall.init
                0xc029f4e8        0xc arch/i386/kernel/kernel.o
                0xc029f4e8                __initcall_dmi_scan_machine
                0xc029f4ec                __initcall_cpuid_init
                0xc029f4f0                __initcall_apm_init
 .initcall.init
                0xc029f4f4        0x4 kernel/kernel.o
                0xc029f4f4                __initcall_uid_cache_init
 .initcall.init
                0xc029f4f8        0xc mm/mm.o
                0xc029f4f8                __initcall_kmem_cpucache_init
                0xc029f4fc                __initcall_kswapd_init
                0xc029f500                __initcall_init_shmem_fs
 .initcall.init
                0xc029f504       0x3c fs/fs.o
                0xc029f504                __initcall_bdflush_init
                0xc029f508                __initcall_init_pipe_fs
                0xc029f50c                __initcall_fasync_init
                0xc029f510                __initcall_filelock_init
                0xc029f514                __initcall_dnotify_init
                0xc029f518                __initcall_init_misc_binfmt
                0xc029f51c                __initcall_init_script_binfmt
                0xc029f520                __initcall_init_elf_binfmt
                0xc029f524                __initcall_init_proc_fs
                0xc029f528                __initcall_partition_setup
                0xc029f52c                __initcall_init_ext2_fs
                0xc029f530                __initcall_init_fat_fs
                0xc029f534                __initcall_init_msdos_fs
                0xc029f538                __initcall_init_iso9660_fs
                0xc029f53c                __initcall_init_reiserfs_fs
 .initcall.init
                0xc029f540        0x4 drivers/block/block.o
                0xc029f540                __initcall_loop_init
 .initcall.init
                0xc029f544        0x4 drivers/char/char.o
                0xc029f544                __initcall_rs_init
 .initcall.init
                0xc029f548        0x8 drivers/net/net.o
                0xc029f548                __initcall_dummy_init_module
                0xc029f54c                __initcall_rtl8139_init_module
 .initcall.init
                0xc029f550        0x4 drivers/ide/idedriver.o
                0xc029f550                __initcall_ide_cdrom_init
 .initcall.init
                0xc029f554        0x4 drivers/cdrom/driver.o
                0xc029f554                __initcall_cdrom_init
 .initcall.init
                0xc029f558        0x4 drivers/pci/driver.o
                0xc029f558                __initcall_pci_proc_init
 .initcall.init
                0xc029f55c       0x1c net/network.o
                0xc029f55c                __initcall_p8022_init
                0xc029f560                __initcall_snap_init
                0xc029f564                __initcall_inet_init
                0xc029f568                __initcall_af_unix_init
                0xc029f56c                __initcall_netlink_proto_init
                0xc029f570                __initcall_packet_init
                0xc029f574                __initcall_atalk_init
                0xc029f578                __initcall_end=.
                0xc02a0000                .=ALIGN(0x1000)
                0xc029f578                __init_end=.
                0xc02a0000                .=ALIGN(0x1000)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;linux.map中的信息可以帮助我们和dmesg的输出信息对照起来，可以看到内核中每个我们感兴趣的静态模块的加载顺序。&lt;br /&gt;
以上工作都是基于linux-2.4内核实现的，新版本内核该如何实现呢？&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>openresty压测过程和systemtap工具使用中的一些问题</title>
      <link>https://bg2bkk.github.io/post/openresty%E5%8E%8B%E6%B5%8B%E8%BF%87%E7%A8%8B%E5%92%8Csystemtap%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8%E4%B8%AD%E7%9A%84%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98/</link>
      <pubDate>Mon, 22 Feb 2016 11:15:36 +0800</pubDate>
      
      <guid>https://bg2bkk.github.io/post/openresty%E5%8E%8B%E6%B5%8B%E8%BF%87%E7%A8%8B%E5%92%8Csystemtap%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8%E4%B8%AD%E7%9A%84%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98/</guid>
      <description>

&lt;h2 id=&#34;一-tegine编译-高版本的httpluamodule:dab12220e12920eb4ab0fdd954035a76&#34;&gt;一、tegine编译+高版本的httpluamodule&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;tengine-2.1.0的ngx_lua模块随着tengine软件发布，和以往版本的tengine不一样。&lt;/li&gt;
&lt;li&gt;tengine自带的ngx_lua模块版本太老，与openresty相比要差几个版本，导致openresty里的一些好的软件工具不可用。

&lt;ul&gt;
&lt;li&gt;编译tengine+lua时需要手动指定ngx_lua模块和LuaJIT2.1

&lt;ul&gt;
&lt;li&gt;新版本ngx_lua能弥补openrestysystemtap在probe某些函数时的错误

&lt;ul&gt;
&lt;li&gt;关键脚本ngx-lua-exec-time.sxx中第58行@pfunc(ngx_http_lua_free_fake_request)函数找不到&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;使用LuaJIT2.1能解决lua执行时的stap问题。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;#关键脚本stapxx/samples/ngx-lua-exec-time.sxx中第58行@pfunc(ngx_http_lua_free_fake_request)函数找不到的问题：
2&amp;gt; sudo ./samples/ngx-lua-exec-time.sxx -x 11070
semantic error: while resolving probe point: identifier &#39;process&#39; at &amp;lt;input&amp;gt;:58:7
        source:       process(&amp;quot;/usr/local/nginx/sbin/nginx&amp;quot;).function(&amp;quot;ngx_http_lua_free_fake_request&amp;quot;)
                      ^

semantic error: no match (similar functions: ngx_http_lua_get_request, ngx_http_create_request, ngx_http_free_request, ngx_http_lua_post_subrequest, ngx_http_scgi_create_request)
Pass 2: analysis failed.  [man error::pass2]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;#tegine编译选项
CFLAGS=&amp;quot;-g -O2&amp;quot; ./configure  --add-module=/path/ngx_openresty-1.7.10.1/bundle/ngx_lua-0.9.15/ --with-luajit-lib=/usr/local/lib/ --with-luajit-inc=/usr/local/include/luajit-2.1/ --with-ld-opt=-Wl,-rpath,/usr/local/lib

make -j16

#新版本ngx_lua在openresty的bundle的ngx_lua-0.9.15/里，也可以从https://github.com/openresty/lua-nginx-module获得

#LuaJIT2.1的源代码也在bundle里，也可以从https://github.com/openresty/luajit2获得。

LuaJIT2.1的编译选项是：
make CCDEBUG=-g -B -j8
make -j16
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;二-axel下载工具和debuginfo-centos-org:dab12220e12920eb4ab0fdd954035a76&#34;&gt;二、axel下载工具和debuginfo.centos.org&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;我们在安装kernel的debuginfo包的时候，由于只有debuginfo.centos.org上面有rpm包，所以yum源设置为它，但是在国内访问实在是慢，因此推荐使用axel或者mwget下载。mwget顾名思义是多线程的wget工具，下载rpm包非常快，值得推荐。&lt;/li&gt;
&lt;li&gt;当我们为了系统中的systemtap安装时，需要安装kernel-debuginfo，这时需要注意严格按照自己的kernel版本来，centos系的需要注意是否2.6.32-431.11.2.el6.toa.2.x86_64后面有toa之类的&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;#debian系的可以使用dpkg -l linux-image*命令，查看具体内核版本；

huang@ThinkPad-X220:~$ dpkg -l linux-image*
Desired=Unknown/Install/Remove/Purge/Hold
| Status=Not/Inst/Conf-files/Unpacked/halF-conf/Half-inst/trig-aWait/Trig-pend
|/ Err?=(none)/Reinst-required (Status,Err: uppercase=bad)
||/ Name                   Version          Architecture     Description
+++-======================-================-================-==================================================
un  linux-image            &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;           (no description available)
un  linux-image-3.0        &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;           (no description available)
ii  linux-image-3.13.0-24- 3.13.0-24.47     amd64            Linux kernel image for version 3.13.0 on 64 bit x8
ii  linux-image-3.13.0-24- 3.13.0-24.47     amd64            Linux kernel debug image for version 3.13.0 on 64 
ii  linux-image-extra-3.13 3.13.0-24.46     amd64            Linux kernel extra modules for version 3.13.0 on 6
ii  linux-image-generic    3.13.0.24.28     amd64            Generic Linux kernel image

#特别要注意的是3.13.0-24.46、 47、 48，小版本很重要的。
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;三-centos6-4的gcc版本过低导致的问题:dab12220e12920eb4ab0fdd954035a76&#34;&gt;三、centos6.4的gcc版本过低导致的问题&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;在使用stapxx的工具追踪nginx运行情况时，发现有如下情况，比如：&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;2&amp;gt; sudo ./samples/ngx-rewrite-latency-distr.sxx -x 11070
semantic error: not accessible at this address [man error::dwarf] (0x44a53b, dieoffset: 0x13a891): identifier &#39;$r&#39; at &amp;lt;input&amp;gt;:67:9
        source:     r = $r
                        ^

Pass 2: analysis failed.  [man error::pass2]

# 这个r是没有问题的，在nginx-systemtap-toolkit/ngx-active-reqs中有类似定义：
my $c = &#39;@cast(c, &amp;quot;ngx_connection_t&amp;quot;)&#39;;
my $r = &#39;@cast(r, &amp;quot;ngx_http_request_t&amp;quot;)&#39;;
my $u = &#39;@cast(u, &amp;quot;ngx_http_upstream_t&amp;quot;)&#39;;
my $p = &#39;@cast(p, &amp;quot;ngx_event_pipe_t&amp;quot;)&#39;;
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;产生原因&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;tengine的DWARF信息不完整

&lt;ul&gt;
&lt;li&gt;低版本的gcc在O2时优化掉很多东西，而高版本gcc智能的多&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;解决方法有两种&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;一种方法是将gcc的编译优化选项降低为O0，以前是O2，则这个ngx_http_request_t的符号，即nginx的DWARF信息可以保留下来。&lt;/li&gt;
&lt;li&gt;另一种方法是升级gcc，考虑到在线上服务器升级gcc不太好，这里介绍一种&lt;a href=&#34;http://ask.xmodulo.com/upgrade-gcc-centos.html&#34;&gt;暂时升级gcc的办法&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ sudo wget http://people.centos.org/tru/devtools-1.1/devtools-1.1.repo -P /etc/yum.repos.d
$ sudo sh -c &#39;echo &amp;quot;enabled=1&amp;quot; &amp;gt;&amp;gt; /etc/yum.repos.d/devtools-1.1.repo&#39;
$ sudo yum install devtoolset-1.1
$ scl enable devtoolset-1.1 bash
$ gcc --version
# 通过devtoolset工具可以暂时提高gcc版本，而不更改之前服务器的配置，这个很有效果，高版本的gcc会智能保留symbol。
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;四-apache的压测工具ab升级高版本:dab12220e12920eb4ab0fdd954035a76&#34;&gt;四、apache的压测工具ab升级高版本&lt;/h2&gt;

&lt;p&gt;在压测过程中，我们想微观的通过tcpdump抓包分析通信过程。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;发现ab工具在发起keepalive请求时，在完成-n的请求数后额外的发出一个请求，随后又发出F包关闭连接，导致通信过程多出一次。&lt;/li&gt;
&lt;li&gt;已有的httpd 2.3自带的ab工具有这个bug，升级httpd2.4后这个问题修复。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;五-tcpdump抓取fin包:dab12220e12920eb4ab0fdd954035a76&#34;&gt;五、tcpdump抓取fin包&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# tcp包里有个flags字段表示包的类型，tcpdump可以根据该字段抓取相应类型的包：
# tcp[13] 就是 TCP flags (URG,ACK,PSH,RST,SYN,FIN)
# Unskilled 32
# Attackers 16
# Pester     8
# Real       4
# Security   2
# Folks      1

#抓取fin包：
tcpdump -ni any port 9001 and &#39;tcp[13] &amp;amp; 1 != 0 &#39; -s0  -w fin.cap -vvv
#抓取syn+fin包：
tcpdump -ni any port 9001 and &#39;tcp[13] &amp;amp; 3 != 0 &#39; -s0  -w syn_fin.cap -vvv
#抓取rst包：
tcpdump -ni any port 9001 and &#39;tcp[13] &amp;amp; 4 != 0 &#39; -s0  -w rst.cap -vvv
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;http://babyhe.blog.51cto.com/1104064/1395489&#34;&gt;参考链接&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>linux shell控制并发进程数实践</title>
      <link>https://bg2bkk.github.io/post/shell%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%AE%9E%E8%B7%B5/</link>
      <pubDate>Fri, 19 Feb 2016 10:54:28 +0800</pubDate>
      
      <guid>https://bg2bkk.github.io/post/shell%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%AE%9E%E8%B7%B5/</guid>
      <description>

&lt;h1 id=&#34;shell脚本多线程应用:98445e76c0e56f8e093561726589792e&#34;&gt;shell脚本多线程应用&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;同事将新上线APP的一部分log交给我，让我统计下这些log中供出现了哪些deviceid

&lt;ul&gt;
&lt;li&gt;采用awk就可以实现这部分匹配和统计功能，还是比较简单的&lt;/li&gt;
&lt;li&gt;挑战在于，这批log文件非常多非常大，单进程工作处理起来非常的慢。因此我想到了多进程方式。&lt;/li&gt;
&lt;li&gt;以往需要使用shell来实现多进程时，采用以下模板&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;for seq; do
    {
        task
    }&amp;amp;
done
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;* 当任务较为简单，并发数不多时，这招很管用。然而现在log文件有好几K个，grep处理文件非常耗CPU，上述模板将会按文件数启动进程，系统的CPU Load一跃而起，泪目。
* 此时的情况是，解决问题的思路和方向没有错，方式上还需要改进。关键在于：控制并发任务，合理使用CPU。
* 如何在shell中控制并发进程数呢，我找到这样一个帖子
* http://blog.sciencenet.cn/blog-548663-750136.html
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;shell脚本中控制并发任务数的大体方式是：

&lt;ul&gt;
&lt;li&gt;初始化token池，形成一定token空间，又能在为空时阻塞想拿token的进程

&lt;ul&gt;
&lt;li&gt;生成一个数组，执行任务前先从数组中获得一个元素，能够获得就继续执行，否则阻塞。数组大小最好为CPU核心数。任务执行完成后将元素放回，以供别的进程使用。&lt;/li&gt;
&lt;li&gt;生成一个阻塞访问的管道pipe，先向管道中写入若干行，任务执行前从管道中获取token，任务结束后放回。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;最终脚本如下所示

&lt;ul&gt;
&lt;li&gt;我在理解这个脚本的时候感到吃力，比如exec、read等既熟悉又陌生的指令，毕竟没写过shell脚本&lt;/li&gt;
&lt;li&gt;后来我发现，man bash和man sh是第一手消息资料

&lt;ul&gt;
&lt;li&gt;if -p $directory中，-p是什么意思，在man bash的CONDITIONAL EXPRESSIONS中&lt;/li&gt;
&lt;li&gt;read -u999中，-u又是什么意思，在man bash的 SHELL BUILTIN COMMANDS的read指令中&lt;/li&gt;
&lt;li&gt;exec 999&amp;lt;&amp;gt;$Pfifo中，man bash的REDIRECTION小节中&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;#!/bin/sh

awk=/usr/bin/awk
uniq=/usr/bin/uniq

Nproc=24

#$$是进程pid
Pfifo=&amp;quot;/tmp/$$.fifo&amp;quot;
mkfifo $Pfifo

#以999为文件描述符打开管道,&amp;lt;&amp;gt;表示可读可写
exec 999&amp;lt;&amp;gt;$Pfifo
rm -f $Pfifo

#向管道中写入Nproc行,作为令牌
for((i=1; i&amp;lt;=$Nproc; i++)); do
    echo
done &amp;gt;&amp;amp;999

echo &#39;&#39; &amp;gt; out
echo &#39;&#39; &amp;gt; ooo
filenames=`ls *.log`
for filename in $filenames; do
#从管道中取出1行作为token，如果管道为空，read将会阻塞
#man bash可以知道-u是从fd中读取一行
    read -u999

    {
    #所要执行的任务
        `$awk -F&#39;,&#39; &#39;/did/ {for(i=1;i&amp;lt;=NF;i++) if($i ~ /did/) print $i i}&#39; $filename | $awk -F&#39;:&#39; &#39;{print $2}&#39; | $awk -F&#39;&amp;quot;&#39; &#39;{print $2}&#39;  | $uniq | $awk &#39;{count[$1]++}END{for(name in count)print name &amp;gt;&amp;gt; &amp;quot;out&amp;quot;}&#39;` &amp;amp;&amp;amp; {
            echo &amp;quot;$filename done&amp;quot;
        } || {
            echo &amp;quot;$filename error&amp;quot;
        }
        sleep 1
    #归还token
        echo &amp;gt;&amp;amp;999
    }&amp;amp;

done

#等待所有子进程结束
wait 

#关闭管道
exec 999&amp;gt;&amp;amp;-

echo `$awk &#39;{count[$0]++}END{for(name in count)print name}&#39; out &amp;gt; ooo; awk &#39;END{print NR}&#39; ooo`
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;单进程方式处理这些log需要3个小时，而控制并发进程数的话只需要10分钟不到。

&lt;ul&gt;
&lt;li&gt;可见大部分计算资源都浪费在CPU切换上了。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;参考链接:98445e76c0e56f8e093561726589792e&#34;&gt;参考链接&lt;/h1&gt;

&lt;h2 id=&#34;linux-shell-和-lsof-等工具使用的一些tips:98445e76c0e56f8e093561726589792e&#34;&gt;linux shell 和 lsof 等工具使用的一些tips&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://www.cnblogs.com/chengmo/archive/2010/10/20/1855805.html&#34;&gt;linux shell数据输入输出的重定向分析&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://linuxtools-rst.readthedocs.org/zh_CN/latest/tool/lsof.html&#34;&gt;lsof 一切皆文件&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;文件描述符与进程间通信:98445e76c0e56f8e093561726589792e&#34;&gt;文件描述符与进程间通信&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://adelphos.blog.51cto.com/2363901/1598570&#34;&gt;IO重定向和文件描述符&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://www.cnblogs.com/GODYCA/archive/2013/01/05/2845618.html&#34;&gt;文件描述符与进程间通信的关联&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;linux-shell-cocurrency并发控制:98445e76c0e56f8e093561726589792e&#34;&gt;linux shell cocurrency并发控制&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://blog.sciencenet.cn/blog-548663-750136.html&#34;&gt;Bash脚本实现批量作业并行化&lt;/a&gt;
&lt;a href=&#34;https://pebblesinthesand.wordpress.com/2008/05/22/a-srcipt-for-running-processes-in-parallel-in-bash/&#34;&gt;A script for running processes in parallel in Bash&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;awk-sed:98445e76c0e56f8e093561726589792e&#34;&gt;awk&amp;amp;sed&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://kodango.com/sed-and-awk-notes-part-1&#34;&gt;sed&amp;amp;awk入门 一&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://kodango.com/sed-and-awk-notes-part-2&#34;&gt;sed&amp;amp;awk入门 二&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://www.cnblogs.com/dong008259/archive/2011/12/06/2277287.html&#34;&gt;awk用法汇总&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>livestream的几种初步解决方案</title>
      <link>https://bg2bkk.github.io/post/livestream%E7%9A%84%E5%87%A0%E7%A7%8D%E5%88%9D%E6%AD%A5%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/</link>
      <pubDate>Thu, 18 Feb 2016 20:57:19 +0800</pubDate>
      
      <guid>https://bg2bkk.github.io/post/livestream%E7%9A%84%E5%87%A0%E7%A7%8D%E5%88%9D%E6%AD%A5%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/</guid>
      <description>

&lt;h1 id=&#34;实时视频流解决方案:522c154dca6ec9c4e9be4965f54df0ed&#34;&gt;实时视频流解决方案&lt;/h1&gt;

&lt;h2 id=&#34;mjpg-streamer:522c154dca6ec9c4e9be4965f54df0ed&#34;&gt;mjpg-streamer&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;site: https://github.com/codewithpassion/mjpg-streamer/tree/master/mjpg-streamer

    link: http://www.cnblogs.com/hnrainll/archive/2011/06/08/2074909.html
    link: http://blog.163.com/chenhongswing@126/blog/static/1335924432011825104144612/
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;    #提供一个可以直接使用的demo

    git clone https://github.com/codewithpassion/mjpg-streamer/tree/master/mjpg-streamer

    cd mjpg-streamer

    ./mjpg_streamer -i &amp;quot;input_uvc.so -d /dev/video0 -r 640x480 -y&amp;quot; -o &amp;quot;output_http.so -w ./www&amp;quot;

    127.0.0.1:8080访问主页，可以获得stream、static以及通过vlc和mplayer播放
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;ffmpeg-websocket播放:522c154dca6ec9c4e9be4965f54df0ed&#34;&gt;ffmpeg+websocket播放&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;site: https://github.com/phoboslab/jsmpeg
link: http://segmentfault.com/a/1190000000392586
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;    #提供可以直接运行的demo

    git clone https://github.com/phoboslab/jsmpeg

    nodejs stream-server.js huang	监听随机端口
        Listening for MPEG Stream on http://127.0.0.1:8082/&amp;lt;secret&amp;gt;/&amp;lt;width&amp;gt;/&amp;lt;height&amp;gt;
        Awaiting WebSocket connections on ws://127.0.0.1:8084/
        Stream Connected: 127.0.0.1:52460 size: 640x480
        New WebSocket Connection (1 total)
        Disconnected WebSocket (0 total)

    ffmpeg -s 640x480 -f video4linux2 -i /dev/video0 -f mpeg1video -b 800k -r 30 http://localhost:8082/huang/640/480/		ffmpeg采集编码并发送视频流
    google-chrome stream-example.html		使用websocket在线观看
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;vlc视频流输出和vlc视频流播放:522c154dca6ec9c4e9be4965f54df0ed&#34;&gt;vlc视频流输出和vlc视频流播放&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;site: http://www.cnblogs.com/fx2008/p/4315416.html
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;    a、关掉防火墙，至少将视频流端口开启
    b、vlc --ttl 12 -vvv --color -I telnet --telnet-password videolan --rtsp-host 0.0.0.0 --rtsp-port 5554
    c、通过telnet启动vlc的vlm管理中，telnet 127.0.0.1 4212，密码是刚才的videolan
    d、new Test vod enabled 新建一个vod，名字是Test
    e、setup Test input /path/video.file    给Test输入视频
    f、vlc rtsp://127.0.0.1:5554/Test 启动vlc观看视频流，这里还差声音
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;nginx的rtmp转播:522c154dca6ec9c4e9be4965f54df0ed&#34;&gt;nginx的rtmp转播&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;site: http://itony.me/619.html
site: https://github.com/arut/nginx-rtmp-module
site: http://openresty.org
site: http://blog.csdn.net/leixiaohua1020/article/details/12029543
site: http://blog.csdn.net/leixiaohua1020/article/details/39803457
site: http://blog.csdn.net/fireroll/article/details/18899285
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;    a、安装openresty和rtmp模块
    b、配置nginx，rtmp配置块与http配置块平级
        rtmp {
            server {
                listen 1935;
                application live1 {
                    live on;
                    record off;
                }
            }
        }
    c、ffmpeg转发视频流  
        ffmpeg -re -i xxx.mp4 -c copy -f flv   rtmp://localhost:1935/live1/room1
        其中的live1是应用，room1是将来要打开的节点

    d、在vlc中打开视频流： 
        rtmp://localhost:1935/live1/room1

    e、ffmpeg -f video4linux2 -i /dev/video0 -c:v libx264 -an -f flv rtmp://localhost:1935/live1/room1 试试摄像头
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;aliyun-nginx-rtmp在线转播:522c154dca6ec9c4e9be4965f54df0ed&#34;&gt;aliyun+nginx+rtmp在线转播&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;site: http://blog.csdn.net/xdwyyan/article/details/43198985
注意：在nginx中配置rtmp后，reload是不够的，需要kill掉重新启动nginx。
通过sudo netstat -tlnp | grep 1935来观察nginx是否将端口打开
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;    sudo ffmpeg -i /dev/video0 -acodec acc -strict experimental -ar 44100 -ac 2 -b:a 96k -r 25 -b:v 500k -s 640*480 -f flv rtmp://101.200.124.174:1935/live1/room1
    vlc rtmp://101.200.124.174:1935/live1/room1

    ffmpeg -loglevel verbose -re -i xxx.mp4 -vcodec libx264 -vprofile baseline -acodec libmp3lame -ar 44100 -ac 1 -f flv rtmp://101.200.124.174:1935/hls/movie
    vlc http://101.200.124.174/hls/movie

    #v4l2读取摄像头，进行x264编码并将视频流发送至阿里云，进而进行hls播放
    ffmpeg -f video4linux2 -s 320x240 -i /dev/video0 -vcodec libx264 -f flv  rtmp://101.200.124.174:1935/hls/movie
    vlc http://101.200.124.174/hls/movie
    手机浏览器打开也行

    #http config block
    rtmp {
        server {
            listen 1935;
            application live1 {
                live on;
                record off;
            }
            application hls{
                live on;
                hls on;
                hls_path /tmp/hls;
            }
    
        }
    }

    #server config block
    location /hls {
        types {
            application/vnd.apple.mpegurl m3u8;
            video/mp2t ts;
        }
        root /tmp;
        add_header Cache-Control no-cache;
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;extra-info:522c154dca6ec9c4e9be4965f54df0ed&#34;&gt;Extra Info&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;防火墙设置，配置1985端口可以被外网访问
huang@vultr:~$ sudo iptables -A INPUT -m state --state NEW -m tcp -p tcp --dport 1985 -j ACCEPT
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
  </channel>
</rss>